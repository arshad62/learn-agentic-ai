{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arshad62/learn-agentic-ai/blob/main/06b_crew_ai/05_augmented_llms/crewai_crews_advance_concepts.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ap0eICBqtaNa"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ['GEMINI_API_KEY'] =  userdata.get('GEMINI_API_KEY')\n",
        "#os.environ['OPENAI_API_KEY'] =  userdata.get('OPENAI_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFSW_ZpBsr_p",
        "outputId": "a67adba3-0573-4634-cd64-e740c344dce4",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.5/42.5 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.2/240.2 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m52.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m545.9/545.9 kB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m51.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.4/211.4 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m628.3/628.3 kB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.4/71.4 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.6/32.6 MB\u001b[0m \u001b[31m52.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.0/65.0 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.9/55.9 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.7/118.7 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.4/177.4 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m73.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m85.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m756.0/756.0 kB\u001b[0m \u001b[31m37.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.0/236.0 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.2/16.2 MB\u001b[0m \u001b[31m79.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.8/231.8 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.9/253.9 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.6/131.6 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m65.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.1/45.1 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m69.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.8/311.8 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.8/99.8 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.8/76.8 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.7/35.7 MB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m77.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.1/71.1 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m44.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m71.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m71.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m415.1/415.1 kB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.2/209.2 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m508.0/508.0 kB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m306.6/306.6 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m78.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m452.6/452.6 kB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m67.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "transformers 4.48.3 requires tokenizers<0.22,>=0.21, but you have tokenizers 0.20.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -Uq crewai crewai-tools\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade chromadb\n",
        "!pip install --upgrade tokenizers"
      ],
      "metadata": {
        "collapsed": true,
        "id": "xISagNdfpk5n",
        "outputId": "ac2d220a-19fa-4117-ba7e-49559b6f0f00",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: chromadb in /usr/local/lib/python3.11/dist-packages (0.5.23)\n",
            "Collecting chromadb\n",
            "  Using cached chromadb-0.6.3-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.2.2.post1)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.11/dist-packages (from chromadb) (2.10.6)\n",
            "Requirement already satisfied: chroma-hnswlib==0.7.6 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.7.6)\n",
            "Requirement already satisfied: fastapi>=0.95.2 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.115.11)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.34.0)\n",
            "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.26.4)\n",
            "Requirement already satisfied: posthog>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (3.18.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.12.2)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.20.1)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.30.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.30.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.51b0)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.30.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.21.0)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.48.9)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.67.1)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.70.0)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.3.0)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.15.1)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (32.0.1)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.11/dist-packages (from chromadb) (9.0.0)\n",
            "Requirement already satisfied: PyYAML>=6.0.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.0.2)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (5.1.0)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.11/dist-packages (from chromadb) (3.10.15)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.27.2)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (13.9.4)\n",
            "Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb) (24.2)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
            "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi>=0.95.2->chromadb) (0.46.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.38.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.32.3)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.3.0)\n",
            "Requirement already satisfied: durationpy>=0.7 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (0.9)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.2.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (5.29.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.18)\n",
            "Requirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.5.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.68.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.30.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.30.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.30.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.30.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.51b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.51b0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation==0.51b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.51b0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.51b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.51b0)\n",
            "Requirement already satisfied: opentelemetry-util-http==0.51b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.51b0)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation==0.51b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.17.2)\n",
            "Requirement already satisfied: asgiref~=3.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-asgi==0.51b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (3.8.1)\n",
            "Requirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
            "Requirement already satisfied: distro>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb) (1.9.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (2.27.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (2.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers>=0.13.2->chromadb) (0.28.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.4)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.1)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.4)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (14.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.17.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2024.10.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.21.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->kubernetes>=28.1.0->chromadb) (3.4.1)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.11/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
            "Downloading chromadb-0.6.3-py3-none-any.whl (611 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.1/611.1 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: chromadb\n",
            "  Attempting uninstall: chromadb\n",
            "    Found existing installation: chromadb 0.5.23\n",
            "    Uninstalling chromadb-0.5.23:\n",
            "      Successfully uninstalled chromadb-0.5.23\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "embedchain 0.1.127 requires chromadb<0.6.0,>=0.5.10, but you have chromadb 0.6.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed chromadb-0.6.3\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.11/dist-packages (0.21.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers) (0.28.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (3.17.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (2025.1.31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "GGr9H6g3u7Yw"
      },
      "outputs": [],
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NpugUP6Ns_9s",
        "outputId": "133bb58e-1f8e-4788-9024-8031c1802951"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m\u001b[35m Flow started with ID: 6c3ff93a-d394-4960-a591-21df4e7c357d\u001b[00m\n",
            "step1\n",
            "step2\n"
          ]
        }
      ],
      "source": [
        "from crewai.flow.flow import Flow, start, listen\n",
        "\n",
        "\n",
        "class MyFlow(Flow):\n",
        "\n",
        "  @start()\n",
        "  def function1(self):\n",
        "    print(\"step1\")\n",
        "\n",
        "  @listen(function1)\n",
        "  def function2(self):\n",
        "    print(\"step2\")\n",
        "\n",
        "obj = MyFlow()\n",
        "obj.kickoff()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bNu9UJvmzxNt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "3431DBKDvLKH",
        "outputId": "22f68068-4716-4b43-9a3e-8e06655bd471"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The capital of France is **Paris**.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "from crewai import LLM\n",
        "\n",
        "llm1 = LLM(\n",
        "    model=\"gemini/gemini-2.0-flash\",\n",
        ")\n",
        "\n",
        "llm1.call(\"What is the capital of France?\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "google_embedder = {\n",
        "    \"provider\": \"google\",\n",
        "    \"config\": {\n",
        "         \"model\": \"models/text-embedding-004\",\n",
        "         \"api_key\": userdata.get('GEMINI_API_KEY'),\n",
        "         }\n",
        "}"
      ],
      "metadata": {
        "id": "uJbk8RXv_F0h"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "VAKrwYPb9X_L",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "605523a7-8d7f-4ca5-99af-66fc3e14fd9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:opentelemetry.trace:Overriding of current TracerProvider is not allowed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mAbout User\u001b[00m\n",
            "\u001b[95m## Task:\u001b[00m \u001b[92mAnswer the following questions about the user: What city does Arshad live in and how old is he?\u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mAbout User\u001b[00m\n",
            "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
            "Arshad lives in Doha, Qatar, and he is 62 years old.\u001b[00m\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from crewai import Agent, Task, Crew, Process, LLM\n",
        "from crewai.knowledge.source.string_knowledge_source import StringKnowledgeSource\n",
        "\n",
        "# Create a knowledge source\n",
        "content = \"Users name is Arshad. He is 62 years old and lives in Doha, Qatar. He is working as Telecome Consultant at MoD\"\n",
        "string_source = StringKnowledgeSource(\n",
        "    content=content,\n",
        ")\n",
        "\n",
        "\n",
        "# Create an agent with the knowledge store\n",
        "agent = Agent(\n",
        "    role=\"About User\",\n",
        "    goal=\"You know everything about the user.\",\n",
        "    backstory=\"\"\"You are a master at understanding people and their preferences.\"\"\",\n",
        "    verbose=True,\n",
        "    allow_delegation=False,\n",
        "    llm=llm1,\n",
        ")\n",
        "task = Task(\n",
        "    description=\"Answer the following questions about the user: {question}\",\n",
        "    expected_output=\"An answer to the question.\",\n",
        "    agent=agent,\n",
        ")\n",
        "\n",
        "crew = Crew(\n",
        "    memory=True,\n",
        "    agents=[agent],\n",
        "    tasks=[task],\n",
        "    verbose=True,\n",
        "    process=Process.sequential,\n",
        "    knowledge_sources=[string_source], # Enable knowledge by adding the sources here. You can also add more sources to the sources list.\n",
        "    embedder=google_embedder\n",
        "\n",
        ")\n",
        "\n",
        "result = crew.kickoff(inputs={\"question\": \"What city does Arshad live in and how old is he?\"})"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['CREWAI_STORAGE_DIR']='/my_crew1'"
      ],
      "metadata": {
        "id": "vZXRhpziuWUp"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from crewai import LLM\n",
        "\n",
        "llm1 = LLM(\n",
        "    model=\"gemini/gemini-2.0-flash\",\n",
        ")"
      ],
      "metadata": {
        "id": "TF6W3QCYx20V"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from crewai import Crew, Process\n",
        "from crewai.memory import LongTermMemory, ShortTermMemory, EntityMemory\n",
        "# from crewai.memory.storage import LTMSQLiteStorage, RAGStorage\n",
        "from crewai.memory.storage.ltm_sqlite_storage import LTMSQLiteStorage\n",
        "from crewai.memory.storage.rag_storage import RAGStorage\n",
        "\n",
        "from typing import List, Optional\n",
        "\n",
        "# Create an agent with the knowledge store\n",
        "agent = Agent(\n",
        "    role=\"About User\",\n",
        "    goal=\"You know everything about the user.\",\n",
        "    backstory=\"\"\"You are a master at understanding people and their preferences.\"\"\",\n",
        "    verbose=True,\n",
        "    allow_delegation=False,\n",
        "    llm=llm1,\n",
        ")\n",
        "task = Task(\n",
        "    description=\"Answer the following questions about the user: {question}\",\n",
        "    expected_output=\"An answer to the question.\",\n",
        "    agent=agent,\n",
        ")\n",
        "\n",
        "crew = Crew(\n",
        "    agents=[agent],\n",
        "    tasks=[task],\n",
        "    process = Process.sequential,\n",
        "    memory = True,\n",
        "    # Long-term memory for persistent storage across sessions\n",
        "    long_term_memory = LongTermMemory(\n",
        "        storage=LTMSQLiteStorage(\n",
        "            db_path=\"./my_crew2/long_term_memory_storage1.db\"\n",
        "        )\n",
        "    ),\n",
        "    # Short-term memory for current context using RAG\n",
        "    short_term_memory = ShortTermMemory(\n",
        "        storage = RAGStorage(\n",
        "                embedder_config=google_embedder,\n",
        "                type=\"short_term\",\n",
        "                path=\"./my_crew2/short_term1/\"\n",
        "            )\n",
        "        ),\n",
        "\n",
        "    # Entity memory for tracking key information about entities\n",
        "    entity_memory = EntityMemory(\n",
        "        storage=RAGStorage(\n",
        "            embedder_config=google_embedder,\n",
        "            type=\"short_term\",\n",
        "            path=\"./my_crew2/entity1/\"\n",
        "        )\n",
        "    ),\n",
        "    verbose=True,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4qEtZohmsWqJ",
        "outputId": "37d98170-c653-4c0e-b324-a6a068d14ec6"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:opentelemetry.trace:Overriding of current TracerProvider is not allowed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Integrating Mem0 for Enhanced User Memory\n"
      ],
      "metadata": {
        "id": "QPpWuM_VyG-O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from crewai import Crew, Process\n",
        "from mem0 import MemoryClient\n",
        "\n",
        "# Set environment variables for Mem0\n",
        "os.environ[\"MEM0_API_KEY\"] = userdata.get('MEM0_API_KEY')\n",
        "\n",
        "# Step 1: Record preferences based on past conversation or user input\n",
        "client = MemoryClient()\n",
        "# messages = [\n",
        "#     {\"role\": \"user\", \"content\": \"Hi there! I'm planning a vacation and could use some advice.\"},\n",
        "#     {\"role\": \"assistant\", \"content\": \"Hello! I'd be happy to help with your vacation planning. What kind of destination do you prefer?\"},\n",
        "#     {\"role\": \"user\", \"content\": \"I am more of a beach person than a mountain person.\"},\n",
        "#     {\"role\": \"assistant\", \"content\": \"That's interesting. Do you like hotels or Airbnb?\"},\n",
        "#     {\"role\": \"user\", \"content\": \"I like Airbnb more.\"},\n",
        "# ]\n",
        "# client.add(messages, user_id=\"john\")\n",
        "\n",
        "# Step 2: Create a Crew with User Memory\n",
        "\n",
        "# Create an agent with the knowledge store\n",
        "agent = Agent(\n",
        "    role=\"About User\",\n",
        "    goal=\"You know everything about the user.\",\n",
        "    backstory=\"\"\"You are a master at understanding people and their preferences.\"\"\",\n",
        "    verbose=True,\n",
        "    allow_delegation=False,\n",
        "    llm=llm1,\n",
        ")\n",
        "task = Task(\n",
        "    description=\"Answer the following questions about the user: {question}\",\n",
        "    expected_output=\"An answer to the question.\",\n",
        "    agent=agent,\n",
        ")\n",
        "\n",
        "crew = Crew(\n",
        "    agents=[agent],\n",
        "    tasks=[task],\n",
        "    process = Process.sequential,\n",
        "    verbose=True,\n",
        "    memory=True,\n",
        "    memory_config={\n",
        "        \"provider\": \"mem0\",\n",
        "        \"config\": {\"user_id\": \"john\"},\n",
        "    },\n",
        ")\n",
        "\n",
        "crew.kickoff(inputs={\"question\": \"What is your favorite vacation destination?\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zvuaYvNwvGMH",
        "outputId": "27e2d1d1-37f5-4073-aa20-2614ab97b429"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:opentelemetry.trace:Overriding of current TracerProvider is not allowed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mAbout User\u001b[00m\n",
            "\u001b[95m## Task:\u001b[00m \u001b[92mAnswer the following questions about the user: What is your favorite vacation destination?\u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mAbout User\u001b[00m\n",
            "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
            "As an AI, I do not have personal preferences or the ability to travel, so I do not have a favorite vacation destination.\u001b[00m\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/mem0/client/main.py:32: DeprecationWarning: Using default output format 'v1.0' is deprecated and will be removed in version 0.1.70. Please use output_format='v1.1' for enhanced memory details. Check out the docs for more information: https://docs.mem0.ai/platform/quickstart#4-1-create-memories\n",
            "  return func(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/mem0/client/main.py:32: DeprecationWarning: Using default output format 'v1.0' is deprecated and will be removed in version 0.1.70. Please use output_format='v1.1' for enhanced memory details. Check out the docs for more information: https://docs.mem0.ai/platform/quickstart#4-1-create-memories\n",
            "  return func(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CrewOutput(raw='As an AI, I do not have personal preferences or the ability to travel, so I do not have a favorite vacation destination.', pydantic=None, json_dict=None, tasks_output=[TaskOutput(description='Answer the following questions about the user: What is your favorite vacation destination?', name=None, expected_output='An answer to the question.', summary='Answer the following questions about the user: What is your...', raw='As an AI, I do not have personal preferences or the ability to travel, so I do not have a favorite vacation destination.', pydantic=None, json_dict=None, agent='About User', output_format=<OutputFormat.RAW: 'raw'>)], token_usage=UsageMetrics(total_tokens=251, prompt_tokens=177, cached_prompt_tokens=0, completion_tokens=74, successful_requests=1))"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tools"
      ],
      "metadata": {
        "id": "TjmPV4Y5igih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade transformers\n",
        "!pip install --upgrade tokenizers\n",
        "!pip install -Uq 'crewai[tools]'"
      ],
      "metadata": {
        "id": "Xzmx5DBcdCiN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "1e022e5b-46d6-47c8-8e6d-2171f34b93ca"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.49.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.28.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
            "  Using cached tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
            "Using cached tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "Installing collected packages: tokenizers\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.20.3\n",
            "    Uninstalling tokenizers-0.20.3:\n",
            "      Successfully uninstalled tokenizers-0.20.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "embedchain 0.1.127 requires chromadb<0.6.0,>=0.5.10, but you have chromadb 0.6.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed tokenizers-0.21.0\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.11/dist-packages (0.21.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers) (0.28.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (3.17.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (2025.1.31)\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "transformers 4.49.0 requires tokenizers<0.22,>=0.21, but you have tokenizers 0.20.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade chromadb"
      ],
      "metadata": {
        "collapsed": true,
        "id": "eHue-nhx0rae",
        "outputId": "fa33edca-21e9-4f0a-e429-26ac8c7ad6f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: chromadb in /usr/local/lib/python3.11/dist-packages (0.5.23)\n",
            "Collecting chromadb\n",
            "  Using cached chromadb-0.6.3-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.2.2.post1)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.11/dist-packages (from chromadb) (2.10.6)\n",
            "Requirement already satisfied: chroma-hnswlib==0.7.6 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.7.6)\n",
            "Requirement already satisfied: fastapi>=0.95.2 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.115.11)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.34.0)\n",
            "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.26.4)\n",
            "Requirement already satisfied: posthog>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (3.18.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.12.2)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.20.1)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.30.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.30.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.51b0)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.30.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.20.3)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.48.9)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.67.1)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.70.0)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.3.0)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.15.1)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (32.0.1)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.11/dist-packages (from chromadb) (9.0.0)\n",
            "Requirement already satisfied: PyYAML>=6.0.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.0.2)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (5.1.0)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.11/dist-packages (from chromadb) (3.10.15)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.27.2)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (13.9.4)\n",
            "Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb) (24.2)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
            "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi>=0.95.2->chromadb) (0.46.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.38.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.32.3)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.3.0)\n",
            "Requirement already satisfied: durationpy>=0.7 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (0.9)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.2.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (5.29.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.18)\n",
            "Requirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.5.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.68.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.30.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.30.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.30.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.30.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.51b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.51b0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation==0.51b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.51b0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.51b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.51b0)\n",
            "Requirement already satisfied: opentelemetry-util-http==0.51b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.51b0)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation==0.51b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.17.2)\n",
            "Requirement already satisfied: asgiref~=3.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-asgi==0.51b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (3.8.1)\n",
            "Requirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
            "Requirement already satisfied: distro>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb) (1.9.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (2.27.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (2.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers>=0.13.2->chromadb) (0.28.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.4)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.1)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.4)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (14.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.17.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2024.10.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.21.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->kubernetes>=28.1.0->chromadb) (3.4.1)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.11/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
            "Using cached chromadb-0.6.3-py3-none-any.whl (611 kB)\n",
            "Installing collected packages: chromadb\n",
            "  Attempting uninstall: chromadb\n",
            "    Found existing installation: chromadb 0.5.23\n",
            "    Uninstalling chromadb-0.5.23:\n",
            "      Successfully uninstalled chromadb-0.5.23\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "embedchain 0.1.127 requires chromadb<0.6.0,>=0.5.10, but you have chromadb 0.6.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed chromadb-0.6.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "chromadb"
                ]
              },
              "id": "1814f39504ce409fb20d9b44e97743d8"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pzVzY9Pq3zAn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"SERPER_API_KEY\"] = userdata.get('SERPER_API_KEY')"
      ],
      "metadata": {
        "id": "P3a8h46aI1SH"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedder = {\n",
        "        \"provider\": \"google\",\n",
        "        \"config\": {\n",
        "            \"model\": \"models/text-embedding-004\",\n",
        "            \"api_key\": userdata.get('GEMINI_API_KEY'),\n",
        "        }\n",
        "    }"
      ],
      "metadata": {
        "id": "EVhmjxSsuL9c"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -Uq langchain-google-genai"
      ],
      "metadata": {
        "id": "jqJVnF7ivuop",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63623e6c-fc9c-45e8-ef68-6ff6c908bcf4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.4 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.5/1.4 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-generativeai 0.8.4 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.6.16 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from crewai import LLM\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "llm1=LLM(model=\"gemini/gemini-1.5-flash\")"
      ],
      "metadata": {
        "id": "c8-oehbdviqn"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai\n",
        "import os\n",
        "from crewai import Agent, Task, Crew\n",
        "# Importing crewAI tools\n",
        "from crewai_tools import (\n",
        "    DirectoryReadTool,\n",
        "    FileReadTool,\n",
        "    SerperDevTool,\n",
        "    WebsiteSearchTool\n",
        ")\n",
        "\n",
        "# Set up API keys\n",
        "os.environ[\"SERPER_API_KEY\"] = userdata.get('SERPER_API_KEY') # serper.dev API key\n",
        "os.environ[\"GEMINI_API_KEY\"] = userdata.get('GEMINI_API_KEY')\n",
        "\n",
        "# Instantiate tools\n",
        "docs_tool = DirectoryReadTool(directory='./blog-posts')\n",
        "file_tool = FileReadTool()\n",
        "search_tool = SerperDevTool()\n",
        "# Example with WebsiteSearchTool\n",
        "web_rag_tool = WebsiteSearchTool(embedder_config=google_embedder)\n",
        "\n",
        "# Create agents\n",
        "researcher = Agent(\n",
        "    role='Market Research Analyst',\n",
        "    goal='Provide up-to-date market analysis of the AI industry',\n",
        "    backstory='An expert analyst with a keen eye for market trends.',\n",
        "    tools=[search_tool, web_rag_tool],\n",
        "    verbose=True,\n",
        "    llm=llm1\n",
        ")\n",
        "\n",
        "writer = Agent(\n",
        "    role='Content Writer',\n",
        "    goal='Craft engaging blog posts about the AI industry',\n",
        "    backstory='A skilled writer with a passion for technology.',\n",
        "    tools=[docs_tool, file_tool],\n",
        "    verbose=True,\n",
        "    llm=llm1\n",
        ")\n",
        "\n",
        "# Define tasks\n",
        "research = Task(\n",
        "    description='Research the latest trends in the AI industry and provide a summary.',\n",
        "    expected_output='A summary of the top 3 trending developments in the AI industry with a unique perspective on their significance.',\n",
        "    agent=researcher\n",
        ")\n",
        "\n",
        "write = Task(\n",
        "    description='Write an engaging blog post about the AI industry, based on the research analyst’s summary. Draw inspiration from the latest blog posts in the directory.',\n",
        "    expected_output='A 4-paragraph blog post formatted in markdown with engaging, informative, and accessible content, avoiding complex jargon.',\n",
        "    agent=writer,\n",
        "    output_file='blog-posts/new_post.md'  # The final blog post will be saved here\n",
        ")\n",
        "\n",
        "# Assemble a crew with planning enabled\n",
        "crew = Crew(\n",
        "    agents=[researcher, writer],\n",
        "    tasks=[research, write],\n",
        "    verbose=True,\n",
        "    planning=True,  # Enable planning feature\n",
        "    planning_llm=llm1\n",
        ")\n",
        "\n",
        "# Execute tasks\n",
        "crew.kickoff()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 584
        },
        "id": "n4R4y8KZNRkw",
        "outputId": "e98b59c9-6203-4f2f-ef17-ea9cd9c2aec2"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.61.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.27.2)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.8.2)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.10.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'OPENAI_API_KEY'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-80c2f3c4bf26>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0msearch_tool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSerperDevTool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# Example with WebsiteSearchTool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mweb_rag_tool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWebsiteSearchTool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedder_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgoogle_embedder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# Create agents\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/crewai_tools/tools/website_search/website_search_tool.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, website, **kwargs)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwebsite\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwebsite\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"data_type\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWEB_PAGE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/crewai_tools/tools/rag/rag_tool.py\u001b[0m in \u001b[0;36m_set_default_adapter\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0mcrewai_tools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madapters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedchain_adapter\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEmbedchainAdapter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0mapp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mApp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mApp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m             self.adapter = EmbedchainAdapter(\n\u001b[1;32m     48\u001b[0m                 \u001b[0membedchain_app\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mapp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummarize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummarize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/embedchain/app.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, id, name, config, db, embedding_model, llm, config_data, auto_deploy, chunker, cache_config, memory_config, log_level)\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding_model\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mOpenAIEmbedder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdb\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mChromaDB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mllm\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mOpenAILlm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/embedchain/embedder/openai.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"text-embedding-ada-002\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mapi_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_key\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"OPENAI_API_KEY\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mapi_base\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_base\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"OPENAI_API_BASE\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/os.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'OPENAI_API_KEY'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: import markdown for jupyter display\n",
        "\n",
        "from IPython.display import Markdown\n",
        "\n",
        "def display_markdown_file(file_path):\n",
        "    with open(file_path, 'r') as f:\n",
        "        content = f.read()\n",
        "    display(Markdown(content))\n",
        "\n",
        "# Example usage: Assuming 'blog-posts/new_post.md' is the file generated by your code\n",
        "display_markdown_file('blog-posts/new_post.md')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "id": "NRv779rBMN3U",
        "outputId": "19f30d56-ce30-4ddc-a64e-afb7ef61b103"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "# The AI Revolution: Top Trends Shaping the Future\n\nThe artificial intelligence industry is experiencing unprecedented growth and innovation, transforming businesses and daily life as we know it. From self-driving cars to virtual assistants, AI's influence is undeniable, and the pace of development shows no signs of slowing down. Staying informed about the latest trends is crucial for anyone looking to understand and leverage the power of AI.\n\nCurrently, three major trends are taking center stage. First, advancements in generative AI are democratizing content creation and problem-solving. Second, the growing emphasis on ethical AI and responsible development is ensuring that AI systems are fair, transparent, and beneficial to society. And finally, AI is revolutionizing healthcare, offering new possibilities for diagnostics, treatment, and patient care.\n\nWhat makes these trends particularly significant is their potential to create a more accessible, trustworthy, and equitable future. Generative AI is empowering non-technical users to harness the power of AI, while ethical AI is building trust and ensuring the long-term sustainability of AI adoption. Moreover, AI's transformative impact on healthcare has the potential to democratize access to quality medical services and improve patient outcomes globally, especially with the convergence of AI and robotics.\n\nLooking ahead, the AI industry promises even more groundbreaking developments. As AI technologies continue to mature, we can expect to see even greater integration into our daily lives, driving innovation and creating new opportunities across various sectors. By embracing these advancements and addressing the ethical considerations that come with them, we can unlock the full potential of AI and create a future where technology benefits all of humanity.\n```"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating your own Tools"
      ],
      "metadata": {
        "id": "rMPlKb9l0sk6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from crewai.tools import BaseTool\n",
        "from pydantic import BaseModel, Field\n",
        "from typing import Type\n",
        "\n",
        "class MyToolInput(BaseModel):\n",
        "    \"\"\"Input schema for MyCustomTool.\"\"\"\n",
        "    student_name: str = Field(..., description=\"Student name\")\n",
        "    student_roll_no : int = Field(..., description=\"student id\")\n",
        "\n",
        "class PiaicStudentCard(BaseTool):\n",
        "    name: str = \"Piaic student card generator\"\n",
        "    description: str = \"this function will create Piaic student card\"\n",
        "    args_schema: Type[BaseModel] = MyToolInput\n",
        "\n",
        "    def _run(self, student_name: str, student_roll_no: int ) -> str:\n",
        "        # Your tool's logic here\n",
        "        return f\"\"\"PIAIC student card\n",
        "student name: {student_name}\n",
        "student roll no: {student_roll_no}\n",
        "Pakistan zindabd!\n",
        "        \"\"\""
      ],
      "metadata": {
        "id": "ortq46tpxmW_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from crewai.tools import tool\n",
        "\n",
        "@tool(\"PIAIC fee update\")\n",
        "def my_tool(roll_no: int) -> dict | str:\n",
        "    \"\"\"this function search piaic student fee updates, it will required roll no of PIAIC student\"\"\"\n",
        "    #database\n",
        "\n",
        "    data = {100:'paid',\n",
        "         200:'unpaid'}\n",
        "\n",
        "\n",
        "    status = data.get(roll_no)\n",
        "\n",
        "    if status:\n",
        "      return {\"status\": status}\n",
        "    else:\n",
        "      return \"student not found\"\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "f8rtrAviRgAn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from crewai import Agent, Task, Crew\n",
        "\n",
        "card = PiaicStudentCard()\n",
        "\n",
        "\n",
        "piaic_manager = Agent(\n",
        "    role=\"PIAIC manager\",\n",
        "    goal = \"Manage all quries regarding PIAIC and you will use only relevant tools for student query\",\n",
        "    backstory=\"\"\"You are a master at understanding people and their preferences.\"\"\",\n",
        "    tools=[card, my_tool],\n",
        "    verbose=True,\n",
        "    llm=llm1\n",
        ")\n",
        "\n",
        "piaic_card_creator = Task(\n",
        "    description=\"you will be responsible for all PIAIC relevant operations, student query '{query}' you must be know how to answer his question based on final context\",\n",
        "    expected_output=\"final query answer only\",\n",
        "    agent=piaic_manager\n",
        ")\n",
        "\n",
        "crew = Crew(\n",
        "    agents=[piaic_manager],\n",
        "    tasks=[piaic_card_creator],\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "result = crew.kickoff(inputs={\n",
        "    \"query\":\"I'm PIAIC student my name is Muhammad Qasim and my roll number is 100, can you create my student card.\"\n",
        "})\n",
        "\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eL5p9zmc189a",
        "outputId": "59442f54-d664-4abc-adef-dc43c0849ade"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:opentelemetry.trace:Overriding of current TracerProvider is not allowed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mPIAIC manager\u001b[00m\n",
            "\u001b[95m## Task:\u001b[00m \u001b[92myou will be responsible for all PIAIC relevant operations, student query 'I'm PIAIC student my name is Muhammad Qasim and my roll number is 100, can you create my student card.' you must be know how to answer his question based on final context\u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mPIAIC manager\u001b[00m\n",
            "\u001b[95m## Thought:\u001b[00m \u001b[92mThe user is asking to generate a student card. I should use the \"Piaic student card generator\" tool to generate the card. I need to extract the student's name and roll number from the query.\u001b[00m\n",
            "\u001b[95m## Using tool:\u001b[00m \u001b[92mPiaic student card generator\u001b[00m\n",
            "\u001b[95m## Tool Input:\u001b[00m \u001b[92m\n",
            "\"{\\\"student_name\\\": \\\"Muhammad Qasim\\\", \\\"student_roll_no\\\": 100}\"\u001b[00m\n",
            "\u001b[95m## Tool Output:\u001b[00m \u001b[92m\n",
            "PIAIC student card\n",
            "student name: Muhammad Qasim\n",
            "student roll no: 100\n",
            "Pakistan zindabd!\n",
            "        \u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mPIAIC manager\u001b[00m\n",
            "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
            "PIAIC student card\n",
            "student name: Muhammad Qasim\n",
            "student roll no: 100\n",
            "Pakistan zindabd!\u001b[00m\n",
            "\n",
            "\n",
            "PIAIC student card\n",
            "student name: Muhammad Qasim\n",
            "student roll no: 100\n",
            "Pakistan zindabd!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = crew.kickoff(inputs={\n",
        "    \"query\":\"I'm PIAIC student  my roll number is 100, can you share my fee updates?.\"\n",
        "})\n",
        "\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q1KC8MMJSes1",
        "outputId": "7055925d-7313-425c-c915-86278e34dfd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mPIAIC manager\u001b[00m\n",
            "\u001b[95m## Task:\u001b[00m \u001b[92myou will be responsible for all PIAIC relevant operations, student query 'I'm PIAIC student  my roll number is 100, can you share my fee updates?.' you must be know how to answer his question based on final context\u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mPIAIC manager\u001b[00m\n",
            "\u001b[95m## Using tool:\u001b[00m \u001b[92mPIAIC fee update\u001b[00m\n",
            "\u001b[95m## Tool Input:\u001b[00m \u001b[92m\n",
            "\"{\\\"roll_no\\\": 100}\"\u001b[00m\n",
            "\u001b[95m## Tool Output:\u001b[00m \u001b[92m\n",
            "{'status': 'paid'}\u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mPIAIC manager\u001b[00m\n",
            "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
            "your fee is paid\u001b[00m\n",
            "\n",
            "\n",
            "your fee is paid\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = crew.kickoff(inputs={\n",
        "    \"query\":\"I'm PIAIC student  my roll number is 200, can you share my fee updates?.\"\n",
        "})\n",
        "\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vlUXsdNGQSNX",
        "outputId": "475b9dd5-c761-4cd8-dad3-98de3e0d2b7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mPIAIC manager\u001b[00m\n",
            "\u001b[95m## Task:\u001b[00m \u001b[92myou will be responsible for all PIAIC relevant operations, student query 'I'm PIAIC student  my roll number is 200, can you share my fee updates?.' you must be know how to answer his question based on final context\u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mPIAIC manager\u001b[00m\n",
            "\u001b[95m## Using tool:\u001b[00m \u001b[92mPIAIC fee update\u001b[00m\n",
            "\u001b[95m## Tool Input:\u001b[00m \u001b[92m\n",
            "\"{\\\"roll_no\\\": 200}\"\u001b[00m\n",
            "\u001b[95m## Tool Output:\u001b[00m \u001b[92m\n",
            "{'status': 'unpaid'}\n",
            "\n",
            "\n",
            "You ONLY have access to the following tools, and should NEVER make up tools that are not listed here:\n",
            "\n",
            "Tool Name: Piaic student card generator\n",
            "Tool Arguments: {'student_name': {'description': 'Student name', 'type': 'str'}, 'student_roll_no': {'description': 'student id', 'type': 'int'}}\n",
            "Tool Description: this function will create Piaic student card\n",
            "Tool Name: PIAIC fee update\n",
            "Tool Arguments: {'roll_no': {'description': None, 'type': 'int'}}\n",
            "Tool Description: this function search piaic student fee updates, it will required roll no of PIAIC student\n",
            "\n",
            "IMPORTANT: Use the following format in your response:\n",
            "\n",
            "```\n",
            "Thought: you should always think about what to do\n",
            "Action: the action to take, only one name of [Piaic student card generator, PIAIC fee update], just the name, exactly as it's written.\n",
            "Action Input: the input to the action, just a simple JSON object, enclosed in curly braces, using \" to wrap keys and values.\n",
            "Observation: the result of the action\n",
            "```\n",
            "\n",
            "Once all necessary information is gathered, return the following format:\n",
            "\n",
            "```\n",
            "Thought: I now know the final answer\n",
            "Final Answer: the final answer to the original input question\n",
            "```\u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mPIAIC manager\u001b[00m\n",
            "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
            "Your fee status is unpaid.\u001b[00m\n",
            "\n",
            "\n",
            "Your fee status is unpaid.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Process"
      ],
      "metadata": {
        "id": "xx5Sbl5PVwep"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from crewai import Agent, Task, Crew, Process\n",
        "\n",
        "# Importing crewAI tools\n",
        "from crewai_tools import (\n",
        "    DirectoryReadTool,\n",
        "    FileReadTool,\n",
        "    SerperDevTool,\n",
        "    WebsiteSearchTool\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "# Instantiate tools\n",
        "docs_tool = DirectoryReadTool(directory='./blog-posts2')\n",
        "file_tool = FileReadTool()\n",
        "search_tool = SerperDevTool()\n",
        "web_rag_tool = WebsiteSearchTool()\n",
        "\n",
        "# Define your agents\n",
        "researcher = Agent(\n",
        "    role=\"Researcher\",\n",
        "    goal=\"Conduct thorough research and analysis on AI and AI agents\",\n",
        "    backstory=\"You're an expert researcher, specialized in technology, software engineering, AI, and startups. You work as a freelancer and are currently researching for a new client.\",\n",
        "    allow_delegation=False,\n",
        "    tools=[search_tool,web_rag_tool],\n",
        "    llm=llm1\n",
        ")\n",
        "\n",
        "writer = Agent(\n",
        "    role=\"Senior Writer\",\n",
        "    goal=\"Create compelling content about AI and AI agents\",\n",
        "    backstory=\"You're a senior writer, specialized in technology, software engineering, AI, and startups. You work as a freelancer and are currently writing content for a new client.\",\n",
        "    allow_delegation=False,\n",
        "    tools=[docs_tool,file_tool],\n",
        "    llm=llm1\n",
        ")\n",
        "\n",
        "# Define your task\n",
        "task = Task(\n",
        "    description=\"Generate a list of 5 interesting ideas for an article, then write one captivating paragraph for each idea that showcases the potential of a full article on this topic. Return the list of ideas with their paragraphs and your notes.\",\n",
        "    expected_output=\"5 bullet points, each with a paragraph and accompanying notes.\",\n",
        ")\n",
        "\n",
        "# Define the manager agent\n",
        "manager = Agent(\n",
        "    role=\"Project Manager\",\n",
        "    goal=\"Efficiently manage the crew and ensure high-quality task completion\",\n",
        "    backstory=\"You're an experienced project manager, skilled in overseeing complex projects and guiding teams to success. Your role is to coordinate the efforts of the crew members, ensuring that each task is completed on time and to the highest standard.\",\n",
        "    allow_delegation=True,\n",
        "    llm=llm1\n",
        ")\n",
        "\n",
        "# Instantiate your crew with a custom manager\n",
        "crew = Crew(\n",
        "    agents=[researcher, writer],\n",
        "    tasks=[task],\n",
        "    manager_agent=manager,\n",
        "    function_calling_llm=llm1,\n",
        "    process=Process.hierarchical,\n",
        "    verbose=True\n",
        "\n",
        ")\n",
        "\n",
        "# Start the crew's work\n",
        "result = crew.kickoff()\n",
        "from IPython.display import Markdown\n",
        "\n",
        "Markdown(result.raw)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "DPHWMms13Vj0",
        "outputId": "4ba1ce4b-358f-4bff-f965-0c738a246d6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:opentelemetry.trace:Overriding of current TracerProvider is not allowed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mProject Manager\u001b[00m\n",
            "\u001b[95m## Task:\u001b[00m \u001b[92mGenerate a list of 5 interesting ideas for an article, then write one captivating paragraph for each idea that showcases the potential of a full article on this topic. Return the list of ideas with their paragraphs and your notes.\u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mProject Manager\u001b[00m\n",
            "\u001b[95m## Using tool:\u001b[00m \u001b[92mDelegate work to coworker\u001b[00m\n",
            "\u001b[95m## Tool Input:\u001b[00m \u001b[92m\n",
            "\"{\\\"task\\\": {\\\"description\\\": \\\"Research potential topics for articles that would be interesting and engaging for a general audience. I need a diverse range of ideas, so explore different fields and current trends.\\\", \\\"type\\\": \\\"str\\\"}, \\\"context\\\": {\\\"description\\\": \\\"The goal is to generate 5 distinct and captivating article ideas that can be developed into full-length pieces. The target audience is broad, so topics should be accessible and engaging to a wide range of readers.\\\", \\\"type\\\": \\\"str\\\"}, \\\"coworker\\\": {\\\"description\\\": \\\"Researcher\\\", \\\"type\\\": \\\"str\\\"}}\"\u001b[00m\n",
            "\u001b[95m## Tool Output:\u001b[00m \u001b[92m\n",
            "\n",
            "I encountered an error while trying to use the tool. This was the error: unhashable type: 'dict'.\n",
            " Tool Delegate work to coworker accepts these inputs: Tool Name: Delegate work to coworker\n",
            "Tool Arguments: {'task': {'description': 'The task to delegate', 'type': 'str'}, 'context': {'description': 'The context for the task', 'type': 'str'}, 'coworker': {'description': 'The role/name of the coworker to delegate to', 'type': 'str'}}\n",
            "Tool Description: Delegate a specific task to one of the following coworkers: Researcher, Senior Writer\n",
            "The input to this tool should be the coworker, the task you want them to do, and ALL necessary context to execute the task, they know nothing about the task, so share absolute everything you know, don't reference things but instead explain them..\n",
            "Moving on then. I MUST either use a tool (use one at time) OR give my best final answer not both at the same time. When responding, I must use the following format:\n",
            "\n",
            "```\n",
            "Thought: you should always think about what to do\n",
            "Action: the action to take, should be one of [Delegate work to coworker, Ask question to coworker]\n",
            "Action Input: the input to the action, dictionary enclosed in curly braces\n",
            "Observation: the result of the action\n",
            "```\n",
            "This Thought/Action/Action Input/Result can repeat N times. Once I know the final answer, I must return the following format:\n",
            "\n",
            "```\n",
            "Thought: I now can give a great answer\n",
            "Final Answer: Your final answer must be the great and the most complete as possible, it must be outcome described\n",
            "\n",
            "```\u001b[00m\n",
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mResearcher\u001b[00m\n",
            "\u001b[95m## Task:\u001b[00m \u001b[92mCan you provide me with 5 interesting and diverse article ideas suitable for a general audience? The topics should be engaging and have the potential to be expanded into full articles.\u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mResearcher\u001b[00m\n",
            "\u001b[95m## Thought:\u001b[00m \u001b[92mOkay, I need to generate 5 diverse and interesting article ideas suitable for a general audience. I will use the search tool to find trending topics and then refine those into article ideas. I should aim for topics that can be expanded upon.\u001b[00m\n",
            "\u001b[95m## Using tool:\u001b[00m \u001b[92mSearch the internet with Serper\u001b[00m\n",
            "\u001b[95m## Tool Input:\u001b[00m \u001b[92m\n",
            "\"{\\\"search_query\\\": \\\"trending topics general interest\\\"}\"\u001b[00m\n",
            "\u001b[95m## Tool Output:\u001b[00m \u001b[92m\n",
            "{'searchParameters': {'q': 'trending topics general interest', 'type': 'search', 'num': 10, 'engine': 'google'}, 'organic': [{'title': 'Trending Now - Google Trends', 'link': 'https://trends.google.com/trending', 'snippet': 'All categories Autos and Vehicles Beauty and Fashion Business and Finance Climate Entertainment Food and Drink Games Health Hobbies and Leisure Jobs and ...', 'position': 1}, {'title': 'Top Trending Topics (January 2025)', 'link': 'https://explodingtopics.com/blog/trending-topics', 'snippet': 'Top Trending Topics (January 2025) · 1. AI Vocal Remover · 2. Boucle Bed · 3. AI Code Assistant · 4. CBG Gummies · 5. Bamboo Pajamas · 6. Claude AI · 7 ...', 'position': 2}, {'title': 'Popular and Trending Topics - Current & Controversial Issues', 'link': 'https://mclennan.libguides.com/issues/popular_issues', 'snippet': 'Race in America · ACLU · Asian Nation · BET: National News · Black Lives Matter · Christianity Today: Racism · Christian Science Monitor Electronic Edition · Dissent ...', 'position': 3}, {'title': 'Google Trends', 'link': 'https://trends.google.com/trends/', 'snippet': 'Search interest, past 24 hours. Explore. Why is trending? Search it. Dive deeper. Explore issues and events in detail. Curated by the Trends Data Team.', 'position': 4, 'sitelinks': [{'title': 'Trending Now', 'link': 'https://trends.google.com/trending'}, {'title': 'Trends TV', 'link': 'https://trends.google.com/tv/'}, {'title': 'Explore', 'link': 'https://trends.google.com/trends/explore?geo=IN&hl=en-US'}, {'title': 'Trends Help', 'link': 'https://support.google.com/trends/?hl=en'}]}, {'title': 'Current Events and Controversial Issues - Research Topic Ideas', 'link': 'https://libguides.umflint.edu/topics/current', 'snippet': 'Activism · Art as commentary · Early childhood development · Citizen scientists · Emergency manager law · Environmental health · Government regulations · Health care ...', 'position': 5}, {'title': 'What are the best group discussion topics? - Quora', 'link': 'https://www.quora.com/What-are-the-best-group-discussion-topics', 'snippet': \"1.India's impact in Global market 2.Should import from china be banned? 3.Role of social platform in today's life 4.Should National anthem be played in Cinema ...\", 'position': 6, 'sitelinks': [{'title': 'How to find a topic of interest - Quora', 'link': 'https://www.quora.com/How-do-I-find-a-topic-of-interest'}, {'title': 'How to choose a great general topic of interest that is juicy, add a ...', 'link': 'https://www.quora.com/How-do-you-choose-a-great-general-topic-of-interest-that-is-juicy-add-a-layer-specificity-by-obtaining-background-information-and-identify-additional-specific-LS-of-your-topic'}, {'title': 'What are the most searched general knowledge topics today? - Quora', 'link': 'https://www.quora.com/What-are-the-most-searched-general-knowledge-topics-today'}, {'title': 'Which are the best and trending topics for facts website related?', 'link': 'https://www.quora.com/Which-are-the-best-and-trending-topics-for-facts-website-related'}]}, {'title': 'Trending Topics: What Students Are Searching For In 2023 - Infobase', 'link': 'https://infobase.com/blog/trending-topics-what-students-are-searching-for-in-2023/', 'snippet': 'Climate Change · Study Skills & Critical Thinking · Social Media · Mental Health · Psychology, Stress, and Addiction · Abortion · Minimum Wage and ...', 'position': 7}, {'title': 'Research Topics | Pew Research Center', 'link': 'https://www.pewresearch.org/topics/', 'snippet': 'Research Topics ... Politics & Policy · International Affairs · Immigration & Migration · Race & Ethnicity · Religion · Age & Generations · Gender & LGBTQ.', 'position': 8, 'sitelinks': [{'title': 'Religion & Social Values', 'link': 'https://www.pewresearch.org/topic/religion/religion-social-values/'}, {'title': 'Other Topics', 'link': 'https://www.pewresearch.org/topic/other-topics/'}, {'title': 'Education', 'link': 'https://www.pewresearch.org/topic/other-topics/education/'}, {'title': 'Abortion', 'link': 'https://www.pewresearch.org/topic/politics-policy/political-issues/abortion/'}]}, {'title': 'Current Events Resources - Hot Topics, News by Topic, Global ...', 'link': 'https://www.thrall.org/current/', 'snippet': 'Births, Weddings, Celebrations; Classifieds; Education. Events & Public Programs; Food, Health, & Safety; Legal Notices & Government.', 'position': 9}, {'title': '1,700+ Easy Topics for Group Discussion With Your Students', 'link': 'https://www.thinkific.com/blog/topics-for-group-discussion/', 'snippet': 'Health and fitness; Interests and hobbies; Cooking and food; Creativity and innovation; Art and expression; Culture ...', 'position': 10}], 'peopleAlsoAsk': [{'question': 'What are the most googled topics?', 'snippet': 'Ranking\\nKeyword\\nSearch Intent\\n1\\nYouTube\\nNavigational\\n2\\nFacebook\\nNavigational\\n3\\nWhatsApp Web\\nNavigational\\n4\\nTranslate\\nNavigational, Transactional', 'title': 'Top 100 Google Searches (February 2025) - Exploding Topics', 'link': 'https://explodingtopics.com/blog/top-google-searches'}, {'question': 'What is the hottest topic in the news today?', 'snippet': \"TRENDING NEWS\\nThieves nab pricey bulldogs from a Colorado pet store after faking a seizure, sheriff says. ...\\nA whale caught in fishing nets has been freed off Poland's Baltic coast. ...\\nAmazon's new AI-powered Alexa promises to be your 'best friend in a digital world' for a monthly fee.\", 'title': \"Trending News | What's New Around the World - AP News\", 'link': 'https://apnews.com/hub/trending-news'}, {'question': 'What is the best topic for 2024?', 'snippet': \"HERE'S A ROUNDUP OF TRENDING SPEAKER TOPICS FOR 2024 THAT ADDRESS CURRENT CHALLENGES, EMERGING TECHNOLOGIES, AND SHIFTING CULTURAL DYNAMICS:\\n1\\nSustainability and Climate Solutions. ...\\n2\\nMental Health and Resilience. ...\\n3\\nDiversity, Equity, and Inclusion (DEI) ...\\n4\\nArtificial Intelligence and Ethics.\", 'title': 'Speaking Topics in Trend | 2024 - SpeakerHUB', 'link': 'https://speakerhubhq.medium.com/speaking-topics-in-trend-2024-48abebc14a2c'}, {'question': 'What is Google Trends interest?', 'snippet': 'What is Google Trends? Google Trends tells us what people are searching for, in real time. We can use this data to measure search interest in a particular topic, in a particular place, and at a particular time.', 'title': 'Basics of Google Trends', 'link': 'https://newsinitiative.withgoogle.com/resources/trainings/basics-of-google-trends/'}], 'relatedSearches': [{'query': 'Semrush'}, {'query': 'Google Trends'}, {'query': 'Hot topics in the news today'}, {'query': 'Trending searches today'}, {'query': 'Most popular trends right now'}, {'query': 'Top 10 most popular trends right now'}, {'query': 'Trending topics for students'}, {'query': 'Google Trends YouTube'}, {'query': 'Current trending topics on YouTube'}], 'credits': 1}\u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mResearcher\u001b[00m\n",
            "\u001b[95m## Thought:\u001b[00m \u001b[92mThought: Okay, there are some interesting things in here. I see AI, Climate Change, Mental Health, and DEI. I will refine those.\u001b[00m\n",
            "\u001b[95m## Using tool:\u001b[00m \u001b[92mSearch the internet with Serper\u001b[00m\n",
            "\u001b[95m## Tool Input:\u001b[00m \u001b[92m\n",
            "\"{\\\"search_query\\\": \\\"future of AI for everyday people\\\"}\"\u001b[00m\n",
            "\u001b[95m## Tool Output:\u001b[00m \u001b[92m\n",
            "{'searchParameters': {'q': 'future of AI for everyday people', 'type': 'search', 'num': 10, 'engine': 'google'}, 'organic': [{'title': 'Future of AI: Trends, Impacts, and Predictions - Simplilearn.com', 'link': 'https://www.simplilearn.com/future-of-artificial-intelligence-article', 'snippet': \"Discover AI's potential to reshape industries, jobs, and our daily lives. Explore what the future holds for AI and its impact on the world.\", 'position': 1}, {'title': 'What is the Future of AI in Everyday Life', 'link': 'https://www.canadianctb.ca/blog-and-news/what-is-the-future-of-ai-in-everyday-life', 'snippet': 'AI-powered technologies will become more integrated into our lives, making tasks easier, more efficient, and more personalized.', 'position': 2}, {'title': 'The Future of AI is Now - UC San Diego Today', 'link': 'https://today.ucsd.edu/story/the-future-of-ai-is-now', 'snippet': 'From ChatGPT to facial recognition, self-driving cars and virtual assistants such as Alexa and Siri, AI is already a part of our everyday lives.', 'position': 3}, {'title': 'What is Artificial Intelligence and How is it Shaping the Future? - SMU', 'link': 'https://www.smu.edu/meadows/newsandevents/news/2023/what-is-artificial-intelligence', 'snippet': 'While some may fear that AI will replace human jobs, the reality is that it will likely create new roles that most people have not yet imagined.', 'position': 4}, {'title': 'The Rise of Artificial Intelligence in Everyday Life: Shaping the Future', 'link': 'https://www.linkedin.com/pulse/rise-artificial-intelligence-everyday-life-shaping-future--9harc', 'snippet': 'Increased Efficiency: Repetitive duties can be automated by AI, freeing humans up to focus on more significant or imaginative activities.', 'position': 5}, {'title': 'When will the AI fad die out? : r/compsci - Reddit', 'link': 'https://www.reddit.com/r/compsci/comments/1du985l/when_will_the_ai_fad_die_out/', 'snippet': 'Eventually it will either die out or become mainstream. AI will likely become just part of every day technology and it will simply become a ...', 'position': 6}, {'title': 'Enhancing Everyday Life: How AI is Revolutionizing Your Daily ...', 'link': 'https://www.morgan.edu/ceamls/news/enhancing-everyday-life-how-ai-is-revolutionizing-your-daily-experience', 'snippet': 'By streamlining routine tasks, personalizing experiences, revolutionizing healthcare, enhancing communication, and fueling creativity, AI is ...', 'position': 7}, {'title': 'Has AI Improved Your Everyday life? : r/ArtificialInteligence - Reddit', 'link': 'https://www.reddit.com/r/ArtificialInteligence/comments/16ofae7/has_ai_improved_your_everyday_life/', 'snippet': 'For example, AI-powered speech recognition can enable people with mobility impairments to control devices, and AI-based image recognition can ...', 'position': 8}, {'title': '3. Improvements ahead: How humans and AI might evolve together ...', 'link': 'https://www.pewresearch.org/internet/2018/12/10/improvements-ahead-how-humans-and-ai-might-evolve-together-in-the-next-decade/', 'snippet': 'AI will be integrated into most aspects of life, producing new efficiencies and enhancing human capacities.', 'position': 9, 'sitelinks': [{'title': 'Ai Will Be Integrated Into...', 'link': 'https://www.pewresearch.org/internet/2018/12/10/improvements-ahead-how-humans-and-ai-might-evolve-together-in-the-next-decade/#:~:text=AI%20will%20be%20integrated%20into%20most%20aspects%20of%20life%2C%20producing%20new%20efficiencies%20and%20enhancing%20human%20capacities,-Many%20of%20the%20leading%20experts'}, {'title': 'Ai Will Optimize And Augment...', 'link': 'https://www.pewresearch.org/internet/2018/12/10/improvements-ahead-how-humans-and-ai-might-evolve-together-in-the-next-decade/#:~:text=AI%20will%20optimize%20and%20augment%20people%27s%20lives,-The%20hopeful%20experts%20in%20this'}, {'title': 'The Future Of Work: Some...', 'link': 'https://www.pewresearch.org/internet/2018/12/10/improvements-ahead-how-humans-and-ai-might-evolve-together-in-the-next-decade/#:~:text=The%20future%20of%20work%3A%20Some%20predict%20new%20work%20will%20emerge%20or%20solutions%20will%20be%20found%2C%20while%20others%20have%20deep%20concerns%20about%20massive%20job%20losses%20and%20an%20unraveling%20society,-A%20number%20of%20expert%20insights'}]}], 'peopleAlsoAsk': [{'question': 'What is the future of humans with artificial intelligence?', 'snippet': 'The productivity of artificial intelligence may boost our workplaces, which will benefit people by enabling them to do more work. As the future of AI replaces tedious or dangerous tasks, the human workforce is liberated to focus on tasks for which they are more equipped, such as those requiring creativity and empathy.\\nDec 16, 2024', 'title': 'Future of AI: Trends, Impacts, and Predictions - Simplilearn.com', 'link': 'https://www.simplilearn.com/future-of-artificial-intelligence-article'}, {'question': 'How can AI be used in everyday life?', 'snippet': '1.\\n1\\nVirtual assistants like Siri and Alexa.\\n2\\nRecommendation systems used in e-commerce platforms.\\n3\\nFraud detection in financial institutions.\\n4\\nAutonomous vehicles.\\n5\\nNLP for chatbots and customer service.\\n6\\nImage and facial recognition in security systems.\\n7\\nMedical diagnosis and healthcare systems.', 'title': 'Top Artificial Intelligence Applications | AI Applications 2025', 'link': 'https://www.simplilearn.com/tutorials/artificial-intelligence-tutorial/artificial-intelligence-applications'}, {'question': 'How is AI quietly changing everyday life?', 'snippet': 'These AI-driven assistants are getting smarter, helping you set reminders, order groceries, and even control your smart home devices. Imagine telling your assistant to set the perfect ambiance for movie night — adjusting the lights, playing your favourite playlist, and even setting the temperature just right.', 'title': 'How AI is Quietly Transforming Your Everyday Life | by Sumit Kumar', 'link': 'https://medium.com/@sumittatawat/how-ai-is-quietly-transforming-your-everyday-life-de4facb66276'}, {'question': 'Will AI replace humans entirely in the future?', 'snippet': \"By embracing responsible AI development, establishing ethical frameworks, and implementing effective regulations, we can ensure that AI remains a powerful tool that serves humanity's interests rather than becoming a force of domination. So, the answer to the question- Will AI replace humans?, is undoubtedly a BIG NO.\", 'title': 'Can AI replace Human Intelligence? - Antino', 'link': 'https://www.antino.com/blog/why-ai-never-replace-humans'}], 'relatedSearches': [{'query': 'Future of AI examples'}, {'query': 'Artificial intelligence and the future of humans'}, {'query': \"Future of Artificial intelligence'' PDF\"}, {'query': 'Future of ai for everyday people essay'}, {'query': 'How artificial intelligence will change the future Essay'}, {'query': 'How will AI change the future of work'}, {'query': 'Future of AI in education'}, {'query': 'Future of artificial intelligence ppt'}], 'credits': 1}\u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mResearcher\u001b[00m\n",
            "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
            "Here are 5 diverse and interesting article ideas suitable for a general audience:\n",
            "\n",
            "1.  **\"AI Assistants: Friend or Foe?\"**: Explores the increasing integration of AI assistants like Alexa, Siri, and Google Assistant into our daily lives. It discusses the benefits of convenience and automation but also delves into potential privacy concerns, data security risks, and the impact on human interaction. This can be expanded with expert interviews and real-life user experiences.\n",
            "\n",
            "2.  **\"Beyond the Headlines: Understanding Climate Anxiety and Finding Hope\"**: Addresses the growing phenomenon of climate anxiety and its impact on mental health. The article would provide practical strategies for coping with eco-related stress, focusing on actions individuals can take to make a difference and fostering a sense of hope and resilience. Includes tips for engaging in climate activism, reducing carbon footprint, and connecting with nature.\n",
            "\n",
            "3.  **\"The Gig Economy Game: How to Thrive in the Age of Freelancing\"**: Offers a practical guide for navigating the challenges and opportunities of the gig economy. Topics covered include finding lucrative freelance work, managing finances, building a personal brand, and maintaining work-life balance. Also could include interviews with successful freelancers across different industries.\n",
            "\n",
            "4.  **\"The Power of Lifelong Learning: Staying Relevant in a Rapidly Changing World\"**: Emphasizes the importance of continuous learning and skill development in today's fast-paced environment. The article could showcase accessible learning resources, highlight the benefits of acquiring new skills, and inspire readers to embrace a growth mindset. Examples of successful career transitions through upskilling could be incorporated.\n",
            "\n",
            "5.  **\"Beyond Representation: What True Inclusion Really Means\"**: Goes beyond surface-level discussions of diversity to explore the complexities of creating truly inclusive environments in workplaces, schools, and communities. The article would delve into topics like unconscious bias, microaggressions, and systemic inequalities, offering actionable steps for fostering a sense of belonging for everyone. Real-world examples of successful inclusion initiatives and the positive impact they have had would be highlighted.\u001b[00m\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mProject Manager\u001b[00m\n",
            "\u001b[95m## Using tool:\u001b[00m \u001b[92mAsk question to coworker\u001b[00m\n",
            "\u001b[95m## Tool Input:\u001b[00m \u001b[92m\n",
            "\"{\\\"question\\\": \\\"Can you provide me with 5 interesting and diverse article ideas suitable for a general audience? The topics should be engaging and have the potential to be expanded into full articles.\\\", \\\"context\\\": \\\"I am working on a project to generate article ideas, and I need your help to come up with some compelling topics that would appeal to a broad readership.\\\", \\\"coworker\\\": \\\"Researcher\\\"}\"\u001b[00m\n",
            "\u001b[95m## Tool Output:\u001b[00m \u001b[92m\n",
            "Here are 5 diverse and interesting article ideas suitable for a general audience:\n",
            "\n",
            "1.  **\"AI Assistants: Friend or Foe?\"**: Explores the increasing integration of AI assistants like Alexa, Siri, and Google Assistant into our daily lives. It discusses the benefits of convenience and automation but also delves into potential privacy concerns, data security risks, and the impact on human interaction. This can be expanded with expert interviews and real-life user experiences.\n",
            "\n",
            "2.  **\"Beyond the Headlines: Understanding Climate Anxiety and Finding Hope\"**: Addresses the growing phenomenon of climate anxiety and its impact on mental health. The article would provide practical strategies for coping with eco-related stress, focusing on actions individuals can take to make a difference and fostering a sense of hope and resilience. Includes tips for engaging in climate activism, reducing carbon footprint, and connecting with nature.\n",
            "\n",
            "3.  **\"The Gig Economy Game: How to Thrive in the Age of Freelancing\"**: Offers a practical guide for navigating the challenges and opportunities of the gig economy. Topics covered include finding lucrative freelance work, managing finances, building a personal brand, and maintaining work-life balance. Also could include interviews with successful freelancers across different industries.\n",
            "\n",
            "4.  **\"The Power of Lifelong Learning: Staying Relevant in a Rapidly Changing World\"**: Emphasizes the importance of continuous learning and skill development in today's fast-paced environment. The article could showcase accessible learning resources, highlight the benefits of acquiring new skills, and inspire readers to embrace a growth mindset. Examples of successful career transitions through upskilling could be incorporated.\n",
            "\n",
            "5.  **\"Beyond Representation: What True Inclusion Really Means\"**: Goes beyond surface-level discussions of diversity to explore the complexities of creating truly inclusive environments in workplaces, schools, and communities. The article would delve into topics like unconscious bias, microaggressions, and systemic inequalities, offering actionable steps for fostering a sense of belonging for everyone. Real-world examples of successful inclusion initiatives and the positive impact they have had would be highlighted.\u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mProject Manager\u001b[00m\n",
            "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
            "*   **Article Idea:** \"AI Assistants: Friend or Foe?\"\n",
            "\n",
            "    **Captivating Paragraph:** Imagine a world where your every command is anticipated, your schedule flawlessly managed, and information instantly at your fingertips. This is the promise of AI assistants like Alexa, Siri, and Google Assistant, now woven into the fabric of our daily lives. But behind the veneer of convenience lurks a web of potential privacy breaches, data security vulnerabilities, and the creeping erosion of genuine human connection. Are we trading our autonomy for ease, and what is the true cost of this digital bargain?\n",
            "\n",
            "    **Notes:** This article can explore the ethical implications of AI, interview experts on data privacy, and feature personal anecdotes of people's experiences with AI assistants.\n",
            "\n",
            "*   **Article Idea:** \"Beyond the Headlines: Understanding Climate Anxiety and Finding Hope\"\n",
            "\n",
            "    **Captivating Paragraph:** The weight of a warming planet bears down on us, a constant stream of dire headlines fueling a growing epidemic of climate anxiety. But beyond the fear and despair lies the power to act, to reclaim our hope and forge a more sustainable future. This article dives deep into the psychological impact of climate change, offering practical tools to cope with eco-related stress and empowering readers to become agents of positive change, one small step at a time.\n",
            "\n",
            "    **Notes:** This article could include interviews with climate psychologists, showcase successful grassroots environmental initiatives, and offer actionable tips for reducing your carbon footprint.\n",
            "\n",
            "*   **Article Idea:** \"The Gig Economy Game: How to Thrive in the Age of Freelancing\"\n",
            "\n",
            "    **Captivating Paragraph:** The traditional 9-to-5 is fading, replaced by a dynamic landscape of freelancers, contractors, and independent consultants. The gig economy offers unprecedented freedom and flexibility, but also presents a unique set of challenges. From securing consistent work to managing finances and maintaining work-life balance, this article provides a roadmap for navigating the new world of work and building a thriving freelance career.\n",
            "\n",
            "    **Notes:** This article could feature interviews with successful freelancers, offer practical tips for managing finances and taxes, and explore the legal and ethical considerations of the gig economy.\n",
            "\n",
            "*   **Article Idea:** \"The Power of Lifelong Learning: Staying Relevant in a Rapidly Changing World\"\n",
            "\n",
            "    **Captivating Paragraph:** In an era of relentless technological advancement, the ability to learn and adapt is no longer a luxury, but a necessity. The skills that are valued today may be obsolete tomorrow, making lifelong learning the key to staying relevant and thriving in a rapidly changing world. This article explores the transformative power of continuous learning, showcasing accessible resources and inspiring readers to embrace a growth mindset and unlock their full potential.\n",
            "\n",
            "    **Notes:** This article could feature interviews with individuals who have successfully reinvented their careers through learning, highlight innovative online learning platforms, and offer practical tips for incorporating learning into your daily routine.\n",
            "\n",
            "*   **Article Idea:** \"Beyond Representation: What True Inclusion Really Means\"\n",
            "\n",
            "    **Captivating Paragraph:** We celebrate diversity, but are we truly inclusive? True inclusion goes beyond mere representation, demanding a deeper examination of unconscious biases, systemic inequalities, and the subtle microaggressions that can marginalize individuals and undermine a sense of belonging. This article delves into the complexities of creating truly inclusive environments in workplaces, schools, and communities, offering actionable strategies for fostering equity, empathy, and respect for all.\n",
            "\n",
            "    **Notes:** This article could feature interviews with diversity and inclusion experts, showcase successful inclusion initiatives in different organizations, and offer practical tips for addressing unconscious bias and promoting cultural sensitivity.\u001b[00m\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "*   **Article Idea:** \"AI Assistants: Friend or Foe?\"\n\n    **Captivating Paragraph:** Imagine a world where your every command is anticipated, your schedule flawlessly managed, and information instantly at your fingertips. This is the promise of AI assistants like Alexa, Siri, and Google Assistant, now woven into the fabric of our daily lives. But behind the veneer of convenience lurks a web of potential privacy breaches, data security vulnerabilities, and the creeping erosion of genuine human connection. Are we trading our autonomy for ease, and what is the true cost of this digital bargain?\n\n    **Notes:** This article can explore the ethical implications of AI, interview experts on data privacy, and feature personal anecdotes of people's experiences with AI assistants.\n\n*   **Article Idea:** \"Beyond the Headlines: Understanding Climate Anxiety and Finding Hope\"\n\n    **Captivating Paragraph:** The weight of a warming planet bears down on us, a constant stream of dire headlines fueling a growing epidemic of climate anxiety. But beyond the fear and despair lies the power to act, to reclaim our hope and forge a more sustainable future. This article dives deep into the psychological impact of climate change, offering practical tools to cope with eco-related stress and empowering readers to become agents of positive change, one small step at a time.\n\n    **Notes:** This article could include interviews with climate psychologists, showcase successful grassroots environmental initiatives, and offer actionable tips for reducing your carbon footprint.\n\n*   **Article Idea:** \"The Gig Economy Game: How to Thrive in the Age of Freelancing\"\n\n    **Captivating Paragraph:** The traditional 9-to-5 is fading, replaced by a dynamic landscape of freelancers, contractors, and independent consultants. The gig economy offers unprecedented freedom and flexibility, but also presents a unique set of challenges. From securing consistent work to managing finances and maintaining work-life balance, this article provides a roadmap for navigating the new world of work and building a thriving freelance career.\n\n    **Notes:** This article could feature interviews with successful freelancers, offer practical tips for managing finances and taxes, and explore the legal and ethical considerations of the gig economy.\n\n*   **Article Idea:** \"The Power of Lifelong Learning: Staying Relevant in a Rapidly Changing World\"\n\n    **Captivating Paragraph:** In an era of relentless technological advancement, the ability to learn and adapt is no longer a luxury, but a necessity. The skills that are valued today may be obsolete tomorrow, making lifelong learning the key to staying relevant and thriving in a rapidly changing world. This article explores the transformative power of continuous learning, showcasing accessible resources and inspiring readers to embrace a growth mindset and unlock their full potential.\n\n    **Notes:** This article could feature interviews with individuals who have successfully reinvented their careers through learning, highlight innovative online learning platforms, and offer practical tips for incorporating learning into your daily routine.\n\n*   **Article Idea:** \"Beyond Representation: What True Inclusion Really Means\"\n\n    **Captivating Paragraph:** We celebrate diversity, but are we truly inclusive? True inclusion goes beyond mere representation, demanding a deeper examination of unconscious biases, systemic inequalities, and the subtle microaggressions that can marginalize individuals and undermine a sense of belonging. This article delves into the complexities of creating truly inclusive environments in workplaces, schools, and communities, offering actionable strategies for fostering equity, empathy, and respect for all.\n\n    **Notes:** This article could feature interviews with diversity and inclusion experts, showcase successful inclusion initiatives in different organizations, and offer practical tips for addressing unconscious bias and promoting cultural sensitivity."
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Advance Tools"
      ],
      "metadata": {
        "id": "RuhYj5rQlCLG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel, Field\n",
        "\n",
        "class TeacherAssignmentOutPut(BaseModel):\n",
        "  score :int  = Field(..., description=\"student assignment score\")\n",
        "  feedback : str = Field(..., description=\"teacher feedback\")\n",
        "  question : str = Field(..., description=\"question\")\n",
        "  answer : str = Field(..., description=\"python code for markdown format\")"
      ],
      "metadata": {
        "id": "7ni_Ka-deeMe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "from crewai import Agent\n",
        "from crewai_tools import CodeInterpreterTool\n",
        "from crewai import Task, Crew, Process\n",
        "\n",
        "teacher = Agent(\n",
        "    role=\"AI teacher\",\n",
        "    goal=\"you are Agentic AI teacher you have to check python assignment code submission.\",\n",
        "    backstory=\"you have to check student python code submission.\",\n",
        "    tools=[CodeInterpreterTool()],\n",
        "    llm=llm1\n",
        ")\n",
        "\n",
        "assignment_check = Task(\n",
        "    description=\"you are Agentic AI teacher you have to check python assignment code submission. question: '''{qestion}''' student solution : '''{solution}''' \",\n",
        "    expected_output=\"final code is runing, assign number between 1-10\",\n",
        "    output_pydantic=TeacherAssignmentOutPut,\n",
        "    agent=teacher # Added the missing agent here\n",
        ")\n",
        "\n",
        "\n",
        "crew = Crew(\n",
        "    agents=[teacher],\n",
        "    tasks=[assignment_check],\n",
        "    process=Process.sequential,\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "question = \"create function add two numbers\"\n",
        "\n",
        "solution = \"\"\"\n",
        "def add_two_number(num1 : int , num2 : int):\n",
        "  return num1 + num2\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "result = crew.kickoff(inputs={\n",
        "    \"qestion\": question,\n",
        "    \"solution\" : solution\n",
        "})\n",
        "\n",
        "print(result)"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AsEHDn2eogrp",
        "outputId": "fffaad61-74a5-4a20-ff87-f7184cc16293"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:opentelemetry.trace:Overriding of current TracerProvider is not allowed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mAI teacher\u001b[00m\n",
            "\u001b[95m## Task:\u001b[00m \u001b[92myou are Agentic AI teacher you have to check python assignment code submission. question: '''create function add two numbers''' student solution : '''\n",
            "def add_two_number(num1 : int , num2 : int):\n",
            "  return num1 + num2\n",
            "\n",
            "''' \u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mAI teacher\u001b[00m\n",
            "\u001b[95m## Using tool:\u001b[00m \u001b[92mCode Interpreter\u001b[00m\n",
            "\u001b[95m## Tool Input:\u001b[00m \u001b[92m\n",
            "\"{\\\"code\\\": \\\"def add_two_number(num1 : int , num2 : int):\\\\n  return num1 + num2\\\\n\\\\nprint(add_two_number(5, 3))\\\", \\\"libraries_used\\\": []}\"\u001b[00m\n",
            "\u001b[95m## Tool Output:\u001b[00m \u001b[92m\n",
            "\n",
            "I encountered an error while trying to use the tool. This was the error: Error while fetching server API version: ('Connection aborted.', FileNotFoundError(2, 'No such file or directory')).\n",
            " Tool Code Interpreter accepts these inputs: Tool Name: Code Interpreter\n",
            "Tool Arguments: {'code': {'description': 'Python3 code used to be interpreted in the Docker container. ALWAYS PRINT the final result and the output of the code', 'type': 'str'}, 'libraries_used': {'description': 'List of libraries used in the code with proper installing names separated by commas. Example: numpy,pandas,beautifulsoup4', 'type': 'list[str]'}}\n",
            "Tool Description: Interprets Python3 code strings with a final print statement..\n",
            "Moving on then. I MUST either use a tool (use one at time) OR give my best final answer not both at the same time. When responding, I must use the following format:\n",
            "\n",
            "```\n",
            "Thought: you should always think about what to do\n",
            "Action: the action to take, should be one of [Code Interpreter]\n",
            "Action Input: the input to the action, dictionary enclosed in curly braces\n",
            "Observation: the result of the action\n",
            "```\n",
            "This Thought/Action/Action Input/Result can repeat N times. Once I know the final answer, I must return the following format:\n",
            "\n",
            "```\n",
            "Thought: I now can give a great answer\n",
            "Final Answer: Your final answer must be the great and the most complete as possible, it must be outcome described\n",
            "\n",
            "```\u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mAI teacher\u001b[00m\n",
            "\u001b[95m## Using tool:\u001b[00m \u001b[92mCode Interpreter\u001b[00m\n",
            "\u001b[95m## Tool Input:\u001b[00m \u001b[92m\n",
            "\"{\\\"code\\\": \\\"def add_two_number(num1 : int , num2 : int):\\\\n  return num1 + num2\\\\n\\\\nprint(add_two_number(5, 3))\\\", \\\"libraries_used\\\": []}\"\u001b[00m\n",
            "\u001b[95m## Tool Output:\u001b[00m \u001b[92m\n",
            "\n",
            "I encountered an error while trying to use the tool. This was the error: Error while fetching server API version: ('Connection aborted.', FileNotFoundError(2, 'No such file or directory')).\n",
            " Tool Code Interpreter accepts these inputs: Tool Name: Code Interpreter\n",
            "Tool Arguments: {'code': {'description': 'Python3 code used to be interpreted in the Docker container. ALWAYS PRINT the final result and the output of the code', 'type': 'str'}, 'libraries_used': {'description': 'List of libraries used in the code with proper installing names separated by commas. Example: numpy,pandas,beautifulsoup4', 'type': 'list[str]'}}\n",
            "Tool Description: Interprets Python3 code strings with a final print statement..\n",
            "Moving on then. I MUST either use a tool (use one at time) OR give my best final answer not both at the same time. When responding, I must use the following format:\n",
            "\n",
            "```\n",
            "Thought: you should always think about what to do\n",
            "Action: the action to take, should be one of [Code Interpreter]\n",
            "Action Input: the input to the action, dictionary enclosed in curly braces\n",
            "Observation: the result of the action\n",
            "```\n",
            "This Thought/Action/Action Input/Result can repeat N times. Once I know the final answer, I must return the following format:\n",
            "\n",
            "```\n",
            "Thought: I now can give a great answer\n",
            "Final Answer: Your final answer must be the great and the most complete as possible, it must be outcome described\n",
            "\n",
            "```\u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mAI teacher\u001b[00m\n",
            "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
            "{\n",
            "  \"score\": 9,\n",
            "  \"feedback\": \"The code is correct and defines a function that adds two numbers. The type hints are a good addition. A small improvement could be adding a docstring to explain what the function does.\",\n",
            "  \"question\": \"create function add two numbers\",\n",
            "  \"answer\": \"def add_two_number(num1 : int , num2 : int):\\n  return num1 + num2\"\n",
            "}\u001b[00m\n",
            "\n",
            "\n",
            "score=9 feedback='The code is correct and defines a function that adds two numbers. The type hints are a good addition. A small improvement could be adding a docstring to explain what the function does.' question='create function add two numbers' answer='def add_two_number(num1 : int , num2 : int):\\n  return num1 + num2'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result.to_dict()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CTDw4geAnxIA",
        "outputId": "0cf0ece5-fbb3-4721-85f2-7f53b989c193"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'score': 9,\n",
              " 'feedback': 'The code is correct and defines a function that adds two numbers. The type hints are a good addition. A small improvement could be adding a docstring to explain what the function does.',\n",
              " 'question': 'create function add two numbers',\n",
              " 'answer': 'def add_two_number(num1 : int , num2 : int):\\n  return num1 + num2'}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for k,v in result.to_dict().items():\n",
        "  print(str(\"*\"*10) + str(k) + str(\"*\"*10))\n",
        "  display(v)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "id": "jk9bcz1hrCer",
        "outputId": "173966b9-5cfd-4c9f-97ad-767d4a3cd163"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**********score**********\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**********feedback**********\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\"The function correctly adds two numbers.  Consider adding docstrings for better readability and to explain the function's purpose.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**********question**********\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'create function add two numbers'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**********answer**********\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'def add_two_number(num1, num2):\\n  return num1 + num2\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "W78nXiRdtUxn"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}