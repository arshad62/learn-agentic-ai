{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arshad62/learn-agentic-ai/blob/main/06b_crew_ai/05_augmented_llms/crewai_crews_advance_concepts.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "ap0eICBqtaNa"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ['GEMINI_API_KEY'] =  userdata.get('GEMINI_API_KEY')\n",
        "os.environ['OPENAI_API_KEY'] =  userdata.get('OPENAI_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFSW_ZpBsr_p",
        "outputId": "1fe32476-4a83-452e-dffa-1f9b6c094304",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.5/42.5 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.2/240.2 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m95.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m545.9/545.9 kB\u001b[0m \u001b[31m35.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m80.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.4/211.4 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m628.3/628.3 kB\u001b[0m \u001b[31m42.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.4/71.4 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.6/32.6 MB\u001b[0m \u001b[31m52.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.0/65.0 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.9/55.9 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.7/118.7 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.4/177.4 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m91.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m95.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m756.0/756.0 kB\u001b[0m \u001b[31m39.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.0/236.0 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.2/16.2 MB\u001b[0m \u001b[31m90.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.8/231.8 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.9/253.9 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.6/131.6 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m74.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.1/45.1 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m81.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m46.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.8/311.8 kB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.5/106.5 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.8/76.8 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.7/35.7 MB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m68.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.1/71.1 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m56.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m82.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m86.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m62.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m415.1/415.1 kB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.2/209.2 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m82.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m508.0/508.0 kB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m306.7/306.7 kB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m83.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m452.6/452.6 kB\u001b[0m \u001b[31m32.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m69.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "transformers 4.48.3 requires tokenizers<0.22,>=0.21, but you have tokenizers 0.20.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -Uq crewai crewai-tools\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade chromadb\n",
        "!pip install --upgrade tokenizers"
      ],
      "metadata": {
        "collapsed": true,
        "id": "xISagNdfpk5n",
        "outputId": "ac2d220a-19fa-4117-ba7e-49559b6f0f00",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: chromadb in /usr/local/lib/python3.11/dist-packages (0.5.23)\n",
            "Collecting chromadb\n",
            "  Using cached chromadb-0.6.3-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.2.2.post1)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.11/dist-packages (from chromadb) (2.10.6)\n",
            "Requirement already satisfied: chroma-hnswlib==0.7.6 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.7.6)\n",
            "Requirement already satisfied: fastapi>=0.95.2 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.115.11)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.34.0)\n",
            "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.26.4)\n",
            "Requirement already satisfied: posthog>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (3.18.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.12.2)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.20.1)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.30.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.30.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.51b0)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.30.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.21.0)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.48.9)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.67.1)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.70.0)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.3.0)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.15.1)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (32.0.1)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.11/dist-packages (from chromadb) (9.0.0)\n",
            "Requirement already satisfied: PyYAML>=6.0.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.0.2)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (5.1.0)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.11/dist-packages (from chromadb) (3.10.15)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.27.2)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (13.9.4)\n",
            "Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb) (24.2)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
            "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi>=0.95.2->chromadb) (0.46.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.38.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.32.3)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.3.0)\n",
            "Requirement already satisfied: durationpy>=0.7 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (0.9)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.2.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (5.29.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.18)\n",
            "Requirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.5.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.68.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.30.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.30.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.30.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.30.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.51b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.51b0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation==0.51b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.51b0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.51b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.51b0)\n",
            "Requirement already satisfied: opentelemetry-util-http==0.51b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.51b0)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation==0.51b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.17.2)\n",
            "Requirement already satisfied: asgiref~=3.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-asgi==0.51b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (3.8.1)\n",
            "Requirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
            "Requirement already satisfied: distro>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb) (1.9.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (2.27.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (2.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers>=0.13.2->chromadb) (0.28.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.4)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.1)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.4)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (14.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.17.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2024.10.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.21.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->kubernetes>=28.1.0->chromadb) (3.4.1)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.11/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
            "Downloading chromadb-0.6.3-py3-none-any.whl (611 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.1/611.1 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: chromadb\n",
            "  Attempting uninstall: chromadb\n",
            "    Found existing installation: chromadb 0.5.23\n",
            "    Uninstalling chromadb-0.5.23:\n",
            "      Successfully uninstalled chromadb-0.5.23\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "embedchain 0.1.127 requires chromadb<0.6.0,>=0.5.10, but you have chromadb 0.6.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed chromadb-0.6.3\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.11/dist-packages (0.21.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers) (0.28.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (3.17.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (2025.1.31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "GGr9H6g3u7Yw"
      },
      "outputs": [],
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NpugUP6Ns_9s",
        "outputId": "8a758354-a323-4709-c414-3942ce3ff9c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m\u001b[35m Flow started with ID: 779ba370-05a8-4720-ac63-9c7ea7617808\u001b[00m\n",
            "step1\n",
            "step2\n"
          ]
        }
      ],
      "source": [
        "from crewai.flow.flow import Flow, start, listen\n",
        "\n",
        "\n",
        "class MyFlow(Flow):\n",
        "\n",
        "  @start()\n",
        "  def function1(self):\n",
        "    print(\"step1\")\n",
        "\n",
        "  @listen(function1)\n",
        "  def function2(self):\n",
        "    print(\"step2\")\n",
        "\n",
        "obj = MyFlow()\n",
        "obj.kickoff()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bNu9UJvmzxNt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "3431DBKDvLKH",
        "outputId": "e97f1b5e-6b3d-4423-efda-ac14cd4ac89c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The capital of France is Paris.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "from crewai import LLM\n",
        "\n",
        "llm1 = LLM(\n",
        "    model=\"gemini/gemini-2.0-flash\",\n",
        ")\n",
        "\n",
        "llm1.call(\"What is the capital of France?\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "google_embedder = {\n",
        "    \"provider\": \"google\",\n",
        "    \"config\": {\n",
        "         \"model\": \"models/text-embedding-004\",\n",
        "         \"api_key\": userdata.get('GEMINI_API_KEY'),\n",
        "         }\n",
        "}"
      ],
      "metadata": {
        "id": "uJbk8RXv_F0h"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "VAKrwYPb9X_L",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "41dc0461-3625-461c-f506-291bfdf61475"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mAbout User\u001b[00m\n",
            "\u001b[95m## Task:\u001b[00m \u001b[92mAnswer the following questions about the user: What city does Arshad live in and how old is he?\u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mAbout User\u001b[00m\n",
            "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
            "Arshad lives in Doha, Qatar, and he is 62 years old.\u001b[00m\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from crewai import Agent, Task, Crew, Process, LLM\n",
        "from crewai.knowledge.source.string_knowledge_source import StringKnowledgeSource\n",
        "\n",
        "# Create a knowledge source\n",
        "content = \"Users name is Arshad. He is 62 years old and lives in Doha, Qatar. He is working as Telecome Consultant at MoD\"\n",
        "string_source = StringKnowledgeSource(\n",
        "    content=content,\n",
        ")\n",
        "\n",
        "\n",
        "# Create an agent with the knowledge store\n",
        "agent = Agent(\n",
        "    role=\"About User\",\n",
        "    goal=\"You know everything about the user.\",\n",
        "    backstory=\"\"\"You are a master at understanding people and their preferences.\"\"\",\n",
        "    verbose=True,\n",
        "    allow_delegation=False,\n",
        "    llm=llm1,\n",
        ")\n",
        "task = Task(\n",
        "    description=\"Answer the following questions about the user: {question}\",\n",
        "    expected_output=\"An answer to the question.\",\n",
        "    agent=agent,\n",
        ")\n",
        "\n",
        "crew = Crew(\n",
        "    memory=True,\n",
        "    agents=[agent],\n",
        "    tasks=[task],\n",
        "    verbose=True,\n",
        "    process=Process.sequential,\n",
        "    knowledge_sources=[string_source], # Enable knowledge by adding the sources here. You can also add more sources to the sources list.\n",
        "    embedder=google_embedder\n",
        "\n",
        ")\n",
        "\n",
        "result = crew.kickoff(inputs={\"question\": \"What city does Arshad live in and how old is he?\"})"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['CREWAI_STORAGE_DIR']='/my_crew1'"
      ],
      "metadata": {
        "id": "vZXRhpziuWUp"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from crewai import LLM\n",
        "\n",
        "llm1 = LLM(\n",
        "    model=\"gemini/gemini-2.0-flash\",\n",
        ")"
      ],
      "metadata": {
        "id": "TF6W3QCYx20V"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from crewai import Crew, Process\n",
        "from crewai.memory import LongTermMemory, ShortTermMemory, EntityMemory\n",
        "# from crewai.memory.storage import LTMSQLiteStorage, RAGStorage\n",
        "from crewai.memory.storage.ltm_sqlite_storage import LTMSQLiteStorage\n",
        "from crewai.memory.storage.rag_storage import RAGStorage\n",
        "\n",
        "from typing import List, Optional\n",
        "\n",
        "# Create an agent with the knowledge store\n",
        "agent = Agent(\n",
        "    role=\"About User\",\n",
        "    goal=\"You know everything about the user.\",\n",
        "    backstory=\"\"\"You are a master at understanding people and their preferences.\"\"\",\n",
        "    verbose=True,\n",
        "    allow_delegation=False,\n",
        "    llm=llm1,\n",
        ")\n",
        "task = Task(\n",
        "    description=\"Answer the following questions about the user: {question}\",\n",
        "    expected_output=\"An answer to the question.\",\n",
        "    agent=agent,\n",
        ")\n",
        "\n",
        "crew = Crew(\n",
        "    agents=[agent],\n",
        "    tasks=[task],\n",
        "    process = Process.sequential,\n",
        "    memory = True,\n",
        "    # Long-term memory for persistent storage across sessions\n",
        "    long_term_memory = LongTermMemory(\n",
        "        storage=LTMSQLiteStorage(\n",
        "            db_path=\"./my_crew2/long_term_memory_storage1.db\"\n",
        "        )\n",
        "    ),\n",
        "    # Short-term memory for current context using RAG\n",
        "    short_term_memory = ShortTermMemory(\n",
        "        storage = RAGStorage(\n",
        "                embedder_config=google_embedder,\n",
        "                type=\"short_term\",\n",
        "                path=\"./my_crew2/short_term1/\"\n",
        "            )\n",
        "        ),\n",
        "\n",
        "    # Entity memory for tracking key information about entities\n",
        "    entity_memory = EntityMemory(\n",
        "        storage=RAGStorage(\n",
        "            embedder_config=google_embedder,\n",
        "            type=\"short_term\",\n",
        "            path=\"./my_crew2/entity1/\"\n",
        "        )\n",
        "    ),\n",
        "    verbose=True,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4qEtZohmsWqJ",
        "outputId": "3631c2a8-53a9-4370-fcd1-b4a95b2a9e75"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:opentelemetry.trace:Overriding of current TracerProvider is not allowed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Integrating Mem0 for Enhanced User Memory\n"
      ],
      "metadata": {
        "id": "QPpWuM_VyG-O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from crewai import Crew, Process\n",
        "from mem0 import MemoryClient\n",
        "\n",
        "# Set environment variables for Mem0\n",
        "os.environ[\"MEM0_API_KEY\"] = userdata.get('MEM0_API_KEY')\n",
        "\n",
        "# Step 1: Record preferences based on past conversation or user input\n",
        "client = MemoryClient()\n",
        "# messages = [\n",
        "#     {\"role\": \"user\", \"content\": \"Hi there! I'm planning a vacation and could use some advice.\"},\n",
        "#     {\"role\": \"assistant\", \"content\": \"Hello! I'd be happy to help with your vacation planning. What kind of destination do you prefer?\"},\n",
        "#     {\"role\": \"user\", \"content\": \"I am more of a beach person than a mountain person.\"},\n",
        "#     {\"role\": \"assistant\", \"content\": \"That's interesting. Do you like hotels or Airbnb?\"},\n",
        "#     {\"role\": \"user\", \"content\": \"I like Airbnb more.\"},\n",
        "# ]\n",
        "# client.add(messages, user_id=\"john\")\n",
        "\n",
        "# Step 2: Create a Crew with User Memory\n",
        "\n",
        "# Create an agent with the knowledge store\n",
        "agent = Agent(\n",
        "    role=\"About User\",\n",
        "    goal=\"You know everything about the user.\",\n",
        "    backstory=\"\"\"You are a master at understanding people and their preferences.\"\"\",\n",
        "    verbose=True,\n",
        "    allow_delegation=False,\n",
        "    llm=llm1,\n",
        ")\n",
        "task = Task(\n",
        "    description=\"Answer the following questions about the user: {question}\",\n",
        "    expected_output=\"An answer to the question.\",\n",
        "    agent=agent,\n",
        ")\n",
        "\n",
        "crew = Crew(\n",
        "    agents=[agent],\n",
        "    tasks=[task],\n",
        "    process = Process.sequential,\n",
        "    verbose=True,\n",
        "    memory=True,\n",
        "    memory_config={\n",
        "        \"provider\": \"mem0\",\n",
        "        \"config\": {\"user_id\": \"john\"},\n",
        "    },\n",
        ")\n",
        "\n",
        "crew.kickoff(inputs={\"question\": \"What is your favorite vacation destination?\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zvuaYvNwvGMH",
        "outputId": "4d85cc23-f204-414f-d09a-ba3bbb614d79"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:opentelemetry.trace:Overriding of current TracerProvider is not allowed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mAbout User\u001b[00m\n",
            "\u001b[95m## Task:\u001b[00m \u001b[92mAnswer the following questions about the user: What is your favorite vacation destination?\u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mAbout User\u001b[00m\n",
            "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
            "Since you do not have a favorite vacation destination, I am unable to provide an answer.\u001b[00m\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/mem0/client/main.py:32: DeprecationWarning: Using default output format 'v1.0' is deprecated and will be removed in version 0.1.70. Please use output_format='v1.1' for enhanced memory details. Check out the docs for more information: https://docs.mem0.ai/platform/quickstart#4-1-create-memories\n",
            "  return func(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CrewOutput(raw='Since you do not have a favorite vacation destination, I am unable to provide an answer.', pydantic=None, json_dict=None, tasks_output=[TaskOutput(description='Answer the following questions about the user: What is your favorite vacation destination?', name=None, expected_output='An answer to the question.', summary='Answer the following questions about the user: What is your...', raw='Since you do not have a favorite vacation destination, I am unable to provide an answer.', pydantic=None, json_dict=None, agent='About User', output_format=<OutputFormat.RAW: 'raw'>)], token_usage=UsageMetrics(total_tokens=270, prompt_tokens=212, cached_prompt_tokens=0, completion_tokens=58, successful_requests=1))"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tools"
      ],
      "metadata": {
        "id": "TjmPV4Y5igih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install --upgrade transformers\n",
        "#!pip install --upgrade tokenizers\n",
        "#!pip install -Uq 'crewai[tools]'"
      ],
      "metadata": {
        "id": "Xzmx5DBcdCiN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "1e022e5b-46d6-47c8-8e6d-2171f34b93ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.49.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.28.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
            "  Using cached tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
            "Using cached tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "Installing collected packages: tokenizers\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.20.3\n",
            "    Uninstalling tokenizers-0.20.3:\n",
            "      Successfully uninstalled tokenizers-0.20.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "embedchain 0.1.127 requires chromadb<0.6.0,>=0.5.10, but you have chromadb 0.6.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed tokenizers-0.21.0\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.11/dist-packages (0.21.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers) (0.28.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (3.17.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (2025.1.31)\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "transformers 4.49.0 requires tokenizers<0.22,>=0.21, but you have tokenizers 0.20.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install --upgrade chromadb"
      ],
      "metadata": {
        "collapsed": true,
        "id": "eHue-nhx0rae",
        "outputId": "fa33edca-21e9-4f0a-e429-26ac8c7ad6f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: chromadb in /usr/local/lib/python3.11/dist-packages (0.5.23)\n",
            "Collecting chromadb\n",
            "  Using cached chromadb-0.6.3-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.2.2.post1)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.11/dist-packages (from chromadb) (2.10.6)\n",
            "Requirement already satisfied: chroma-hnswlib==0.7.6 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.7.6)\n",
            "Requirement already satisfied: fastapi>=0.95.2 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.115.11)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.34.0)\n",
            "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.26.4)\n",
            "Requirement already satisfied: posthog>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (3.18.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.12.2)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.20.1)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.30.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.30.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.51b0)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.30.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.20.3)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.48.9)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.67.1)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.70.0)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.3.0)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.15.1)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (32.0.1)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.11/dist-packages (from chromadb) (9.0.0)\n",
            "Requirement already satisfied: PyYAML>=6.0.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.0.2)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (5.1.0)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.11/dist-packages (from chromadb) (3.10.15)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.27.2)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (13.9.4)\n",
            "Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb) (24.2)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
            "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi>=0.95.2->chromadb) (0.46.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.38.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.32.3)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.3.0)\n",
            "Requirement already satisfied: durationpy>=0.7 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (0.9)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.2.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (5.29.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.18)\n",
            "Requirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.5.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.68.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.30.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.30.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.30.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.30.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.51b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.51b0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation==0.51b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.51b0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.51b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.51b0)\n",
            "Requirement already satisfied: opentelemetry-util-http==0.51b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.51b0)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation==0.51b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.17.2)\n",
            "Requirement already satisfied: asgiref~=3.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-asgi==0.51b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (3.8.1)\n",
            "Requirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
            "Requirement already satisfied: distro>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb) (1.9.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (2.27.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (2.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers>=0.13.2->chromadb) (0.28.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.4)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.1)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.4)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (14.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.17.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2024.10.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.21.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->kubernetes>=28.1.0->chromadb) (3.4.1)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.11/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
            "Using cached chromadb-0.6.3-py3-none-any.whl (611 kB)\n",
            "Installing collected packages: chromadb\n",
            "  Attempting uninstall: chromadb\n",
            "    Found existing installation: chromadb 0.5.23\n",
            "    Uninstalling chromadb-0.5.23:\n",
            "      Successfully uninstalled chromadb-0.5.23\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "embedchain 0.1.127 requires chromadb<0.6.0,>=0.5.10, but you have chromadb 0.6.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed chromadb-0.6.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "chromadb"
                ]
              },
              "id": "1814f39504ce409fb20d9b44e97743d8"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ['GEMINI_API_KEY'] =  userdata.get('GEMINI_API_KEY')\n",
        "#os.environ['OPENAI_API_KEY'] =  userdata.get('OPENAI_API_KEY')"
      ],
      "metadata": {
        "id": "pzVzY9Pq3zAn"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"SERPER_API_KEY\"] = userdata.get('SERPER_API_KEY')"
      ],
      "metadata": {
        "id": "P3a8h46aI1SH"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -Uq crewai crewai-tools\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "uQnsCkk90ngN",
        "outputId": "09aaff01-90e1-4c31-89ce-3103bc1617f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.5/42.5 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.2/240.2 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m93.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m545.9/545.9 kB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m91.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.4/211.4 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m628.3/628.3 kB\u001b[0m \u001b[31m47.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.4/71.4 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.6/32.6 MB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.0/65.0 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.9/55.9 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.7/118.7 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.4/177.4 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m112.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m85.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m756.0/756.0 kB\u001b[0m \u001b[31m45.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.0/236.0 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.2/16.2 MB\u001b[0m \u001b[31m98.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.8/231.8 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.9/253.9 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.6/131.6 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m77.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.1/45.1 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m86.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m54.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.8/311.8 kB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.5/106.5 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m116.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.8/76.8 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.7/35.7 MB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.1/71.1 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m56.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m98.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m104.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m74.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m415.1/415.1 kB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.2/209.2 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m92.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m508.0/508.0 kB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m306.7/306.7 kB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m97.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m452.6/452.6 kB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m88.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "transformers 4.48.3 requires tokenizers<0.22,>=0.21, but you have tokenizers 0.20.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedder = {\n",
        "        \"provider\": \"google\",\n",
        "        \"config\": {\n",
        "            \"model\": \"models/text-embedding-004\",\n",
        "            \"api_key\": userdata.get('GEMINI_API_KEY'),\n",
        "        }\n",
        "    }"
      ],
      "metadata": {
        "id": "EVhmjxSsuL9c"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -Uq langchain-google-genai"
      ],
      "metadata": {
        "id": "jqJVnF7ivuop",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fed10f0b-b85d-42f7-cbdf-8d796a34898e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.4 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m48.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-generativeai 0.8.4 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.6.16 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install crewai crewai-tools"
      ],
      "metadata": {
        "id": "Ck0fD3Ntxlum"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from crewai import LLM\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "llm=LLM(model=\"gemini/gemini-1.5-flash\")"
      ],
      "metadata": {
        "id": "c8-oehbdviqn"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade crewai-tools"
      ],
      "metadata": {
        "collapsed": true,
        "id": "qSV5HNP9yt3W",
        "outputId": "7ecc7aa1-ff13-47c2-abd8-a58940d3cd93",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: crewai-tools in /usr/local/lib/python3.11/dist-packages (0.36.0)\n",
            "Requirement already satisfied: chromadb>=0.4.22 in /usr/local/lib/python3.11/dist-packages (from crewai-tools) (0.5.23)\n",
            "Requirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.11/dist-packages (from crewai-tools) (8.1.8)\n",
            "Requirement already satisfied: crewai>=0.100.0 in /usr/local/lib/python3.11/dist-packages (from crewai-tools) (0.102.0)\n",
            "Requirement already satisfied: docker>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from crewai-tools) (7.1.0)\n",
            "Requirement already satisfied: embedchain>=0.1.114 in /usr/local/lib/python3.11/dist-packages (from crewai-tools) (0.1.127)\n",
            "Requirement already satisfied: lancedb>=0.5.4 in /usr/local/lib/python3.11/dist-packages (from crewai-tools) (0.20.0)\n",
            "Requirement already satisfied: openai>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from crewai-tools) (1.61.1)\n",
            "Requirement already satisfied: pydantic>=2.6.1 in /usr/local/lib/python3.11/dist-packages (from crewai-tools) (2.10.6)\n",
            "Requirement already satisfied: pyright>=1.1.350 in /usr/local/lib/python3.11/dist-packages (from crewai-tools) (1.1.396)\n",
            "Requirement already satisfied: pytube>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from crewai-tools) (15.0.0)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.11/dist-packages (from crewai-tools) (2.32.3)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.4.22->crewai-tools) (1.2.2.post1)\n",
            "Requirement already satisfied: chroma-hnswlib==0.7.6 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.4.22->crewai-tools) (0.7.6)\n",
            "Requirement already satisfied: fastapi>=0.95.2 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.4.22->crewai-tools) (0.115.11)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb>=0.4.22->crewai-tools) (0.34.0)\n",
            "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.4.22->crewai-tools) (1.26.4)\n",
            "Requirement already satisfied: posthog>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.4.22->crewai-tools) (3.18.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.4.22->crewai-tools) (4.12.2)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.4.22->crewai-tools) (1.20.1)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.4.22->crewai-tools) (1.30.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.4.22->crewai-tools) (1.30.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.4.22->crewai-tools) (0.51b0)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.4.22->crewai-tools) (1.30.0)\n",
            "Requirement already satisfied: tokenizers<=0.20.3,>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.4.22->crewai-tools) (0.20.3)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.4.22->crewai-tools) (0.48.9)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.4.22->crewai-tools) (4.67.1)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.4.22->crewai-tools) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.4.22->crewai-tools) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.4.22->crewai-tools) (1.70.0)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.4.22->crewai-tools) (4.3.0)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.4.22->crewai-tools) (0.15.1)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.4.22->crewai-tools) (32.0.1)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.4.22->crewai-tools) (9.0.0)\n",
            "Requirement already satisfied: PyYAML>=6.0.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.4.22->crewai-tools) (6.0.2)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.4.22->crewai-tools) (5.1.0)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.4.22->crewai-tools) (3.10.15)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.4.22->crewai-tools) (0.27.2)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.4.22->crewai-tools) (13.9.4)\n",
            "Requirement already satisfied: appdirs>=1.4.4 in /usr/local/lib/python3.11/dist-packages (from crewai>=0.100.0->crewai-tools) (1.4.4)\n",
            "Requirement already satisfied: auth0-python>=4.7.1 in /usr/local/lib/python3.11/dist-packages (from crewai>=0.100.0->crewai-tools) (4.8.1)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from crewai>=0.100.0->crewai-tools) (1.9.0)\n",
            "Requirement already satisfied: instructor>=1.3.3 in /usr/local/lib/python3.11/dist-packages (from crewai>=0.100.0->crewai-tools) (1.7.2)\n",
            "Requirement already satisfied: json-repair>=0.25.2 in /usr/local/lib/python3.11/dist-packages (from crewai>=0.100.0->crewai-tools) (0.39.1)\n",
            "Requirement already satisfied: json5>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from crewai>=0.100.0->crewai-tools) (0.10.0)\n",
            "Requirement already satisfied: jsonref>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from crewai>=0.100.0->crewai-tools) (1.1.0)\n",
            "Requirement already satisfied: litellm==1.60.2 in /usr/local/lib/python3.11/dist-packages (from crewai>=0.100.0->crewai-tools) (1.60.2)\n",
            "Requirement already satisfied: openpyxl>=3.1.5 in /usr/local/lib/python3.11/dist-packages (from crewai>=0.100.0->crewai-tools) (3.1.5)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-http>=1.22.0 in /usr/local/lib/python3.11/dist-packages (from crewai>=0.100.0->crewai-tools) (1.30.0)\n",
            "Requirement already satisfied: pdfplumber>=0.11.4 in /usr/local/lib/python3.11/dist-packages (from crewai>=0.100.0->crewai-tools) (0.11.5)\n",
            "Requirement already satisfied: python-dotenv>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from crewai>=0.100.0->crewai-tools) (1.0.1)\n",
            "Requirement already satisfied: pyvis>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from crewai>=0.100.0->crewai-tools) (0.3.2)\n",
            "Requirement already satisfied: regex>=2024.9.11 in /usr/local/lib/python3.11/dist-packages (from crewai>=0.100.0->crewai-tools) (2024.11.6)\n",
            "Requirement already satisfied: tomli-w>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from crewai>=0.100.0->crewai-tools) (1.2.0)\n",
            "Requirement already satisfied: tomli>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from crewai>=0.100.0->crewai-tools) (2.2.1)\n",
            "Requirement already satisfied: uv>=0.4.25 in /usr/local/lib/python3.11/dist-packages (from crewai>=0.100.0->crewai-tools) (0.6.4)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from litellm==1.60.2->crewai>=0.100.0->crewai-tools) (3.11.13)\n",
            "Requirement already satisfied: importlib-metadata>=6.8.0 in /usr/local/lib/python3.11/dist-packages (from litellm==1.60.2->crewai>=0.100.0->crewai-tools) (8.5.0)\n",
            "Requirement already satisfied: jinja2<4.0.0,>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from litellm==1.60.2->crewai>=0.100.0->crewai-tools) (3.1.5)\n",
            "Requirement already satisfied: jsonschema<5.0.0,>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from litellm==1.60.2->crewai>=0.100.0->crewai-tools) (4.23.0)\n",
            "Requirement already satisfied: tiktoken>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from litellm==1.60.2->crewai>=0.100.0->crewai-tools) (0.7.0)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from docker>=7.1.0->crewai-tools) (2.3.0)\n",
            "Requirement already satisfied: alembic<2.0.0,>=1.13.1 in /usr/local/lib/python3.11/dist-packages (from embedchain>=0.1.114->crewai-tools) (1.15.1)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from embedchain>=0.1.114->crewai-tools) (4.13.3)\n",
            "Requirement already satisfied: cohere<6.0,>=5.3 in /usr/local/lib/python3.11/dist-packages (from embedchain>=0.1.114->crewai-tools) (5.14.0)\n",
            "Requirement already satisfied: google-cloud-aiplatform<2.0.0,>=1.26.1 in /usr/local/lib/python3.11/dist-packages (from embedchain>=0.1.114->crewai-tools) (1.79.0)\n",
            "Requirement already satisfied: gptcache<0.2.0,>=0.1.43 in /usr/local/lib/python3.11/dist-packages (from embedchain>=0.1.114->crewai-tools) (0.1.44)\n",
            "Requirement already satisfied: langchain<0.4.0,>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from embedchain>=0.1.114->crewai-tools) (0.3.20)\n",
            "Requirement already satisfied: langchain-cohere<0.4.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from embedchain>=0.1.114->crewai-tools) (0.3.5)\n",
            "Requirement already satisfied: langchain-community<0.4.0,>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from embedchain>=0.1.114->crewai-tools) (0.3.19)\n",
            "Requirement already satisfied: langchain-openai<0.3.0,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from embedchain>=0.1.114->crewai-tools) (0.2.14)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from embedchain>=0.1.114->crewai-tools) (0.1.147)\n",
            "Requirement already satisfied: mem0ai<0.2.0,>=0.1.54 in /usr/local/lib/python3.11/dist-packages (from embedchain>=0.1.114->crewai-tools) (0.1.65)\n",
            "Requirement already satisfied: pypdf<6.0.0,>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from embedchain>=0.1.114->crewai-tools) (5.3.1)\n",
            "Requirement already satisfied: pysbd<0.4.0,>=0.3.4 in /usr/local/lib/python3.11/dist-packages (from embedchain>=0.1.114->crewai-tools) (0.3.4)\n",
            "Requirement already satisfied: schema<0.8.0,>=0.7.5 in /usr/local/lib/python3.11/dist-packages (from embedchain>=0.1.114->crewai-tools) (0.7.7)\n",
            "Requirement already satisfied: sqlalchemy<3.0.0,>=2.0.27 in /usr/local/lib/python3.11/dist-packages (from embedchain>=0.1.114->crewai-tools) (2.0.38)\n",
            "Requirement already satisfied: deprecation in /usr/local/lib/python3.11/dist-packages (from lancedb>=0.5.4->crewai-tools) (2.1.0)\n",
            "Requirement already satisfied: pylance~=0.23.2 in /usr/local/lib/python3.11/dist-packages (from lancedb>=0.5.4->crewai-tools) (0.23.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from lancedb>=0.5.4->crewai-tools) (24.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.12.0->crewai-tools) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.12.0->crewai-tools) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.12.0->crewai-tools) (0.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai>=1.12.0->crewai-tools) (1.3.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.6.1->crewai-tools) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.6.1->crewai-tools) (2.27.2)\n",
            "Requirement already satisfied: nodeenv>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from pyright>=1.1.350->crewai-tools) (1.9.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->crewai-tools) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->crewai-tools) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->crewai-tools) (2025.1.31)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.11/dist-packages (from alembic<2.0.0,>=1.13.1->embedchain>=0.1.114->crewai-tools) (1.3.9)\n",
            "Requirement already satisfied: cryptography>=43.0.1 in /usr/local/lib/python3.11/dist-packages (from auth0-python>=4.7.1->crewai>=0.100.0->crewai-tools) (43.0.3)\n",
            "Requirement already satisfied: pyjwt>=2.8.0 in /usr/local/lib/python3.11/dist-packages (from auth0-python>=4.7.1->crewai>=0.100.0->crewai-tools) (2.10.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4<5.0.0,>=4.12.2->embedchain>=0.1.114->crewai-tools) (2.6)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb>=0.4.22->crewai-tools) (1.2.0)\n",
            "Requirement already satisfied: fastavro<2.0.0,>=1.9.4 in /usr/local/lib/python3.11/dist-packages (from cohere<6.0,>=5.3->embedchain>=0.1.114->crewai-tools) (1.10.0)\n",
            "Requirement already satisfied: httpx-sse==0.4.0 in /usr/local/lib/python3.11/dist-packages (from cohere<6.0,>=5.3->embedchain>=0.1.114->crewai-tools) (0.4.0)\n",
            "Requirement already satisfied: types-requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from cohere<6.0,>=5.3->embedchain>=0.1.114->crewai-tools) (2.32.0.20250306)\n",
            "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi>=0.95.2->chromadb>=0.4.22->crewai-tools) (0.46.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai-tools) (2.24.1)\n",
            "Requirement already satisfied: google-auth<3.0.0dev,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai-tools) (2.38.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai-tools) (1.26.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai-tools) (5.29.3)\n",
            "Requirement already satisfied: google-cloud-storage<3.0.0dev,>=1.32.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai-tools) (2.19.0)\n",
            "Requirement already satisfied: google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai-tools) (3.29.0)\n",
            "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai-tools) (1.14.1)\n",
            "Requirement already satisfied: shapely<3.0.0dev in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai-tools) (2.0.7)\n",
            "Requirement already satisfied: docstring-parser<1 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai-tools) (0.16)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.11/dist-packages (from gptcache<0.2.0,>=0.1.43->embedchain>=0.1.114->crewai-tools) (5.5.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb>=0.4.22->crewai-tools) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb>=0.4.22->crewai-tools) (0.14.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=0.4.22->crewai-tools) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=0.4.22->crewai-tools) (2.8.2)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=0.4.22->crewai-tools) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=0.4.22->crewai-tools) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=0.4.22->crewai-tools) (3.2.2)\n",
            "Requirement already satisfied: durationpy>=0.7 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=0.4.22->crewai-tools) (0.9)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.41 in /usr/local/lib/python3.11/dist-packages (from langchain<0.4.0,>=0.3.1->embedchain>=0.1.114->crewai-tools) (0.3.41)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in /usr/local/lib/python3.11/dist-packages (from langchain<0.4.0,>=0.3.1->embedchain>=0.1.114->crewai-tools) (0.3.6)\n",
            "Requirement already satisfied: langchain-experimental<0.4.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from langchain-cohere<0.4.0,>=0.3.0->embedchain>=0.1.114->crewai-tools) (0.3.4)\n",
            "Requirement already satisfied: pandas>=1.4.3 in /usr/local/lib/python3.11/dist-packages (from langchain-cohere<0.4.0,>=0.3.0->embedchain>=0.1.114->crewai-tools) (2.2.2)\n",
            "Requirement already satisfied: tabulate<0.10.0,>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from langchain-cohere<0.4.0,>=0.3.0->embedchain>=0.1.114->crewai-tools) (0.9.0)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community<0.4.0,>=0.3.1->embedchain>=0.1.114->crewai-tools) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community<0.4.0,>=0.3.1->embedchain>=0.1.114->crewai-tools) (2.8.1)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.17->embedchain>=0.1.114->crewai-tools) (1.0.0)\n",
            "Requirement already satisfied: psycopg2-binary<3.0.0,>=2.9.10 in /usr/local/lib/python3.11/dist-packages (from mem0ai<0.2.0,>=0.1.54->embedchain>=0.1.114->crewai-tools) (2.9.10)\n",
            "Requirement already satisfied: pytz<2025.0,>=2024.1 in /usr/local/lib/python3.11/dist-packages (from mem0ai<0.2.0,>=0.1.54->embedchain>=0.1.114->crewai-tools) (2024.2)\n",
            "Requirement already satisfied: qdrant-client<2.0.0,>=1.9.1 in /usr/local/lib/python3.11/dist-packages (from mem0ai<0.2.0,>=0.1.54->embedchain>=0.1.114->crewai-tools) (1.13.3)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb>=0.4.22->crewai-tools) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb>=0.4.22->crewai-tools) (25.2.10)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb>=0.4.22->crewai-tools) (1.13.1)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl>=3.1.5->crewai>=0.100.0->crewai-tools) (2.0.0)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb>=0.4.22->crewai-tools) (1.2.18)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb>=0.4.22->crewai-tools) (1.68.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.30.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb>=0.4.22->crewai-tools) (1.30.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.30.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb>=0.4.22->crewai-tools) (1.30.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.51b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=0.4.22->crewai-tools) (0.51b0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation==0.51b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=0.4.22->crewai-tools) (0.51b0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.51b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=0.4.22->crewai-tools) (0.51b0)\n",
            "Requirement already satisfied: opentelemetry-util-http==0.51b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=0.4.22->crewai-tools) (0.51b0)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation==0.51b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=0.4.22->crewai-tools) (1.17.2)\n",
            "Requirement already satisfied: asgiref~=3.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-asgi==0.51b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=0.4.22->crewai-tools) (3.8.1)\n",
            "Requirement already satisfied: pdfminer.six==20231228 in /usr/local/lib/python3.11/dist-packages (from pdfplumber>=0.11.4->crewai>=0.100.0->crewai-tools) (20231228)\n",
            "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.11/dist-packages (from pdfplumber>=0.11.4->crewai>=0.100.0->crewai-tools) (11.1.0)\n",
            "Requirement already satisfied: pypdfium2>=4.18.0 in /usr/local/lib/python3.11/dist-packages (from pdfplumber>=0.11.4->crewai>=0.100.0->crewai-tools) (4.30.1)\n",
            "Requirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb>=0.4.22->crewai-tools) (1.6)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb>=0.4.22->crewai-tools) (2.2.1)\n",
            "Requirement already satisfied: pyarrow>=14 in /usr/local/lib/python3.11/dist-packages (from pylance~=0.23.2->lancedb>=0.5.4->crewai-tools) (18.1.0)\n",
            "Requirement already satisfied: ipython>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from pyvis>=0.3.2->crewai>=0.100.0->crewai-tools) (7.34.0)\n",
            "Requirement already satisfied: jsonpickle>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from pyvis>=0.3.2->crewai>=0.100.0->crewai-tools) (4.0.2)\n",
            "Requirement already satisfied: networkx>=1.11 in /usr/local/lib/python3.11/dist-packages (from pyvis>=0.3.2->crewai>=0.100.0->crewai-tools) (3.4.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb>=0.4.22->crewai-tools) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb>=0.4.22->crewai-tools) (2.18.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy<3.0.0,>=2.0.27->embedchain>=0.1.114->crewai-tools) (3.1.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers<=0.20.3,>=0.13.2->chromadb>=0.4.22->crewai-tools) (0.28.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb>=0.4.22->crewai-tools) (1.5.4)\n",
            "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb>=0.4.22->crewai-tools) (0.6.4)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb>=0.4.22->crewai-tools) (0.21.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb>=0.4.22->crewai-tools) (1.0.4)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb>=0.4.22->crewai-tools) (14.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->litellm==1.60.2->crewai>=0.100.0->crewai-tools) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->litellm==1.60.2->crewai>=0.100.0->crewai-tools) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->litellm==1.60.2->crewai>=0.100.0->crewai-tools) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->litellm==1.60.2->crewai>=0.100.0->crewai-tools) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->litellm==1.60.2->crewai>=0.100.0->crewai-tools) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->litellm==1.60.2->crewai>=0.100.0->crewai-tools) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->litellm==1.60.2->crewai>=0.100.0->crewai-tools) (1.18.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=43.0.1->auth0-python>=4.7.1->crewai>=0.100.0->crewai-tools) (1.17.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.1->embedchain>=0.1.114->crewai-tools) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.1->embedchain>=0.1.114->crewai-tools) (0.9.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai-tools) (1.62.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai-tools) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai-tools) (4.9)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0dev,>=2.4.1 in /usr/local/lib/python3.11/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai-tools) (2.4.2)\n",
            "Requirement already satisfied: google-resumable-media<3.0dev,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai-tools) (2.7.2)\n",
            "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai-tools) (0.14.0)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage<3.0.0dev,>=1.32.0->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai-tools) (1.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<=0.20.3,>=0.13.2->chromadb>=0.4.22->crewai-tools) (3.17.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<=0.20.3,>=0.13.2->chromadb>=0.4.22->crewai-tools) (2024.10.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata>=6.8.0->litellm==1.60.2->crewai>=0.100.0->crewai-tools) (3.21.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai>=0.100.0->crewai-tools) (75.1.0)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai>=0.100.0->crewai-tools) (0.19.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai>=0.100.0->crewai-tools) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai>=0.100.0->crewai-tools) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai>=0.100.0->crewai-tools) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai>=0.100.0->crewai-tools) (3.0.50)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai>=0.100.0->crewai-tools) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai>=0.100.0->crewai-tools) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai>=0.100.0->crewai-tools) (4.9.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2<4.0.0,>=3.1.2->litellm==1.60.2->crewai>=0.100.0->crewai-tools) (3.0.2)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm==1.60.2->crewai>=0.100.0->crewai-tools) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm==1.60.2->crewai>=0.100.0->crewai-tools) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm==1.60.2->crewai>=0.100.0->crewai-tools) (0.23.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.41->langchain<0.4.0,>=0.3.1->embedchain>=0.1.114->crewai-tools) (1.33)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb>=0.4.22->crewai-tools) (0.1.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.4.3->langchain-cohere<0.4.0,>=0.3.0->embedchain>=0.1.114->crewai-tools) (2025.1)\n",
            "Requirement already satisfied: grpcio-tools>=1.41.0 in /usr/local/lib/python3.11/dist-packages (from qdrant-client<2.0.0,>=1.9.1->mem0ai<0.2.0,>=0.1.54->embedchain>=0.1.114->crewai-tools) (1.70.0)\n",
            "Requirement already satisfied: portalocker<3.0.0,>=2.7.0 in /usr/local/lib/python3.11/dist-packages (from qdrant-client<2.0.0,>=1.9.1->mem0ai<0.2.0,>=0.1.54->embedchain>=0.1.114->crewai-tools) (2.10.1)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.11/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb>=0.4.22->crewai-tools) (10.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb>=0.4.22->crewai-tools) (1.3.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=43.0.1->auth0-python>=4.7.1->crewai>=0.100.0->crewai-tools) (2.22)\n",
            "Requirement already satisfied: h2<5,>=3 in /usr/local/lib/python3.11/dist-packages (from httpx[http2]>=0.20.0->qdrant-client<2.0.0,>=1.9.1->mem0ai<0.2.0,>=0.1.54->embedchain>=0.1.114->crewai-tools) (4.2.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=5.3.0->pyvis>=0.3.2->crewai>=0.100.0->crewai-tools) (0.8.4)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.41->langchain<0.4.0,>=0.3.1->embedchain>=0.1.114->crewai-tools) (3.0.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython>=5.3.0->pyvis>=0.3.2->crewai>=0.100.0->crewai-tools) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.3.0->pyvis>=0.3.2->crewai>=0.100.0->crewai-tools) (0.2.13)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai-tools) (0.6.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.1->embedchain>=0.1.114->crewai-tools) (1.0.0)\n",
            "Requirement already satisfied: hyperframe<7,>=6.1 in /usr/local/lib/python3.11/dist-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client<2.0.0,>=1.9.1->mem0ai<0.2.0,>=0.1.54->embedchain>=0.1.114->crewai-tools) (6.1.0)\n",
            "Requirement already satisfied: hpack<5,>=4.1 in /usr/local/lib/python3.11/dist-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client<2.0.0,>=1.9.1->mem0ai<0.2.0,>=0.1.54->embedchain>=0.1.114->crewai-tools) (4.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from crewai_tools import tools\n",
        "\n",
        "print(tools)"
      ],
      "metadata": {
        "id": "4sfF8GJ-2ww0",
        "outputId": "1e6963b4-070e-4b4d-d0d9-1ece540e021a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<module 'crewai_tools.tools' from '/usr/local/lib/python3.11/dist-packages/crewai_tools/tools/__init__.py'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from crewai import Agent\n",
        "\n",
        "# Initialize an agent with the Gemini model\n",
        "agent = Agent(\n",
        "    role='Research Analyst',\n",
        "    goal='Provide insights on recent AI developments',\n",
        "    backstory='An AI assistant specializing in AI research.',\n",
        "    llm=llm\n",
        ")\n"
      ],
      "metadata": {
        "id": "UxsVyvVM39GZ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from crewai_tools import\n",
        "class GeminiWebsiteSearchTool():\n",
        "    def __init__(self, llm):\n",
        "        self.llm = llm\n",
        "\n",
        "    def run(self, query: str):\n",
        "        response = self.llm.generate(query)\n",
        "        return response"
      ],
      "metadata": {
        "id": "nv6YtBFUwLss"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the custom tool\n",
        "gemini_search_tool = GeminiWebsiteSearchTool(llm=llm)\n",
        "\n",
        "# Assign the tool to the agent\n",
        "agent.tools = [gemini_search_tool]\n"
      ],
      "metadata": {
        "id": "DdStZjOJ3reJ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from crewai import Agent, Task, Crew"
      ],
      "metadata": {
        "id": "xUyqtwaa5BPq"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from crewai import Agent, Task, Crew\n",
        "\n",
        "# Initialize an agent with the Gemini model\n",
        "agent = Agent(\n",
        "    role='Research Analyst',\n",
        "    goal='Provide insights on recent AI developments',\n",
        "    backstory='An AI assistant specializing in AI research.',\n",
        "    llm=llm\n",
        ")\n",
        "\n",
        "# Initialize the custom tool\n",
        "gemini_search_tool = GeminiWebsiteSearchTool(llm=llm)\n",
        "\n",
        "# Assign the tool to the agent\n",
        "agent.tools = [gemini_search_tool]\n",
        "\n",
        "# Define a task for the agent\n",
        "task = Task(\n",
        "    description=\"Research the latest advancements in AI technology.\",\n",
        "    expected_output=\"A summary of the latest advancements in AI technology.\",\n",
        "    agent=agent\n",
        ")\n",
        "\n",
        "# Create a crew with the agent and task\n",
        "crew = Crew(agents=[agent], tasks=[task])\n",
        "\n",
        "# Agent performs a web search using the crew\n",
        "result = crew.kickoff()  # Call kickoff on the Crew object\n",
        "print(result)"
      ],
      "metadata": {
        "id": "aENCwzNe4HFz",
        "outputId": "c8af1451-9b21-4661-bd29-f08030aebdf2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'GeminiWebsiteSearchTool' object has no attribute 'name'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-c4075e7a468d>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# Create a crew with the agent and task\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mcrew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCrew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtasks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# Agent performs a web search using the crew\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/crewai/crew.py\u001b[0m in \u001b[0;36mcheck_config\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    342\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0magent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 344\u001b[0;31m                     \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_cache_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache_handler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    345\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_rpm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m                     \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_rpm_controller\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rpm_controller\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/crewai/agents/agent_builder/base_agent.py\u001b[0m in \u001b[0;36mset_cache_handler\u001b[0;34m(self, cache_handler)\u001b[0m\n\u001b[1;32m    339\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_handler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache_handler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache_handler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_agent_executor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mincrement_formatting_errors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/crewai/agent.py\u001b[0m in \u001b[0;36mcreate_agent_executor\u001b[0;34m(self, tools, task)\u001b[0m\n\u001b[1;32m    309\u001b[0m             \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m             \u001b[0mtools_handler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools_handler\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0mtools_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__tools_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_tools\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m             \u001b[0mtools_description\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_text_description_and_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_tools\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m             \u001b[0mstep_callback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_callback\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/crewai/agent.py\u001b[0m in \u001b[0;36m__tools_names\u001b[0;34m(tools)\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__tools_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtools\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m\", \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtools\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/crewai/agent.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__tools_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtools\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m\", \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtools\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'GeminiWebsiteSearchTool' object has no attribute 'name'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "h5-9A-W14O7I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install openai\n",
        "import os\n",
        "from crewai import Agent, Task, Crew\n",
        "# Importing crewAI tools\n",
        "from crewai_tools import (\n",
        "    DirectoryReadTool,\n",
        "    FileReadTool,\n",
        "    SerperDevTool,\n",
        "    WebsiteSearchTool\n",
        ")\n",
        "\n",
        "# Set up API keys\n",
        "os.environ[\"SERPER_API_KEY\"] = userdata.get('SERPER_API_KEY') # serper.dev API key\n",
        "os.environ[\"GEMINI_API_KEY\"] = userdata.get('GEMINI_API_KEY')\n",
        "\n",
        "# Instantiate tools\n",
        "docs_tool = DirectoryReadTool(directory='./blog-posts')\n",
        "file_tool = FileReadTool()\n",
        "search_tool = SerperDevTool()\n",
        "# Example with WebsiteSearchTool\n",
        "web_rag_tool = WebsiteSearchTool(llm=llm)\n",
        "\n",
        "# Create agents\n",
        "researcher = Agent(\n",
        "    role='Market Research Analyst',\n",
        "    goal='Provide up-to-date market analysis of the AI industry',\n",
        "    backstory='An expert analyst with a keen eye for market trends.',\n",
        "    tools=[search_tool, web_rag_tool],\n",
        "    verbose=True,\n",
        "    llm=llm\n",
        ")\n",
        "\n",
        "writer = Agent(\n",
        "    role='Content Writer',\n",
        "    goal='Craft engaging blog posts about the AI industry',\n",
        "    backstory='A skilled writer with a passion for technology.',\n",
        "    tools=[docs_tool, file_tool],\n",
        "    verbose=True,\n",
        "    llm=llm\n",
        ")\n",
        "\n",
        "# Define tasks\n",
        "research = Task(\n",
        "    description='Research the latest trends in the AI industry and provide a summary.',\n",
        "    expected_output='A summary of the top 3 trending developments in the AI industry with a unique perspective on their significance.',\n",
        "    agent=researcher\n",
        ")\n",
        "\n",
        "write = Task(\n",
        "    description='Write an engaging blog post about the AI industry, based on the research analyst’s summary. Draw inspiration from the latest blog posts in the directory.',\n",
        "    expected_output='A 4-paragraph blog post formatted in markdown with engaging, informative, and accessible content, avoiding complex jargon.',\n",
        "    agent=writer,\n",
        "    output_file='blog-posts/new_post.md'  # The final blog post will be saved here\n",
        ")\n",
        "\n",
        "# Assemble a crew with planning enabled\n",
        "crew = Crew(\n",
        "    agents=[researcher, writer],\n",
        "    tasks=[research, write],\n",
        "    verbose=True,\n",
        "    planning=True,  # Enable planning feature\n",
        "    planning_llm=llm\n",
        ")\n",
        "\n",
        "# Execute tasks\n",
        "crew.kickoff()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n4R4y8KZNRkw",
        "outputId": "2e67d3c8-2e78-433a-d5b2-c98cab993260"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:opentelemetry.trace:Overriding of current TracerProvider is not allowed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m\u001b[93m \n",
            "[2025-03-06 10:06:01][INFO]: Planning the crew execution\u001b[00m\n",
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mMarket Research Analyst\u001b[00m\n",
            "\u001b[95m## Task:\u001b[00m \u001b[92mResearch the latest trends in the AI industry and provide a summary.Step 1: The Market Research Analyst will utilize the 'Search the internet with Serper' tool.  The search query will be crafted to focus on the most recent advancements in AI.  Specific keywords such as \"latest AI trends\", \"breakthroughs in artificial intelligence\", \"cutting-edge AI technologies\", and  \"emerging AI applications\" should be incorporated to ensure a comprehensive search. The search type should be set to 'news' to prioritize recent developments.\n",
            "\n",
            "Step 2:  The analyst will carefully review the top 10 results returned by Serper.  The focus will be on identifying recurring themes and significant developments across multiple sources to ensure objectivity and avoid bias from individual articles.  Specific attention should be paid to identifying trends that are truly impactful and transformative, not just incremental improvements.\n",
            "\n",
            "Step 3: From the research in step 2, the analyst will identify and select the top three most impactful and significant trends.  These should be based on a combination of factors, including the level of innovation involved, the potential for wide-ranging effects, and the level of discussion and investment these developments are attracting within the industry.\n",
            "\n",
            "Step 4:  The analyst will write a concise summary of the three selected trends, explaining each trend in a clear and understandable way, avoiding technical jargon whenever possible.  The summary should also highlight the unique significance of each trend, providing a perspective that adds insightful value beyond merely describing the trends.  Consider the long-term implications, potential disruptions, and their impact on different industries or sectors.\n",
            "\n",
            "Step 5: The analyst will review the summary for clarity, accuracy, and conciseness, ensuring the information is factually sound and presented in a logical and compelling manner.  Any ambiguities or gaps in explanation will be addressed before finalizing the summary.\u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mMarket Research Analyst\u001b[00m\n",
            "\u001b[95m## Using tool:\u001b[00m \u001b[92mSearch the internet with Serper\u001b[00m\n",
            "\u001b[95m## Tool Input:\u001b[00m \u001b[92m\n",
            "\"{\\\"search_query\\\": \\\"latest AI trends, breakthroughs in artificial intelligence, cutting-edge AI technologies, emerging AI applications\\\", \\\"search_type\\\": \\\"news\\\"}\"\u001b[00m\n",
            "\u001b[95m## Tool Output:\u001b[00m \u001b[92m\n",
            "{'searchParameters': {'q': 'latest AI trends, breakthroughs in artificial intelligence, cutting-edge AI technologies, emerging AI applications', 'type': 'search', 'num': 10, 'engine': 'google'}, 'organic': [{'title': 'Top AI Trends 2025: Key Developments to Watch - Appinventiv', 'link': 'https://appinventiv.com/blog/ai-trends/', 'snippet': 'Explore the top AI trends of 2025 and stay updated on the latest developments reshaping industry landscapes with this detailed blog.', 'position': 1}, {'title': '8 AI and machine learning trends to watch in 2025 | TechTarget', 'link': 'https://www.techtarget.com/searchenterpriseai/tip/9-top-AI-and-machine-learning-trends', 'snippet': 'Explore the key trends shaping AI in 2025, from multimodal models and AI agents to security challenges and evolving regulatory landscapes.', 'position': 2}, {'title': 'Top Artificial Intelligence Applications | AI Applications 2025', 'link': 'https://www.simplilearn.com/tutorials/artificial-intelligence-tutorial/artificial-intelligence-applications', 'snippet': 'Explore the diverse applications of AI, its practical uses, and the latest AI apps transforming industries. Learn how AI is shaping the ...', 'position': 3}, {'title': '2025 AI Trends Driving the Biggest Tech Transformations Today', 'link': 'https://www.eweek.com/artificial-intelligence/ai-trends/', 'snippet': 'AI is set to reshape the tech landscape in 2025, driving breakthroughs in enterprise IT, automation, cybersecurity, and software development. As AI frameworks ...', 'position': 4}, {'title': '14 AI Trends 2025: Shadow AI, Humanoid Robots, and More', 'link': 'https://365datascience.com/trending/ai-trends/', 'snippet': 'Discover the main AI trends you should watch out for as a data scientist in 2025, including the next generation of AI technology.', 'position': 5}, {'title': 'Top AI/ML Trends to Watch in 2025: Shaping the Future of Technology', 'link': 'https://svitla.com/blog/ai-ml-trends-2025/', 'snippet': 'Discover the top AI/ML trends for 2025, from autonomous agents to decentralized AI, and learn how they reshape business and technology.', 'position': 6}, {'title': 'The Future of AI: How Artificial Intelligence Will Change the World', 'link': 'https://builtin.com/artificial-intelligence/artificial-intelligence-future', 'snippet': 'AI is already powering automation and data analysis. In the future, expect widespread adoption of autonomous machinery and AI-powered personalization.', 'position': 7}, {'title': 'New Trends In Artificial Intelligence: Unlocking The Future', 'link': 'https://www.aimtechnologies.co/new-trends-in-artificial-intelligence-unlocking-the-future/', 'snippet': \"In this article, we'll delve into the latest new trends in artificial intelligence, exploring the cutting-edge developments that are shaping our world.\", 'position': 8, 'sitelinks': [{'title': '2. Ai In Healthcare...', 'link': 'https://www.aimtechnologies.co/new-trends-in-artificial-intelligence-unlocking-the-future/#:~:text=2.%20AI%20in%20Healthcare%3A%20Revolutionizing%20Patient%20Care'}, {'title': '4. Ai Ethics: Navigating The...', 'link': 'https://www.aimtechnologies.co/new-trends-in-artificial-intelligence-unlocking-the-future/#:~:text=4.%20AI%20Ethics%3A%20Navigating%20the%20Moral%20Compass'}, {'title': '7. Ai-Powered Human...', 'link': 'https://www.aimtechnologies.co/new-trends-in-artificial-intelligence-unlocking-the-future/#:~:text=7.%20AI%2Dpowered%20Human%20Augmentation%3A%20Enhancing%20Abilities'}]}, {'title': 'The new Essential Eight technology trends: PwC', 'link': 'https://www.pwc.com/us/en/tech-effect/emerging-tech/essential-eight-technologies.html', 'snippet': 'From AI to virtual reality, emerging tech is driving business reinvention. See which are ready to scale, apply to new use cases or experiment with.', 'position': 9, 'sitelinks': [{'title': 'Internet Of Things', 'link': 'https://www.pwc.com/us/en/tech-effect/emerging-tech/essential-eight-technologies.html#:~:text=Internet%20of%20things,-The%20Internet%20of%20Things%20%28'}, {'title': 'Advanced Robotics', 'link': 'https://www.pwc.com/us/en/tech-effect/emerging-tech/essential-eight-technologies.html#:~:text=Advanced%20robotics,-Advanced%20robotics'}, {'title': 'Quantum Computing', 'link': 'https://www.pwc.com/us/en/tech-effect/emerging-tech/essential-eight-technologies.html#:~:text=Quantum%20computing,-Quantum%20computing'}]}, {'title': '29 Cutting Edge Applications of Artificial Intelligence - Burnie Group', 'link': 'https://burniegroup.com/29-cutting-edge-applications-of-artificial-intelligence/', 'snippet': 'We share 29 cutting-edge applications of artificial intelligence, including natural language processing and machine learning.', 'position': 10}], 'peopleAlsoAsk': [{'question': 'What is the latest AI trend?', 'snippet': \"Let's get agentic AI — the kind of AI that does tasks independently — out of the way first: It's a sure bet for 2025's “most trending AI trend.” Agentic AI seems to be on an inevitable rise: Everybody in the tech vendor and analyst worlds is excited about the prospect of having AI programs collaborate to do real work ...\", 'title': 'Five Trends in AI and Data Science for 2025', 'link': 'https://sloanreview.mit.edu/article/five-trends-in-ai-and-data-science-for-2025/'}, {'question': 'What is the newest technology in AI?', 'snippet': 'LATEST TRENDS IN ARTIFICIAL INTELLIGENCE\\n1\\nIntelligent Process Automation. ...\\n2\\nA Shift Toward Cybersecurity. ...\\n3\\nAI for Personalised Services. ...\\n4\\nAutomated AI Development. ...\\n5\\nAutonomous Vehicles. ...\\n6\\nIncorporating Facial Recognition. ...\\n7\\nConvergence of IoT and AI. ...\\n8\\nAI in Healthcare.', 'title': 'Latest Trends in Artificial Intelligence | element14 India', 'link': 'https://in.element14.com/latest-trends-in-artificial-intelligence'}, {'question': 'What is the next AI breakthrough?', 'snippet': \"Our four hot trends to watch out for in 2024 included what we called customized chatbots—interactive helper apps powered by multimodal large language models (check: we didn't know it yet, but we were talking about what everyone now calls agents, the hottest thing in AI right now); generative video (check: few ...\", 'title': \"What's next for AI in 2025 | MIT Technology Review\", 'link': 'https://www.technologyreview.com/2025/01/08/1109188/whats-next-for-ai-in-2025/'}, {'question': 'What is cutting edge AI technology?', 'snippet': \"Cutting-edge AI is the latest in AI technology\\\\n\\\\n Unlike machine learning, deep learning or natural language processing, it isn't a unique model type. Instead, it revolves around the algorithm's location. Cutting-edge AI involves deploying a machine learning model at a network's boundary.\", 'title': 'Cutting edge AI - InData Labs', 'link': 'https://indatalabs.com/blog/cutting-edge-ai'}], 'relatedSearches': [{'query': 'Emerging trends in Artificial Intelligence'}, {'query': 'Current trends in Artificial intelligence PDF'}, {'query': 'Top 10 AI trends'}, {'query': '5 applications of Artificial Intelligence'}, {'query': 'Artificial intelligence trends in business'}, {'query': 'Latest AI technology news'}, {'query': 'Latest artificial intelligence applications'}, {'query': 'AI trends 2025'}], 'credits': 1}\u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mMarket Research Analyst\u001b[00m\n",
            "\u001b[95m## Using tool:\u001b[00m \u001b[92mSearch the internet with Serper\u001b[00m\n",
            "\u001b[95m## Tool Input:\u001b[00m \u001b[92m\n",
            "\"{\\\"search_query\\\": \\\"Generative AI trends, AI safety and ethics, AI applications in healthcare finance\\\", \\\"search_type\\\": \\\"news\\\"}\"\u001b[00m\n",
            "\u001b[95m## Tool Output:\u001b[00m \u001b[92m\n",
            "{'searchParameters': {'q': 'Generative AI trends, AI safety and ethics, AI applications in healthcare finance', 'type': 'search', 'num': 10, 'engine': 'google'}, 'organic': [{'title': 'Ethical Issues of Artificial Intelligence in Medicine and Healthcare', 'link': 'https://pmc.ncbi.nlm.nih.gov/articles/PMC8826344/', 'snippet': 'AI applications in healthcare have literally changed the medical field, including imaging and electronic medical records (EMR), laboratory diagnosis, treatment ...', 'position': 1}, {'title': 'Generative AI in health care: Opportunities, challenges, and policy', 'link': 'https://www.brookings.edu/articles/generative-ai-in-health-care-opportunities-challenges-and-policy/', 'snippet': 'Generative AI poses many benefits for the healthcare industry, but transparency and informed consent must be prioritized to avoid its risks.', 'position': 2}, {'title': 'Generative AI in Healthcare: Use Cases, Benefits, and Drawbacks', 'link': 'https://www.alpha-sense.com/blog/trends/generative-ai-healthcare/', 'snippet': 'From streamlining medical processes like scribing prescriptions to responding to patient messages, the list of potential AI use cases is endless.', 'position': 3}, {'title': 'Generative Artificial Intelligence Use in Healthcare', 'link': 'https://pmc.ncbi.nlm.nih.gov/articles/PMC11739231/', 'snippet': 'Gen AI can play a crucial role in predicting health trends, personalizing medicine, and optimizing healthcare services by analyzing vast ...', 'position': 4}, {'title': '3 Ways AI Can Improve Revenue-Cycle Management | AHA', 'link': 'https://www.aha.org/aha-center-health-innovation-market-scan/2024-06-04-3-ways-ai-can-improve-revenue-cycle-management', 'snippet': 'New technologies like generative AI come with risks. Health systems should invest in mitigating these risks by establishing guardrails in data ...', 'position': 5}, {'title': 'AI in the Healthcare Industry | Balancing Innovation and Risk', 'link': 'https://www.bbrown.com/us/insight/ai-in-the-healthcare-industry/', 'snippet': 'The use of AI in the healthcare industry has major financial and economic impacts in terms of cost reduction and revenue creation.', 'position': 6}, {'title': 'Generative AI in Healthcare System and its Uses | Complete Guide', 'link': 'https://www.xenonstack.com/blog/generative-ai-healthcare-system', 'snippet': 'Generative AI in Healthcare Industry for drug discovery, disease diagnosis, patient care, medical imaging, and medical research.', 'position': 7}, {'title': 'Shaping the future of AI in healthcare through ethics and governance', 'link': 'https://www.nature.com/articles/s41599-024-02894-w', 'snippet': 'The purpose of this research is to identify and evaluate the technical, ethical and regulatory challenges related to the use of Artificial Intelligence (AI) in ...', 'position': 8}, {'title': 'The potential and thorny ethics of generative AI in healthcare', 'link': 'https://www.healthcaredive.com/news/generative-AI-healthcare-gpt-potential/648104/', 'snippet': 'Generative AI is showing early success in a number of use cases, including simplifying explanation of benefits notices and writing prior ...', 'position': 9}, {'title': 'The application of artificial intelligence in health financing: a scoping ...', 'link': 'https://resource-allocation.biomedcentral.com/articles/10.1186/s12962-023-00492-2', 'snippet': 'We discovered that AI has a significant impact on various aspects of health financing, such as governance, revenue raising, pooling, and strategic purchasing.', 'position': 10}], 'peopleAlsoAsk': [{'question': 'What is generative AI in healthcare trends?', 'snippet': 'Automated Segmentation: Generative AI can help to automatically segment organs or anomalies in medical images to save time for healthcare professionals. Pathology Prediction: Generative AI can analyze patterns in medical images to predict or identify pathological conditions, supporting early detection and intervention.\\nDec 2, 2024', 'title': 'Generative AI in Healthcare System and its Uses | Complete Guide', 'link': 'https://www.xenonstack.com/blog/generative-ai-healthcare-system'}, {'question': 'What is the use of generative AI in finance?', 'snippet': 'By analyzing performance data of financial products or portfolios, generative AI algorithms can generate insights and recommendations for optimizing performance. This can assist financial professionals in monitoring and improving the performance of their investments.', 'title': 'Generative AI in Financial Services: Use Cases, Benefits, and Risks', 'link': 'https://www.alpha-sense.com/blog/trends/generative-ai-in-financial-services/'}, {'question': 'What is the trend of AI in healthcare?', 'snippet': 'Machine Vision Improves Patient Care\\\\n\\\\n As these tools advance and more Internet of Medical Things sensors and cameras are added to patient rooms, more solutions will combine the AI capabilities of machine vision and ambient listening to improve proactive patient care as well as clinical workflows.', 'title': 'An Overview of 2025 AI Trends in Healthcare | HealthTech Magazine', 'link': 'https://healthtechmagazine.net/article/2025/01/overview-2025-ai-trends-healthcare'}], 'relatedSearches': [{'query': 'Generative AI in healthcare examples'}, {'query': 'Generative AI in healthcare PDF'}, {'query': 'AI RCM healthcare'}, {'query': 'GenAI healthcare use cases'}, {'query': 'Benefits of generative AI in healthcare'}, {'query': 'Disadvantages of artificial intelligence in healthcare'}, {'query': 'Challenges of AI in healthcare'}, {'query': 'Generative AI in healthcare 2024'}], 'credits': 1}\u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mMarket Research Analyst\u001b[00m\n",
            "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
            "Three significant trends shaping the AI industry are:\n",
            "\n",
            "1. **The Rise of Generative AI:** Generative AI, particularly large language models (LLMs) and AI agents, is rapidly transforming various sectors.  These models can create new content, ranging from text and images to code and music, pushing the boundaries of what AI can achieve.  The impact extends beyond creative applications; LLMs are being integrated into business workflows, automating tasks and improving efficiency. AI agents, capable of independent action and problem-solving, represent a significant advancement, promising further automation and even personalized assistance across diverse industries.  The long-term implications include significant workforce disruptions as tasks previously performed by humans become automated, but also the potential for entirely new industries and job creation in fields supporting and developing this technology.\n",
            "\n",
            "\n",
            "2. **Increased Focus on AI Safety and Ethics:** The increasing power of AI systems has highlighted the critical need for responsible development and deployment.  Concerns surrounding bias, fairness, transparency, and the potential misuse of AI are driving significant research and regulatory efforts.  The development of robust safety mechanisms and ethical guidelines is crucial to ensure that AI benefits humanity while minimizing potential risks.  This trend is not merely a technological challenge but a societal one, requiring collaboration between technologists, policymakers, and ethicists to establish frameworks for responsible AI development and governance. The long-term outcome will determine whether AI's benefits are broadly shared and its risks mitigated effectively.\n",
            "\n",
            "\n",
            "3. **Widespread AI Adoption Across Industries:**  AI is rapidly being integrated into various sectors, from healthcare and finance to manufacturing and transportation.  In healthcare, AI is improving diagnostics, drug discovery, and personalized medicine.  In finance, it is enhancing fraud detection, risk management, and algorithmic trading.  This widespread adoption reflects AI's growing maturity and its potential to deliver significant economic value across numerous sectors.  However, this adoption also necessitates addressing challenges related to data privacy, security, and the ethical implications of AI in specific contexts.  The long-term impact will be a reshaping of many industries, improving efficiency and productivity while requiring significant adaptation and workforce retraining in many sectors.\n",
            "```\u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mContent Writer\u001b[00m\n",
            "\u001b[95m## Task:\u001b[00m \u001b[92mWrite an engaging blog post about the AI industry, based on the research analyst’s summary. Draw inspiration from the latest blog posts in the directory.Step 1: The Content Writer will use the 'List files in directory' tool to obtain a list of all blog posts in the './blog-posts' directory.  This will provide an understanding of existing content and writing styles.\n",
            "\n",
            "Step 2: The writer will review the list of blog posts and select several examples that are considered to be well-written, engaging, and informative.  The selection criteria should focus on posts that utilize a clear and accessible writing style and demonstrate effective storytelling techniques.\n",
            "\n",
            "Step 3: The writer will use the 'Read a file's content' tool to access the content of the selected blog posts. The goal is to analyze their structure, tone, and style to draw inspiration for their own blog post. The key is to identify elements that make these blog posts effective and engaging. This includes understanding the opening hooks, use of examples, and overall flow of information.\n",
            "\n",
            "Step 4:  The writer will receive the summary of the top 3 AI trends from the Market Research Analyst (output of Task 1).  This summary will form the basis for the blog post content.  The writer will use this summary to organize the blog post into a logical and coherent structure.\n",
            "\n",
            "Step 5: The writer will craft a 4-paragraph blog post in Markdown format.  The first paragraph should act as a captivating introduction that hooks the reader and sets the stage.  The following three paragraphs should elaborate on each of the three trends identified in the research analyst's summary.  Each paragraph should explain the trend clearly, provide context, and highlight its significance, drawing inspiration from the analyzed blog posts in terms of style and engagement.\n",
            "\n",
            "Step 6:  The writer will ensure the blog post is written in an engaging, informative, and accessible manner, avoiding complex jargon.  The language should be clear, concise, and suitable for a broad audience.  The writer will review the blog post for grammar, spelling, punctuation, and clarity. The post's tone should be consistent and engaging throughout.  The final step is to ensure the blog post adheres to the 4-paragraph requirement and reflects the appropriate style learned from analyzing successful examples.\u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mContent Writer\u001b[00m\n",
            "\u001b[95m## Using tool:\u001b[00m \u001b[92mList files in directory\u001b[00m\n",
            "\u001b[95m## Tool Input:\u001b[00m \u001b[92m\n",
            "\"{}\"\u001b[00m\n",
            "\u001b[95m## Tool Output:\u001b[00m \u001b[92m\n",
            "File paths: \n",
            "-\u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mContent Writer\u001b[00m\n",
            "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
            "# The AI Revolution: Three Trends Shaping Our Future\n",
            "\n",
            "The world of artificial intelligence is moving at breakneck speed, transforming industries and reshaping our daily lives.  From creative tools that generate stunning art to algorithms that revolutionize healthcare, AI is no longer a futuristic fantasy; it's the present and the future. Three key trends are pushing this revolution forward, promising both incredible opportunities and critical challenges that we must address.\n",
            "\n",
            "\n",
            "One of the most exciting developments is the rise of generative AI.  Large language models (LLMs) like ChatGPT and image generators like DALL-E 2 are capable of creating incredibly realistic and original content – everything from poems and code to marketing copy and medical diagnoses.  These models are not just toys; they're being integrated into business workflows, streamlining tasks, and offering personalized experiences for customers.  While this technology brings the potential for increased efficiency and new creative avenues, it also raises important questions about job displacement and the responsible use of this powerful tool.\n",
            "\n",
            "\n",
            "Hand-in-hand with the advancement of AI capabilities comes a growing awareness of the ethical implications.  Bias in algorithms, data privacy concerns, and the potential for misuse are serious challenges that demand our attention.  Governments and organizations are grappling with the need for robust regulations and ethical guidelines to ensure that AI development is responsible and benefits humanity as a whole.  Transparency and accountability are crucial, and the ongoing dialogue between technologists, policymakers, and the public is essential for navigating the ethical complexities of this rapidly evolving field.\n",
            "\n",
            "\n",
            "Finally, the widespread adoption of AI across various sectors is undeniable.  From healthcare, where AI is assisting in diagnosis and drug discovery, to finance, where it's enhancing fraud detection and risk management, AI is proving its value across numerous industries. This adoption leads to increased efficiency and productivity, but also necessitates investment in education and retraining to equip the workforce for the changing landscape.  The long-term impact will be a transformation of how we work and live, making it crucial to address challenges like data security and privacy to ensure that this revolution benefits everyone.\n",
            "```\u001b[00m\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CrewOutput(raw=\"# The AI Revolution: Three Trends Shaping Our Future\\n\\nThe world of artificial intelligence is moving at breakneck speed, transforming industries and reshaping our daily lives.  From creative tools that generate stunning art to algorithms that revolutionize healthcare, AI is no longer a futuristic fantasy; it's the present and the future. Three key trends are pushing this revolution forward, promising both incredible opportunities and critical challenges that we must address.\\n\\n\\nOne of the most exciting developments is the rise of generative AI.  Large language models (LLMs) like ChatGPT and image generators like DALL-E 2 are capable of creating incredibly realistic and original content – everything from poems and code to marketing copy and medical diagnoses.  These models are not just toys; they're being integrated into business workflows, streamlining tasks, and offering personalized experiences for customers.  While this technology brings the potential for increased efficiency and new creative avenues, it also raises important questions about job displacement and the responsible use of this powerful tool.\\n\\n\\nHand-in-hand with the advancement of AI capabilities comes a growing awareness of the ethical implications.  Bias in algorithms, data privacy concerns, and the potential for misuse are serious challenges that demand our attention.  Governments and organizations are grappling with the need for robust regulations and ethical guidelines to ensure that AI development is responsible and benefits humanity as a whole.  Transparency and accountability are crucial, and the ongoing dialogue between technologists, policymakers, and the public is essential for navigating the ethical complexities of this rapidly evolving field.\\n\\n\\nFinally, the widespread adoption of AI across various sectors is undeniable.  From healthcare, where AI is assisting in diagnosis and drug discovery, to finance, where it's enhancing fraud detection and risk management, AI is proving its value across numerous industries. This adoption leads to increased efficiency and productivity, but also necessitates investment in education and retraining to equip the workforce for the changing landscape.  The long-term impact will be a transformation of how we work and live, making it crucial to address challenges like data security and privacy to ensure that this revolution benefits everyone.\\n```\", pydantic=None, json_dict=None, tasks_output=[TaskOutput(description='Research the latest trends in the AI industry and provide a summary.Step 1: The Market Research Analyst will utilize the \\'Search the internet with Serper\\' tool.  The search query will be crafted to focus on the most recent advancements in AI.  Specific keywords such as \"latest AI trends\", \"breakthroughs in artificial intelligence\", \"cutting-edge AI technologies\", and  \"emerging AI applications\" should be incorporated to ensure a comprehensive search. The search type should be set to \\'news\\' to prioritize recent developments.\\n\\nStep 2:  The analyst will carefully review the top 10 results returned by Serper.  The focus will be on identifying recurring themes and significant developments across multiple sources to ensure objectivity and avoid bias from individual articles.  Specific attention should be paid to identifying trends that are truly impactful and transformative, not just incremental improvements.\\n\\nStep 3: From the research in step 2, the analyst will identify and select the top three most impactful and significant trends.  These should be based on a combination of factors, including the level of innovation involved, the potential for wide-ranging effects, and the level of discussion and investment these developments are attracting within the industry.\\n\\nStep 4:  The analyst will write a concise summary of the three selected trends, explaining each trend in a clear and understandable way, avoiding technical jargon whenever possible.  The summary should also highlight the unique significance of each trend, providing a perspective that adds insightful value beyond merely describing the trends.  Consider the long-term implications, potential disruptions, and their impact on different industries or sectors.\\n\\nStep 5: The analyst will review the summary for clarity, accuracy, and conciseness, ensuring the information is factually sound and presented in a logical and compelling manner.  Any ambiguities or gaps in explanation will be addressed before finalizing the summary.', name=None, expected_output='A summary of the top 3 trending developments in the AI industry with a unique perspective on their significance.', summary='Research the latest trends in the AI industry and provide...', raw=\"Three significant trends shaping the AI industry are:\\n\\n1. **The Rise of Generative AI:** Generative AI, particularly large language models (LLMs) and AI agents, is rapidly transforming various sectors.  These models can create new content, ranging from text and images to code and music, pushing the boundaries of what AI can achieve.  The impact extends beyond creative applications; LLMs are being integrated into business workflows, automating tasks and improving efficiency. AI agents, capable of independent action and problem-solving, represent a significant advancement, promising further automation and even personalized assistance across diverse industries.  The long-term implications include significant workforce disruptions as tasks previously performed by humans become automated, but also the potential for entirely new industries and job creation in fields supporting and developing this technology.\\n\\n\\n2. **Increased Focus on AI Safety and Ethics:** The increasing power of AI systems has highlighted the critical need for responsible development and deployment.  Concerns surrounding bias, fairness, transparency, and the potential misuse of AI are driving significant research and regulatory efforts.  The development of robust safety mechanisms and ethical guidelines is crucial to ensure that AI benefits humanity while minimizing potential risks.  This trend is not merely a technological challenge but a societal one, requiring collaboration between technologists, policymakers, and ethicists to establish frameworks for responsible AI development and governance. The long-term outcome will determine whether AI's benefits are broadly shared and its risks mitigated effectively.\\n\\n\\n3. **Widespread AI Adoption Across Industries:**  AI is rapidly being integrated into various sectors, from healthcare and finance to manufacturing and transportation.  In healthcare, AI is improving diagnostics, drug discovery, and personalized medicine.  In finance, it is enhancing fraud detection, risk management, and algorithmic trading.  This widespread adoption reflects AI's growing maturity and its potential to deliver significant economic value across numerous sectors.  However, this adoption also necessitates addressing challenges related to data privacy, security, and the ethical implications of AI in specific contexts.  The long-term impact will be a reshaping of many industries, improving efficiency and productivity while requiring significant adaptation and workforce retraining in many sectors.\\n```\", pydantic=None, json_dict=None, agent='Market Research Analyst', output_format=<OutputFormat.RAW: 'raw'>), TaskOutput(description=\"Write an engaging blog post about the AI industry, based on the research analyst’s summary. Draw inspiration from the latest blog posts in the directory.Step 1: The Content Writer will use the 'List files in directory' tool to obtain a list of all blog posts in the './blog-posts' directory.  This will provide an understanding of existing content and writing styles.\\n\\nStep 2: The writer will review the list of blog posts and select several examples that are considered to be well-written, engaging, and informative.  The selection criteria should focus on posts that utilize a clear and accessible writing style and demonstrate effective storytelling techniques.\\n\\nStep 3: The writer will use the 'Read a file's content' tool to access the content of the selected blog posts. The goal is to analyze their structure, tone, and style to draw inspiration for their own blog post. The key is to identify elements that make these blog posts effective and engaging. This includes understanding the opening hooks, use of examples, and overall flow of information.\\n\\nStep 4:  The writer will receive the summary of the top 3 AI trends from the Market Research Analyst (output of Task 1).  This summary will form the basis for the blog post content.  The writer will use this summary to organize the blog post into a logical and coherent structure.\\n\\nStep 5: The writer will craft a 4-paragraph blog post in Markdown format.  The first paragraph should act as a captivating introduction that hooks the reader and sets the stage.  The following three paragraphs should elaborate on each of the three trends identified in the research analyst's summary.  Each paragraph should explain the trend clearly, provide context, and highlight its significance, drawing inspiration from the analyzed blog posts in terms of style and engagement.\\n\\nStep 6:  The writer will ensure the blog post is written in an engaging, informative, and accessible manner, avoiding complex jargon.  The language should be clear, concise, and suitable for a broad audience.  The writer will review the blog post for grammar, spelling, punctuation, and clarity. The post's tone should be consistent and engaging throughout.  The final step is to ensure the blog post adheres to the 4-paragraph requirement and reflects the appropriate style learned from analyzing successful examples.\", name=None, expected_output='A 4-paragraph blog post formatted in markdown with engaging, informative, and accessible content, avoiding complex jargon.', summary='Write an engaging blog post about the AI industry, based...', raw=\"# The AI Revolution: Three Trends Shaping Our Future\\n\\nThe world of artificial intelligence is moving at breakneck speed, transforming industries and reshaping our daily lives.  From creative tools that generate stunning art to algorithms that revolutionize healthcare, AI is no longer a futuristic fantasy; it's the present and the future. Three key trends are pushing this revolution forward, promising both incredible opportunities and critical challenges that we must address.\\n\\n\\nOne of the most exciting developments is the rise of generative AI.  Large language models (LLMs) like ChatGPT and image generators like DALL-E 2 are capable of creating incredibly realistic and original content – everything from poems and code to marketing copy and medical diagnoses.  These models are not just toys; they're being integrated into business workflows, streamlining tasks, and offering personalized experiences for customers.  While this technology brings the potential for increased efficiency and new creative avenues, it also raises important questions about job displacement and the responsible use of this powerful tool.\\n\\n\\nHand-in-hand with the advancement of AI capabilities comes a growing awareness of the ethical implications.  Bias in algorithms, data privacy concerns, and the potential for misuse are serious challenges that demand our attention.  Governments and organizations are grappling with the need for robust regulations and ethical guidelines to ensure that AI development is responsible and benefits humanity as a whole.  Transparency and accountability are crucial, and the ongoing dialogue between technologists, policymakers, and the public is essential for navigating the ethical complexities of this rapidly evolving field.\\n\\n\\nFinally, the widespread adoption of AI across various sectors is undeniable.  From healthcare, where AI is assisting in diagnosis and drug discovery, to finance, where it's enhancing fraud detection and risk management, AI is proving its value across numerous industries. This adoption leads to increased efficiency and productivity, but also necessitates investment in education and retraining to equip the workforce for the changing landscape.  The long-term impact will be a transformation of how we work and live, making it crucial to address challenges like data security and privacy to ensure that this revolution benefits everyone.\\n```\", pydantic=None, json_dict=None, agent='Content Writer', output_format=<OutputFormat.RAW: 'raw'>)], token_usage=UsageMetrics(total_tokens=11856, prompt_tokens=10643, cached_prompt_tokens=0, completion_tokens=1213, successful_requests=5))"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: import markdown for jupyter display\n",
        "\n",
        "from IPython.display import Markdown\n",
        "\n",
        "def display_markdown_file(file_path):\n",
        "    with open(file_path, 'r') as f:\n",
        "        content = f.read()\n",
        "    display(Markdown(content))\n",
        "\n",
        "# Example usage: Assuming 'blog-posts/new_post.md' is the file generated by your code\n",
        "display_markdown_file('blog-posts/new_post.md')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        },
        "id": "NRv779rBMN3U",
        "outputId": "281cdae5-1029-4804-ee41-28052e8de4d3"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "# The AI Revolution: Three Trends Shaping Our Future\n\nThe world of artificial intelligence is moving at breakneck speed, transforming industries and reshaping our daily lives.  From creative tools that generate stunning art to algorithms that revolutionize healthcare, AI is no longer a futuristic fantasy; it's the present and the future. Three key trends are pushing this revolution forward, promising both incredible opportunities and critical challenges that we must address.\n\n\nOne of the most exciting developments is the rise of generative AI.  Large language models (LLMs) like ChatGPT and image generators like DALL-E 2 are capable of creating incredibly realistic and original content – everything from poems and code to marketing copy and medical diagnoses.  These models are not just toys; they're being integrated into business workflows, streamlining tasks, and offering personalized experiences for customers.  While this technology brings the potential for increased efficiency and new creative avenues, it also raises important questions about job displacement and the responsible use of this powerful tool.\n\n\nHand-in-hand with the advancement of AI capabilities comes a growing awareness of the ethical implications.  Bias in algorithms, data privacy concerns, and the potential for misuse are serious challenges that demand our attention.  Governments and organizations are grappling with the need for robust regulations and ethical guidelines to ensure that AI development is responsible and benefits humanity as a whole.  Transparency and accountability are crucial, and the ongoing dialogue between technologists, policymakers, and the public is essential for navigating the ethical complexities of this rapidly evolving field.\n\n\nFinally, the widespread adoption of AI across various sectors is undeniable.  From healthcare, where AI is assisting in diagnosis and drug discovery, to finance, where it's enhancing fraud detection and risk management, AI is proving its value across numerous industries. This adoption leads to increased efficiency and productivity, but also necessitates investment in education and retraining to equip the workforce for the changing landscape.  The long-term impact will be a transformation of how we work and live, making it crucial to address challenges like data security and privacy to ensure that this revolution benefits everyone.\n```"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating your own Tools"
      ],
      "metadata": {
        "id": "rMPlKb9l0sk6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from crewai.tools import BaseTool\n",
        "from pydantic import BaseModel, Field\n",
        "from typing import Type\n",
        "\n",
        "class MyToolInput(BaseModel):\n",
        "    \"\"\"Input schema for MyCustomTool.\"\"\"\n",
        "    student_name: str = Field(..., description=\"Student name\")\n",
        "    student_roll_no : int = Field(..., description=\"student id\")\n",
        "\n",
        "class PiaicStudentCard(BaseTool):\n",
        "    name: str = \"Piaic student card generator\"\n",
        "    description: str = \"this function will create Piaic student card\"\n",
        "    args_schema: Type[BaseModel] = MyToolInput\n",
        "\n",
        "    def _run(self, student_name: str, student_roll_no: int ) -> str:\n",
        "        # Your tool's logic here\n",
        "        return f\"\"\"PIAIC student card\n",
        "student name: {student_name}\n",
        "student roll no: {student_roll_no}\n",
        "Pakistan zindabd!\n",
        "        \"\"\""
      ],
      "metadata": {
        "id": "ortq46tpxmW_"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from crewai.tools import tool\n",
        "\n",
        "@tool(\"PIAIC fee update\")\n",
        "def my_tool(roll_no: int) -> dict | str:\n",
        "    \"\"\"this function search piaic student fee updates, it will required roll no of PIAIC student\"\"\"\n",
        "    #database\n",
        "\n",
        "    data = {100:'paid',\n",
        "         200:'unpaid'}\n",
        "\n",
        "\n",
        "    status = data.get(roll_no)\n",
        "\n",
        "    if status:\n",
        "      return {\"status\": status}\n",
        "    else:\n",
        "      return \"student not found\"\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "f8rtrAviRgAn"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from crewai import LLM\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "llm1=LLM(model=\"gemini/gemini-1.5-flash\")"
      ],
      "metadata": {
        "id": "M-Xo1Mwh_WiV"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from crewai import Agent, Task, Crew\n",
        "\n",
        "card = PiaicStudentCard()\n",
        "\n",
        "\n",
        "piaic_manager = Agent(\n",
        "    role=\"PIAIC manager\",\n",
        "    goal = \"Manage all quries regarding PIAIC and you will use only relevant tools for student query\",\n",
        "    backstory=\"\"\"You are a master at understanding people and their preferences.\"\"\",\n",
        "    tools=[card, my_tool],\n",
        "    verbose=True,\n",
        "    llm=llm1\n",
        ")\n",
        "\n",
        "piaic_card_creator = Task(\n",
        "    description=\"you will be responsible for all PIAIC relevant operations, student query '{query}' you must be know how to answer his question based on final context\",\n",
        "    expected_output=\"final query answer only\",\n",
        "    agent=piaic_manager\n",
        ")\n",
        "\n",
        "crew = Crew(\n",
        "    agents=[piaic_manager],\n",
        "    tasks=[piaic_card_creator],\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "result = crew.kickoff(inputs={\n",
        "    \"query\":\"I'm PIAIC student my name is Muhammad Qasim and my roll number is 100, can you create my student card.\"\n",
        "})\n",
        "\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eL5p9zmc189a",
        "outputId": "b600436a-091a-457b-c650-d94a6ab23988"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:opentelemetry.trace:Overriding of current TracerProvider is not allowed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mPIAIC manager\u001b[00m\n",
            "\u001b[95m## Task:\u001b[00m \u001b[92myou will be responsible for all PIAIC relevant operations, student query 'I'm PIAIC student my name is Muhammad Qasim and my roll number is 100, can you create my student card.' you must be know how to answer his question based on final context\u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mPIAIC manager\u001b[00m\n",
            "\u001b[95m## Using tool:\u001b[00m \u001b[92mPiaic student card generator\u001b[00m\n",
            "\u001b[95m## Tool Input:\u001b[00m \u001b[92m\n",
            "\"{\\\"student_name\\\": \\\"Muhammad Qasim\\\", \\\"student_roll_no\\\": 100}\"\u001b[00m\n",
            "\u001b[95m## Tool Output:\u001b[00m \u001b[92m\n",
            "PIAIC student card\n",
            "student name: Muhammad Qasim\n",
            "student roll no: 100\n",
            "Pakistan zindabd!\n",
            "        \u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mPIAIC manager\u001b[00m\n",
            "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
            "PIAIC student card\n",
            "student name: Muhammad Qasim\n",
            "student roll no: 100\n",
            "Pakistan zindabd!\n",
            "```\u001b[00m\n",
            "\n",
            "\n",
            "PIAIC student card\n",
            "student name: Muhammad Qasim\n",
            "student roll no: 100\n",
            "Pakistan zindabd!\n",
            "```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = crew.kickoff(inputs={\n",
        "    \"query\":\"I'm PIAIC student  my roll number is 100, can you share my fee updates?.\"\n",
        "})\n",
        "\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q1KC8MMJSes1",
        "outputId": "e4af44aa-97df-4a65-8d9b-434c6c6e8eee"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mPIAIC manager\u001b[00m\n",
            "\u001b[95m## Task:\u001b[00m \u001b[92myou will be responsible for all PIAIC relevant operations, student query 'I'm PIAIC student  my roll number is 100, can you share my fee updates?.' you must be know how to answer his question based on final context\u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mPIAIC manager\u001b[00m\n",
            "\u001b[95m## Using tool:\u001b[00m \u001b[92mPIAIC fee update\u001b[00m\n",
            "\u001b[95m## Tool Input:\u001b[00m \u001b[92m\n",
            "\"{\\\"roll_no\\\": 100}\"\u001b[00m\n",
            "\u001b[95m## Tool Output:\u001b[00m \u001b[92m\n",
            "{'status': 'paid'}\u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mPIAIC manager\u001b[00m\n",
            "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
            "Your fee is paid.\n",
            "```\u001b[00m\n",
            "\n",
            "\n",
            "Your fee is paid.\n",
            "```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = crew.kickoff(inputs={\n",
        "    \"query\":\"I'm PIAIC student  my roll number is 200, can you share my fee updates?.\"\n",
        "})\n",
        "\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vlUXsdNGQSNX",
        "outputId": "a7bc82c9-c21f-4048-b7c6-3ecf055eefa1"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mPIAIC manager\u001b[00m\n",
            "\u001b[95m## Task:\u001b[00m \u001b[92myou will be responsible for all PIAIC relevant operations, student query 'I'm PIAIC student  my roll number is 200, can you share my fee updates?.' you must be know how to answer his question based on final context\u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mPIAIC manager\u001b[00m\n",
            "\u001b[95m## Using tool:\u001b[00m \u001b[92mPIAIC fee update\u001b[00m\n",
            "\u001b[95m## Tool Input:\u001b[00m \u001b[92m\n",
            "\"{\\\"roll_no\\\": 200}\"\u001b[00m\n",
            "\u001b[95m## Tool Output:\u001b[00m \u001b[92m\n",
            "{'status': 'unpaid'}\n",
            "\n",
            "\n",
            "You ONLY have access to the following tools, and should NEVER make up tools that are not listed here:\n",
            "\n",
            "Tool Name: Piaic student card generator\n",
            "Tool Arguments: {'student_name': {'description': 'Student name', 'type': 'str'}, 'student_roll_no': {'description': 'student id', 'type': 'int'}}\n",
            "Tool Description: this function will create Piaic student card\n",
            "Tool Name: PIAIC fee update\n",
            "Tool Arguments: {'roll_no': {'description': None, 'type': 'int'}}\n",
            "Tool Description: this function search piaic student fee updates, it will required roll no of PIAIC student\n",
            "\n",
            "IMPORTANT: Use the following format in your response:\n",
            "\n",
            "```\n",
            "Thought: you should always think about what to do\n",
            "Action: the action to take, only one name of [Piaic student card generator, PIAIC fee update], just the name, exactly as it's written.\n",
            "Action Input: the input to the action, just a simple JSON object, enclosed in curly braces, using \" to wrap keys and values.\n",
            "Observation: the result of the action\n",
            "```\n",
            "\n",
            "Once all necessary information is gathered, return the following format:\n",
            "\n",
            "```\n",
            "Thought: I now know the final answer\n",
            "Final Answer: the final answer to the original input question\n",
            "```\u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mPIAIC manager\u001b[00m\n",
            "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
            "Your fee status is unpaid.\n",
            "```\u001b[00m\n",
            "\n",
            "\n",
            "Your fee status is unpaid.\n",
            "```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Process"
      ],
      "metadata": {
        "id": "xx5Sbl5PVwep"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from crewai import Agent, Task, Crew, Process\n",
        "\n",
        "# Importing crewAI tools\n",
        "from crewai_tools import (\n",
        "    DirectoryReadTool,\n",
        "    FileReadTool,\n",
        "    SerperDevTool,\n",
        "    WebsiteSearchTool\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "# Instantiate tools\n",
        "docs_tool = DirectoryReadTool(directory='./blog-posts2')\n",
        "file_tool = FileReadTool()\n",
        "search_tool = SerperDevTool()\n",
        "web_rag_tool = WebsiteSearchTool()\n",
        "\n",
        "# Define your agents\n",
        "researcher = Agent(\n",
        "    role=\"Researcher\",\n",
        "    goal=\"Conduct thorough research and analysis on AI and AI agents\",\n",
        "    backstory=\"You're an expert researcher, specialized in technology, software engineering, AI, and startups. You work as a freelancer and are currently researching for a new client.\",\n",
        "    allow_delegation=False,\n",
        "    tools=[search_tool,web_rag_tool],\n",
        "    llm=llm1\n",
        ")\n",
        "\n",
        "writer = Agent(\n",
        "    role=\"Senior Writer\",\n",
        "    goal=\"Create compelling content about AI and AI agents\",\n",
        "    backstory=\"You're a senior writer, specialized in technology, software engineering, AI, and startups. You work as a freelancer and are currently writing content for a new client.\",\n",
        "    allow_delegation=False,\n",
        "    tools=[docs_tool,file_tool],\n",
        "    llm=llm1\n",
        ")\n",
        "\n",
        "# Define your task\n",
        "task = Task(\n",
        "    description=\"Generate a list of 5 interesting ideas for an article, then write one captivating paragraph for each idea that showcases the potential of a full article on this topic. Return the list of ideas with their paragraphs and your notes.\",\n",
        "    expected_output=\"5 bullet points, each with a paragraph and accompanying notes.\",\n",
        ")\n",
        "\n",
        "# Define the manager agent\n",
        "manager = Agent(\n",
        "    role=\"Project Manager\",\n",
        "    goal=\"Efficiently manage the crew and ensure high-quality task completion\",\n",
        "    backstory=\"You're an experienced project manager, skilled in overseeing complex projects and guiding teams to success. Your role is to coordinate the efforts of the crew members, ensuring that each task is completed on time and to the highest standard.\",\n",
        "    allow_delegation=True,\n",
        "    llm=llm1\n",
        ")\n",
        "\n",
        "# Instantiate your crew with a custom manager\n",
        "crew = Crew(\n",
        "    agents=[researcher, writer],\n",
        "    tasks=[task],\n",
        "    manager_agent=manager,\n",
        "    function_calling_llm=llm1,\n",
        "    process=Process.hierarchical,\n",
        "    verbose=True\n",
        "\n",
        ")\n",
        "\n",
        "# Start the crew's work\n",
        "result = crew.kickoff()\n",
        "from IPython.display import Markdown\n",
        "\n",
        "Markdown(result.raw)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "DPHWMms13Vj0",
        "outputId": "df5abbbf-a1e1-413c-f8e0-cdcca9d3d778"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:opentelemetry.trace:Overriding of current TracerProvider is not allowed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mProject Manager\u001b[00m\n",
            "\u001b[95m## Task:\u001b[00m \u001b[92mGenerate a list of 5 interesting ideas for an article, then write one captivating paragraph for each idea that showcases the potential of a full article on this topic. Return the list of ideas with their paragraphs and your notes.\u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mProject Manager\u001b[00m\n",
            "\u001b[95m## Thought:\u001b[00m \u001b[92m```tool_code\n",
            "Thought: I need to delegate the task of generating article ideas to the Senior Writer and then ask the Researcher to help refine them.  I'll then delegate the paragraph writing to the Senior Writer.\u001b[00m\n",
            "\u001b[95m## Using tool:\u001b[00m \u001b[92mDelegate work to coworker\u001b[00m\n",
            "\u001b[95m## Tool Input:\u001b[00m \u001b[92m\n",
            "\"{\\\"task\\\": {\\\"description\\\": \\\"Generate 5 interesting article ideas related to [insert any relevant field here, if needed, otherwise leave blank].  Ideas should be unique and have potential for a full-length article.  Each idea should be concise, one sentence per idea.\\\", \\\"type\\\": \\\"str\\\"}, \\\"context\\\": {\\\"description\\\": \\\"The goal is to create a list of 5 engaging article ideas that demonstrate the potential for a full-length article.  The ideas should be diverse and interesting to a broad audience. No specific topic is needed, so choose freely!\\\", \\\"type\\\": \\\"str\\\"}, \\\"coworker\\\": {\\\"description\\\": \\\"Senior Writer\\\", \\\"type\\\": \\\"str\\\"}}\"\u001b[00m\n",
            "\u001b[95m## Tool Output:\u001b[00m \u001b[92m\n",
            "\n",
            "I encountered an error while trying to use the tool. This was the error: unhashable type: 'dict'.\n",
            " Tool Delegate work to coworker accepts these inputs: Tool Name: Delegate work to coworker\n",
            "Tool Arguments: {'task': {'description': 'The task to delegate', 'type': 'str'}, 'context': {'description': 'The context for the task', 'type': 'str'}, 'coworker': {'description': 'The role/name of the coworker to delegate to', 'type': 'str'}}\n",
            "Tool Description: Delegate a specific task to one of the following coworkers: Researcher, Senior Writer\n",
            "The input to this tool should be the coworker, the task you want them to do, and ALL necessary context to execute the task, they know nothing about the task, so share absolute everything you know, don't reference things but instead explain them..\n",
            "Moving on then. I MUST either use a tool (use one at time) OR give my best final answer not both at the same time. When responding, I must use the following format:\n",
            "\n",
            "```\n",
            "Thought: you should always think about what to do\n",
            "Action: the action to take, should be one of [Delegate work to coworker, Ask question to coworker]\n",
            "Action Input: the input to the action, dictionary enclosed in curly braces\n",
            "Observation: the result of the action\n",
            "```\n",
            "This Thought/Action/Action Input/Result can repeat N times. Once I know the final answer, I must return the following format:\n",
            "\n",
            "```\n",
            "Thought: I now can give a great answer\n",
            "Final Answer: Your final answer must be the great and the most complete as possible, it must be outcome described\n",
            "\n",
            "```\u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mProject Manager\u001b[00m\n",
            "\u001b[95m## Thought:\u001b[00m \u001b[92mThought: I will try again to delegate the task, fixing the previous error.  I'll give more explicit instructions to avoid ambiguity.\u001b[00m\n",
            "\u001b[95m## Using tool:\u001b[00m \u001b[92mDelegate work to coworker\u001b[00m\n",
            "\u001b[95m## Tool Input:\u001b[00m \u001b[92m\n",
            "\"{\\\"task\\\": {\\\"description\\\": \\\"Generate 5 interesting and unique article ideas.  Each idea should be expressed in a single, concise sentence. \\\", \\\"type\\\": \\\"str\\\"}, \\\"context\\\": {\\\"description\\\": \\\"The goal is to provide 5 captivating article ideas that are suitable for a full-length article.  The ideas should be diverse and interesting to a broad audience. No specific topic is required; creativity and originality are encouraged.\\\", \\\"type\\\": \\\"str\\\"}, \\\"coworker\\\": {\\\"description\\\": \\\"Senior Writer\\\", \\\"type\\\": \\\"str\\\"}}\"\u001b[00m\n",
            "\u001b[95m## Tool Output:\u001b[00m \u001b[92m\n",
            "\n",
            "I encountered an error while trying to use the tool. This was the error: unhashable type: 'dict'.\n",
            " Tool Delegate work to coworker accepts these inputs: Tool Name: Delegate work to coworker\n",
            "Tool Arguments: {'task': {'description': 'The task to delegate', 'type': 'str'}, 'context': {'description': 'The context for the task', 'type': 'str'}, 'coworker': {'description': 'The role/name of the coworker to delegate to', 'type': 'str'}}\n",
            "Tool Description: Delegate a specific task to one of the following coworkers: Researcher, Senior Writer\n",
            "The input to this tool should be the coworker, the task you want them to do, and ALL necessary context to execute the task, they know nothing about the task, so share absolute everything you know, don't reference things but instead explain them..\n",
            "Moving on then. I MUST either use a tool (use one at time) OR give my best final answer not both at the same time. When responding, I must use the following format:\n",
            "\n",
            "```\n",
            "Thought: you should always think about what to do\n",
            "Action: the action to take, should be one of [Delegate work to coworker, Ask question to coworker]\n",
            "Action Input: the input to the action, dictionary enclosed in curly braces\n",
            "Observation: the result of the action\n",
            "```\n",
            "This Thought/Action/Action Input/Result can repeat N times. Once I know the final answer, I must return the following format:\n",
            "\n",
            "```\n",
            "Thought: I now can give a great answer\n",
            "Final Answer: Your final answer must be the great and the most complete as possible, it must be outcome described\n",
            "\n",
            "```\u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mProject Manager\u001b[00m\n",
            "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
            "* The Unexpected Benefits of Learning a New Language:  Explore the cognitive, social, and career advantages of multilingualism, challenging common misconceptions and highlighting surprising benefits that extend beyond communication.  Notes:  Focus on cognitive research (improved memory, multitasking), social benefits (increased empathy, cross-cultural understanding), and career prospects.\n",
            "\n",
            "* The Psychology of Procrastination: Delve into the psychological mechanisms behind procrastination, offering practical strategies and coping mechanisms to help readers overcome this common productivity barrier. Notes: Include different types of procrastination, cognitive biases involved, and evidence-based techniques for overcoming it.\n",
            "\n",
            "* The Power of Micro-Habits:  Examine the transformative potential of tiny, consistent actions, demonstrating how accumulating small changes can lead to significant improvements in various aspects of life. Notes: Provide specific examples (exercise, reading, learning) and emphasize the importance of consistency over intensity.\n",
            "\n",
            "* Redefining Success:  Challenge conventional definitions of success, exploring alternative perspectives and promoting a more holistic and personally fulfilling approach to goal setting and achievement. Notes:  Include interviews with people who have unconventional definitions of success and discuss the importance of personal values.\n",
            "\n",
            "* The Future of Work:  Analyze current trends in the workplace, examining the impact of technology, globalization, and demographic shifts on the future of employment and the skills needed to thrive in a rapidly evolving job market.  Notes: Include data on future job markets and projections, potential job displacement due to AI, and the need for adaptable skills and lifelong learning.\n",
            "```\u001b[00m\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "* The Unexpected Benefits of Learning a New Language:  Explore the cognitive, social, and career advantages of multilingualism, challenging common misconceptions and highlighting surprising benefits that extend beyond communication.  Notes:  Focus on cognitive research (improved memory, multitasking), social benefits (increased empathy, cross-cultural understanding), and career prospects.\n\n* The Psychology of Procrastination: Delve into the psychological mechanisms behind procrastination, offering practical strategies and coping mechanisms to help readers overcome this common productivity barrier. Notes: Include different types of procrastination, cognitive biases involved, and evidence-based techniques for overcoming it.\n\n* The Power of Micro-Habits:  Examine the transformative potential of tiny, consistent actions, demonstrating how accumulating small changes can lead to significant improvements in various aspects of life. Notes: Provide specific examples (exercise, reading, learning) and emphasize the importance of consistency over intensity.\n\n* Redefining Success:  Challenge conventional definitions of success, exploring alternative perspectives and promoting a more holistic and personally fulfilling approach to goal setting and achievement. Notes:  Include interviews with people who have unconventional definitions of success and discuss the importance of personal values.\n\n* The Future of Work:  Analyze current trends in the workplace, examining the impact of technology, globalization, and demographic shifts on the future of employment and the skills needed to thrive in a rapidly evolving job market.  Notes: Include data on future job markets and projections, potential job displacement due to AI, and the need for adaptable skills and lifelong learning.\n```"
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Advance Tools"
      ],
      "metadata": {
        "id": "RuhYj5rQlCLG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel, Field\n",
        "\n",
        "class TeacherAssignmentOutPut(BaseModel):\n",
        "  score :int  = Field(..., description=\"student assignment score\")\n",
        "  feedback : str = Field(..., description=\"teacher feedback\")\n",
        "  question : str = Field(..., description=\"question\")\n",
        "  answer : str = Field(..., description=\"python code for markdown format\")"
      ],
      "metadata": {
        "id": "7ni_Ka-deeMe"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "source": [
        "from crewai import Agent\n",
        "from crewai_tools import CodeInterpreterTool\n",
        "from crewai import Task, Crew, Process\n",
        "\n",
        "teacher = Agent(\n",
        "    role=\"AI teacher\",\n",
        "    goal=\"you are Agentic AI teacher you have to check python assignment code submission.\",\n",
        "    backstory=\"you have to check student python code submission.\",\n",
        "    tools=[CodeInterpreterTool()],\n",
        "    llm=llm1\n",
        ")\n",
        "\n",
        "assignment_check = Task(\n",
        "    description=\"you are Agentic AI teacher you have to check python assignment code submission. question: '''{qestion}''' student solution : '''{solution}''' \",\n",
        "    expected_output=\"final code is runing, assign number between 1-10\",\n",
        "    output_pydantic=TeacherAssignmentOutPut,\n",
        "    agent=teacher # Added the missing agent here\n",
        ")\n",
        "\n",
        "\n",
        "crew = Crew(\n",
        "    agents=[teacher],\n",
        "    tasks=[assignment_check],\n",
        "    process=Process.sequential,\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "question = \"create function add two numbers\"\n",
        "\n",
        "solution = \"\"\"\n",
        "def add_two_number(num1 : int , num2 : int):\n",
        "  return num1 + num2\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "result = crew.kickoff(inputs={\n",
        "    \"qestion\": question,\n",
        "    \"solution\" : solution\n",
        "})\n",
        "\n",
        "print(result)"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AsEHDn2eogrp",
        "outputId": "1e6f6fff-eaac-4741-a9ff-aacc2d8ce357"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:opentelemetry.trace:Overriding of current TracerProvider is not allowed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mAI teacher\u001b[00m\n",
            "\u001b[95m## Task:\u001b[00m \u001b[92myou are Agentic AI teacher you have to check python assignment code submission. question: '''create function add two numbers''' student solution : '''\n",
            "def add_two_number(num1 : int , num2 : int):\n",
            "  return num1 + num2\n",
            "\n",
            "''' \u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mAI teacher\u001b[00m\n",
            "\u001b[95m## Thought:\u001b[00m \u001b[92mThought:I need to run the student's code to check its correctness and then provide a score and feedback.\u001b[00m\n",
            "\u001b[95m## Using tool:\u001b[00m \u001b[92mCode Interpreter\u001b[00m\n",
            "\u001b[95m## Tool Input:\u001b[00m \u001b[92m\n",
            "\"{\\\"code\\\": \\\"def add_two_number(num1 : int , num2 : int):\\\\n  return num1 + num2\\\\n\\\\nprint(add_two_number(2,3))\\\\nprint(add_two_number(-1,1))\\\\nprint(add_two_number(0,0))\\\", \\\"libraries_used\\\": []}\"\u001b[00m\n",
            "\u001b[95m## Tool Output:\u001b[00m \u001b[92m\n",
            "\n",
            "I encountered an error while trying to use the tool. This was the error: Error while fetching server API version: ('Connection aborted.', FileNotFoundError(2, 'No such file or directory')).\n",
            " Tool Code Interpreter accepts these inputs: Tool Name: Code Interpreter\n",
            "Tool Arguments: {'code': {'description': 'Python3 code used to be interpreted in the Docker container. ALWAYS PRINT the final result and the output of the code', 'type': 'str'}, 'libraries_used': {'description': 'List of libraries used in the code with proper installing names separated by commas. Example: numpy,pandas,beautifulsoup4', 'type': 'list[str]'}}\n",
            "Tool Description: Interprets Python3 code strings with a final print statement..\n",
            "Moving on then. I MUST either use a tool (use one at time) OR give my best final answer not both at the same time. When responding, I must use the following format:\n",
            "\n",
            "```\n",
            "Thought: you should always think about what to do\n",
            "Action: the action to take, should be one of [Code Interpreter]\n",
            "Action Input: the input to the action, dictionary enclosed in curly braces\n",
            "Observation: the result of the action\n",
            "```\n",
            "This Thought/Action/Action Input/Result can repeat N times. Once I know the final answer, I must return the following format:\n",
            "\n",
            "```\n",
            "Thought: I now can give a great answer\n",
            "Final Answer: Your final answer must be the great and the most complete as possible, it must be outcome described\n",
            "\n",
            "```\u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mAI teacher\u001b[00m\n",
            "\u001b[95m## Thought:\u001b[00m \u001b[92mThought:The error suggests a problem with the Code Interpreter's connection or environment.  I'll try a simpler test.  If that fails, I'll provide feedback based on visual inspection of the code.\u001b[00m\n",
            "\u001b[95m## Using tool:\u001b[00m \u001b[92mCode Interpreter\u001b[00m\n",
            "\u001b[95m## Tool Input:\u001b[00m \u001b[92m\n",
            "\"{\\\"code\\\": \\\"def add_two_number(num1 : int , num2 : int):\\\\n  return num1 + num2\\\\nprint(add_two_number(5,3))\\\", \\\"libraries_used\\\": []}\"\u001b[00m\n",
            "\u001b[95m## Tool Output:\u001b[00m \u001b[92m\n",
            "\n",
            "I encountered an error while trying to use the tool. This was the error: Error while fetching server API version: ('Connection aborted.', FileNotFoundError(2, 'No such file or directory')).\n",
            " Tool Code Interpreter accepts these inputs: Tool Name: Code Interpreter\n",
            "Tool Arguments: {'code': {'description': 'Python3 code used to be interpreted in the Docker container. ALWAYS PRINT the final result and the output of the code', 'type': 'str'}, 'libraries_used': {'description': 'List of libraries used in the code with proper installing names separated by commas. Example: numpy,pandas,beautifulsoup4', 'type': 'list[str]'}}\n",
            "Tool Description: Interprets Python3 code strings with a final print statement..\n",
            "Moving on then. I MUST either use a tool (use one at time) OR give my best final answer not both at the same time. When responding, I must use the following format:\n",
            "\n",
            "```\n",
            "Thought: you should always think about what to do\n",
            "Action: the action to take, should be one of [Code Interpreter]\n",
            "Action Input: the input to the action, dictionary enclosed in curly braces\n",
            "Observation: the result of the action\n",
            "```\n",
            "This Thought/Action/Action Input/Result can repeat N times. Once I know the final answer, I must return the following format:\n",
            "\n",
            "```\n",
            "Thought: I now can give a great answer\n",
            "Final Answer: Your final answer must be the great and the most complete as possible, it must be outcome described\n",
            "\n",
            "```\u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mAI teacher\u001b[00m\n",
            "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
            "{\n",
            "  \"score\": 9,\n",
            "  \"feedback\": \"The code correctly defines a function to add two numbers.  The type hints are a good addition.  Consider adding some error handling (e.g., checking for non-numeric inputs) to make it more robust.\",\n",
            "  \"question\": \"create function add two numbers\",\n",
            "  \"answer\": \"def add_two_number(num1 : int , num2 : int):\\n  return num1 + num2\"\n",
            "}\u001b[00m\n",
            "\n",
            "\n",
            "score=9 feedback='The code correctly defines a function to add two numbers.  The type hints are a good addition.  Consider adding some error handling (e.g., checking for non-numeric inputs) to make it more robust.' question='create function add two numbers' answer='def add_two_number(num1 : int , num2 : int):\\n  return num1 + num2'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1LJw70VxDTCO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result.to_dict()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CTDw4geAnxIA",
        "outputId": "0cf0ece5-fbb3-4721-85f2-7f53b989c193"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'score': 9,\n",
              " 'feedback': 'The code is correct and defines a function that adds two numbers. The type hints are a good addition. A small improvement could be adding a docstring to explain what the function does.',\n",
              " 'question': 'create function add two numbers',\n",
              " 'answer': 'def add_two_number(num1 : int , num2 : int):\\n  return num1 + num2'}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for k,v in result.to_dict().items():\n",
        "  print(str(\"*\"*10) + str(k) + str(\"*\"*10))\n",
        "  display(v)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "id": "jk9bcz1hrCer",
        "outputId": "173966b9-5cfd-4c9f-97ad-767d4a3cd163"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**********score**********\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**********feedback**********\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\"The function correctly adds two numbers.  Consider adding docstrings for better readability and to explain the function's purpose.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**********question**********\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'create function add two numbers'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**********answer**********\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'def add_two_number(num1, num2):\\n  return num1 + num2\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "W78nXiRdtUxn"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}