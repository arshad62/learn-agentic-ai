{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arshad62/learn-agentic-ai/blob/main/12_langchain_ecosystem/langgraph/course-notebooks/module-3/5_time_travel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ba98beac-d461-4d7d-878a-11beca03ea1c",
      "metadata": {
        "id": "ba98beac-d461-4d7d-878a-11beca03ea1c"
      },
      "source": [
        "# Time travel\n",
        "\n",
        "## Review\n",
        "\n",
        "We discussed motivations for human-in-the-loop:\n",
        "\n",
        "(1) `Approval` - We can interrupt our agent, surface state to a user, and allow the user to accept an action\n",
        "\n",
        "(2) `Debugging` - We can rewind the graph to reproduce or avoid issues\n",
        "\n",
        "(3) `Editing` - You can modify the state\n",
        "\n",
        "We showed how breakpoints can stop the graph at specific nodes or allow the graph to dynamically interrupt itself.\n",
        "\n",
        "Then we showed how to proceed with human approval or directly edit the graph state with human feedback.\n",
        "\n",
        "## Goals\n",
        "\n",
        "Now, let's show how LangGraph [supports debugging](https://langchain-ai.github.io/langgraph/how-tos/human_in_the_loop/time-travel/) by viewing, re-playing, and even forking from past states.\n",
        "\n",
        "We call this `time travel`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "bd48aeb6-8478-4cb4-aef1-d524b80824d3",
      "metadata": {
        "id": "bd48aeb6-8478-4cb4-aef1-d524b80824d3"
      },
      "outputs": [],
      "source": [
        "%%capture --no-stderr\n",
        "%pip install --quiet -U langgraph langchain_google_genai langgraph_sdk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "7d32093f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7d32093f",
        "outputId": "0afc0af0-888b-4cc0-f09f-e1b4e1edb996",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: GOOGLE_API_KEY=AIzaSyBwDMAZHrZqrpcF6clOkgz4iLrsBw-A0QQ\n",
            "env: LANGCHAIN_API_KEY=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\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "%env GOOGLE_API_KEY = {userdata.get('GEMINI_API_KEY')}\n",
        "\n",
        "%env LANGCHAIN_API_KEY = {userdata.get('LANGCHAIN_API_KEY')}\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = \"langchain-academy\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0497d316-832a-4668-b133-fd317ee81220",
      "metadata": {
        "id": "0497d316-832a-4668-b133-fd317ee81220"
      },
      "source": [
        "Let's build our agent."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "d64ab3a1-b39c-4176-88c7-791a0b80c725",
      "metadata": {
        "id": "d64ab3a1-b39c-4176-88c7-791a0b80c725"
      },
      "outputs": [],
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_core.tools import tool\n",
        "\n",
        "def multiply(a: int, b: int) -> int:\n",
        "    \"\"\"Multiply a and b.\n",
        "\n",
        "    Args:\n",
        "        a: first int\n",
        "        b: second int\n",
        "    \"\"\"\n",
        "    return a * b\n",
        "\n",
        "# This will be a tool\n",
        "def add(a: int, b: int) -> int:\n",
        "    \"\"\"Adds a and b.\n",
        "\n",
        "    Args:\n",
        "        a: first int\n",
        "        b: second int\n",
        "    \"\"\"\n",
        "    return a + b\n",
        "\n",
        "def divide(a: int, b: int) -> float:\n",
        "    \"\"\"Adds a and b.\n",
        "\n",
        "    Args:\n",
        "        a: first int\n",
        "        b: second int\n",
        "    \"\"\"\n",
        "    return a / b\n",
        "\n",
        "tools: list[tool] = [add, multiply, divide]\n",
        "llm: ChatGoogleGenerativeAI = ChatGoogleGenerativeAI(model = \"gemini-1.5-flash\")\n",
        "llm_with_tools = llm.bind_tools(tools)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.prebuilt import tools_condition, ToolNode\n",
        "\n",
        "ToolNode"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "8VpqJbqJBsEy",
        "outputId": "e430f14a-9a8d-40c9-cdd7-51cfa6058721"
      },
      "id": "8VpqJbqJBsEy",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "langgraph.prebuilt.tool_node.ToolNode"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>langgraph.prebuilt.tool_node.ToolNode</b><br/>def __init__(tools: Sequence[Union[BaseTool, Callable]], *, name: str=&#x27;tools&#x27;, tags: Optional[list[str]]=None, handle_tool_errors: Union[bool, str, Callable[..., str], tuple[type[Exception], ...]]=True, messages_key: str=&#x27;messages&#x27;) -&gt; None</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/langgraph/prebuilt/tool_node.py</a>A node that runs the tools called in the last AIMessage.\n",
              "\n",
              "It can be used either in StateGraph with a &quot;messages&quot; state key (or a custom key passed via ToolNode&#x27;s &#x27;messages_key&#x27;).\n",
              "If multiple tool calls are requested, they will be run in parallel. The output will be\n",
              "a list of ToolMessages, one for each tool call.\n",
              "\n",
              "Args:\n",
              "    tools: A sequence of tools that can be invoked by the ToolNode.\n",
              "    name: The name of the ToolNode in the graph. Defaults to &quot;tools&quot;.\n",
              "    tags: Optional tags to associate with the node. Defaults to None.\n",
              "    handle_tool_errors: How to handle tool errors raised by tools inside the node. Defaults to True.\n",
              "        Must be one of the following:\n",
              "\n",
              "        - True: all errors will be caught and\n",
              "            a ToolMessage with a default error message (TOOL_CALL_ERROR_TEMPLATE) will be returned.\n",
              "        - str: all errors will be caught and\n",
              "            a ToolMessage with the string value of &#x27;handle_tool_errors&#x27; will be returned.\n",
              "        - tuple[type[Exception], ...]: exceptions in the tuple will be caught and\n",
              "            a ToolMessage with a default error message (TOOL_CALL_ERROR_TEMPLATE) will be returned.\n",
              "        - Callable[..., str]: exceptions from the signature of the callable will be caught and\n",
              "            a ToolMessage with the string value of the result of the &#x27;handle_tool_errors&#x27; callable will be returned.\n",
              "        - False: none of the errors raised by the tools will be caught\n",
              "    messages_key: The state key in the input that contains the list of messages.\n",
              "        The same key will be used for the output from the ToolNode.\n",
              "        Defaults to &quot;messages&quot;.\n",
              "\n",
              "The `ToolNode` is roughly analogous to:\n",
              "\n",
              "```python\n",
              "tools_by_name = {tool.name: tool for tool in tools}\n",
              "def tool_node(state: dict):\n",
              "    result = []\n",
              "    for tool_call in state[&quot;messages&quot;][-1].tool_calls:\n",
              "        tool = tools_by_name[tool_call[&quot;name&quot;]]\n",
              "        observation = tool.invoke(tool_call[&quot;args&quot;])\n",
              "        result.append(ToolMessage(content=observation, tool_call_id=tool_call[&quot;id&quot;]))\n",
              "    return {&quot;messages&quot;: result}\n",
              "```\n",
              "\n",
              "Important:\n",
              "    - The state MUST contain a list of messages.\n",
              "    - The last message MUST be an `AIMessage`.\n",
              "    - The `AIMessage` MUST have `tool_calls` populated.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 132);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "1d8622a9-57cd-44dc-8696-46c5ab32d0b9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "1d8622a9-57cd-44dc-8696-46c5ab32d0b9",
        "outputId": "677f205f-4ef3-4f9b-b082-90c9d50d4d38"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from langgraph.graph import MessagesState\n",
        "from langgraph.graph import START, END, StateGraph\n",
        "from langgraph.prebuilt import tools_condition, ToolNode\n",
        "from langgraph.graph.state import CompiledStateGraph\n",
        "\n",
        "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
        "\n",
        "# System message\n",
        "sys_msg = SystemMessage(content=\"You are a helpful assistant tasked with performing arithmetic on a set of inputs.\")\n",
        "\n",
        "# Node\n",
        "def assistant(state: MessagesState):\n",
        "   return {\"messages\": [llm_with_tools.invoke([sys_msg] + state[\"messages\"])]}\n",
        "\n",
        "# Graph\n",
        "builder: StateGraph = StateGraph(MessagesState)\n",
        "\n",
        "# Define nodes: these do the work\n",
        "builder.add_node(\"assistant\", assistant)\n",
        "builder.add_node(\"tools\", ToolNode(tools))\n",
        "\n",
        "# Define edges: these determine the control flow\n",
        "builder.add_edge(START, \"assistant\")\n",
        "builder.add_conditional_edges(\n",
        "    \"assistant\",\n",
        "    # If the latest message (result) from assistant is a tool call -> tools_condition routes to tools\n",
        "    # If the latest message (result) from assistant is a not a tool call -> tools_condition routes to END\n",
        "    tools_condition,\n",
        ")\n",
        "builder.add_edge(\"tools\", \"assistant\")\n",
        "\n",
        "memory: MemorySaver = MemorySaver()\n",
        "graph: CompiledStateGraph = builder.compile(checkpointer=MemorySaver())\n",
        "\n",
        "# Show\n",
        "display(Image(graph.get_graph(xray=True).draw_mermaid_png()))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fab18a04-1329-47ac-a25b-4e01bf756e2a",
      "metadata": {
        "id": "fab18a04-1329-47ac-a25b-4e01bf756e2a"
      },
      "source": [
        "Let's run it, as before."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "05b2ab62-82bc-4356-8d5b-2d4f49069fdd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "05b2ab62-82bc-4356-8d5b-2d4f49069fdd",
        "outputId": "9470133a-2d12-4d17-87d9-111b5ea5eaba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Multiply 2 and 3\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  multiply (666e8dc8-b967-4b93-9ed7-ac20a4599a5c)\n",
            " Call ID: 666e8dc8-b967-4b93-9ed7-ac20a4599a5c\n",
            "  Args:\n",
            "    a: 2.0\n",
            "    b: 3.0\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: multiply\n",
            "\n",
            "6\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "The result is 6.\n"
          ]
        }
      ],
      "source": [
        "# Input\n",
        "initial_input = {\"messages\": HumanMessage(content=\"Multiply 2 and 3\")}\n",
        "\n",
        "# Thread\n",
        "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
        "\n",
        "# Run the graph until the first interruption\n",
        "for event in graph.stream(initial_input, thread, stream_mode=\"values\"):\n",
        "    event['messages'][-1].pretty_print()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "268cfa43-22d1-4d63-8d81-a3ce00f1f2c8",
      "metadata": {
        "id": "268cfa43-22d1-4d63-8d81-a3ce00f1f2c8"
      },
      "source": [
        "## Browsing History\n",
        "\n",
        "We can use `get_state` to look at the **current** state of our graph, given the `thread_id`!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "161eb053-18f6-4c99-8674-8cbd11cae57e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "161eb053-18f6-4c99-8674-8cbd11cae57e",
        "outputId": "8012d227-a7ed-407a-92f7-de7f94d3aa26"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StateSnapshot(values={'messages': [HumanMessage(content='Multiply 2 and 3', additional_kwargs={}, response_metadata={}, id='8736662d-f6ce-48b3-a17c-6054bd153a9f'), AIMessage(content='', additional_kwargs={'function_call': {'name': 'multiply', 'arguments': '{\"a\": 2.0, \"b\": 3.0}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-1d5d2ad0-3fe9-4535-b3e2-fd856f7ca6fd-0', tool_calls=[{'name': 'multiply', 'args': {'a': 2.0, 'b': 3.0}, 'id': '666e8dc8-b967-4b93-9ed7-ac20a4599a5c', 'type': 'tool_call'}], usage_metadata={'input_tokens': 166, 'output_tokens': 3, 'total_tokens': 169, 'input_token_details': {'cache_read': 0}}), ToolMessage(content='6', name='multiply', id='83dc75b5-03ce-4104-b198-f69aa137247e', tool_call_id='666e8dc8-b967-4b93-9ed7-ac20a4599a5c'), AIMessage(content='The result is 6.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-81ecd874-ed30-4003-966e-1660889813ce-0', usage_metadata={'input_tokens': 199, 'output_tokens': 7, 'total_tokens': 206, 'input_token_details': {'cache_read': 0}})]}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1efccde6-c5b5-647f-8003-9cb141a116f5'}}, metadata={'source': 'loop', 'writes': {'assistant': {'messages': [AIMessage(content='The result is 6.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-81ecd874-ed30-4003-966e-1660889813ce-0', usage_metadata={'input_tokens': 199, 'output_tokens': 7, 'total_tokens': 206, 'input_token_details': {'cache_read': 0}})]}}, 'thread_id': '1', 'step': 3, 'parents': {}}, created_at='2025-01-07T10:01:54.450500+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1efccde6-c256-6bf3-8002-a27367587c92'}}, tasks=())"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "graph.get_state({'configurable': {'thread_id': '1'}})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8d00869e-7b41-4d71-ad3c-cacf8f9c029f",
      "metadata": {
        "id": "8d00869e-7b41-4d71-ad3c-cacf8f9c029f"
      },
      "source": [
        "We can also browse the state history of our agent.\n",
        "\n",
        "`get_state_history` lets us get the state at all prior steps.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "3010169c-3bfa-498c-a30c-7ba53744e4d5",
      "metadata": {
        "id": "3010169c-3bfa-498c-a30c-7ba53744e4d5"
      },
      "outputs": [],
      "source": [
        "all_states = [s for s in graph.get_state_history(thread)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "c4612ccf-59fc-4848-8845-0433fee2ca8e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4612ccf-59fc-4848-8845-0433fee2ca8e",
        "outputId": "0fa523d1-9612-44a3-d7b3-557f9b1143d7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "len(all_states)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af30f269-1152-4fa1-a7c6-2947acad9a27",
      "metadata": {
        "id": "af30f269-1152-4fa1-a7c6-2947acad9a27"
      },
      "source": [
        "The first element is the current state, just as we got from `get_state`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "4e60b292-8efc-4cc3-b836-51f060fa608b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4e60b292-8efc-4cc3-b836-51f060fa608b",
        "outputId": "be0c25f3-45c1-48ad-b48d-1a94195b34ec"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StateSnapshot(values={'messages': [HumanMessage(content='Multiply 2 and 3', additional_kwargs={}, response_metadata={}, id='8736662d-f6ce-48b3-a17c-6054bd153a9f')]}, next=('assistant',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1efccde6-bc87-6558-8000-64aca1567884'}}, metadata={'source': 'loop', 'writes': None, 'thread_id': '1', 'step': 0, 'parents': {}}, created_at='2025-01-07T10:01:53.487979+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1efccde6-bc62-677f-bfff-df683a0bbc55'}}, tasks=(PregelTask(id='e43c903a-c74a-3fa1-2b97-55178c5ef9f1', name='assistant', path=('__pregel_pull', 'assistant'), error=None, interrupts=(), state=None, result={'messages': [AIMessage(content='', additional_kwargs={'function_call': {'name': 'multiply', 'arguments': '{\"a\": 2.0, \"b\": 3.0}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-1d5d2ad0-3fe9-4535-b3e2-fd856f7ca6fd-0', tool_calls=[{'name': 'multiply', 'args': {'a': 2.0, 'b': 3.0}, 'id': '666e8dc8-b967-4b93-9ed7-ac20a4599a5c', 'type': 'tool_call'}], usage_metadata={'input_tokens': 166, 'output_tokens': 3, 'total_tokens': 169, 'input_token_details': {'cache_read': 0}})]}),))"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "all_states[-2]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4148a710-ceed-413b-b93c-070c6c792fa2",
      "metadata": {
        "id": "4148a710-ceed-413b-b93c-070c6c792fa2"
      },
      "source": [
        "Everything above we can visualize here:\n",
        "\n",
        "![fig1.jpg](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66dbb038211b544898570be3_time-travel1.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5ad554a-faf3-489f-a9a9-774f4ec2a526",
      "metadata": {
        "id": "a5ad554a-faf3-489f-a9a9-774f4ec2a526"
      },
      "source": [
        "## Replaying\n",
        "\n",
        "We can re-run our agent from any of the prior steps.\n",
        "\n",
        "![fig2.jpg](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66dbb038a0bd34b541c78fb8_time-travel2.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e135d2db-d613-42da-877e-d429f21aaefd",
      "metadata": {
        "id": "e135d2db-d613-42da-877e-d429f21aaefd"
      },
      "source": [
        "Let's look back at the step that recieved human input!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "3688e511-a440-4330-a450-e5ed889c3b30",
      "metadata": {
        "id": "3688e511-a440-4330-a450-e5ed889c3b30"
      },
      "outputs": [],
      "source": [
        "to_replay = all_states[-2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "72adf296-d519-4bdc-af03-3b29799e9534",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72adf296-d519-4bdc-af03-3b29799e9534",
        "outputId": "66f7855b-0339-4d23-9401-9eb05f85a5a1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StateSnapshot(values={'messages': [HumanMessage(content='Multiply 2 and 3', additional_kwargs={}, response_metadata={}, id='8736662d-f6ce-48b3-a17c-6054bd153a9f')]}, next=('assistant',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1efccde6-bc87-6558-8000-64aca1567884'}}, metadata={'source': 'loop', 'writes': None, 'thread_id': '1', 'step': 0, 'parents': {}}, created_at='2025-01-07T10:01:53.487979+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1efccde6-bc62-677f-bfff-df683a0bbc55'}}, tasks=(PregelTask(id='e43c903a-c74a-3fa1-2b97-55178c5ef9f1', name='assistant', path=('__pregel_pull', 'assistant'), error=None, interrupts=(), state=None, result={'messages': [AIMessage(content='', additional_kwargs={'function_call': {'name': 'multiply', 'arguments': '{\"a\": 2.0, \"b\": 3.0}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-1d5d2ad0-3fe9-4535-b3e2-fd856f7ca6fd-0', tool_calls=[{'name': 'multiply', 'args': {'a': 2.0, 'b': 3.0}, 'id': '666e8dc8-b967-4b93-9ed7-ac20a4599a5c', 'type': 'tool_call'}], usage_metadata={'input_tokens': 166, 'output_tokens': 3, 'total_tokens': 169, 'input_token_details': {'cache_read': 0}})]}),))"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "to_replay"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "571e7894-6546-48ff-9c25-fa6d120391b3",
      "metadata": {
        "id": "571e7894-6546-48ff-9c25-fa6d120391b3"
      },
      "source": [
        "Look at the state."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "6fe69428-f364-4330-bf5d-aa966c7f3b07",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6fe69428-f364-4330-bf5d-aa966c7f3b07",
        "outputId": "ae9681ff-0dec-4fa5-aaf9-34fd393435bc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'messages': [HumanMessage(content='Multiply 2 and 3', additional_kwargs={}, response_metadata={}, id='8736662d-f6ce-48b3-a17c-6054bd153a9f')]}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "to_replay.values"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff2df545-cc80-4962-a34a-faac7af8eb3d",
      "metadata": {
        "id": "ff2df545-cc80-4962-a34a-faac7af8eb3d"
      },
      "source": [
        "We can see the next node to call."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2f333f9-9b2b-46f6-ac3a-525f86b20f1b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2f333f9-9b2b-46f6-ac3a-525f86b20f1b",
        "outputId": "a288143b-1cd3-4c3c-efca-c8c945ca37ec"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('assistant',)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "to_replay.next"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b8938c18-5c22-47df-b71e-40afa73c87af",
      "metadata": {
        "id": "b8938c18-5c22-47df-b71e-40afa73c87af"
      },
      "source": [
        "We also get the config, which tells us the `checkpoint_id` as well as the `thread_id`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "b1298786-afa5-4277-927e-708a8629231b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1298786-afa5-4277-927e-708a8629231b",
        "outputId": "bc814e95-8356-4ca9-f1a5-9c65f20e01d6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'configurable': {'thread_id': '1',\n",
              "  'checkpoint_ns': '',\n",
              "  'checkpoint_id': '1efccde6-bc87-6558-8000-64aca1567884'}}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "to_replay.config"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d93b5eb-f541-4f82-93b1-48f54bf5cf83",
      "metadata": {
        "id": "1d93b5eb-f541-4f82-93b1-48f54bf5cf83"
      },
      "source": [
        "To replay from here, we simply pass the config back to the agent!\n",
        "\n",
        "The graph knows that this checkpoint has aleady been executed.\n",
        "\n",
        "It just re-plays from this checkpoint!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "531b4cd1-54f6-44aa-9ffe-cf5403dad65d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "531b4cd1-54f6-44aa-9ffe-cf5403dad65d",
        "outputId": "81cda938-feeb-4808-c5fa-63066b743c2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Multiply 2 and 3\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  multiply (6eb7f84e-03ad-4b2e-8ba0-54abebaa4a41)\n",
            " Call ID: 6eb7f84e-03ad-4b2e-8ba0-54abebaa4a41\n",
            "  Args:\n",
            "    a: 2.0\n",
            "    b: 3.0\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: multiply\n",
            "\n",
            "6\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "The result is 6.\n"
          ]
        }
      ],
      "source": [
        "for event in graph.stream(None, to_replay.config, stream_mode=\"values\"):\n",
        "    event['messages'][-1].pretty_print()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d7a914e-63e6-4424-970f-15059ce9b4c3",
      "metadata": {
        "id": "7d7a914e-63e6-4424-970f-15059ce9b4c3"
      },
      "source": [
        "Now, we can see our current state after the agent re-ran."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5a5a1f03-19f2-4d22-ba54-1c065ff08e85",
      "metadata": {
        "id": "5a5a1f03-19f2-4d22-ba54-1c065ff08e85"
      },
      "source": [
        "## Forking\n",
        "\n",
        "What if we want to run from that same step, but with a different input.\n",
        "\n",
        "This is forking.\n",
        "\n",
        "![fig3.jpg](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66dbb038f89f2d847ee5c336_time-travel3.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "cdeb5bf2-1566-4d8c-8ea5-65894e3a7038",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdeb5bf2-1566-4d8c-8ea5-65894e3a7038",
        "outputId": "802cf5d1-15cd-40e9-c3b5-6709747f2472"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[HumanMessage(content='Multiply 2 and 3', additional_kwargs={}, response_metadata={}, id='8736662d-f6ce-48b3-a17c-6054bd153a9f')]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "to_fork = all_states[-2]\n",
        "to_fork.values[\"messages\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4a15f6a6-6eaa-48d6-92bb-864ea3a31b6a",
      "metadata": {
        "id": "4a15f6a6-6eaa-48d6-92bb-864ea3a31b6a"
      },
      "source": [
        "Again, we have the config."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "d1621b27-ee51-4dc3-81c4-1d05317280db",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1621b27-ee51-4dc3-81c4-1d05317280db",
        "outputId": "54445c29-9cde-4e91-b2f0-2e958fb619ca"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'configurable': {'thread_id': '1',\n",
              "  'checkpoint_ns': '',\n",
              "  'checkpoint_id': '1efccde6-bc87-6558-8000-64aca1567884'}}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "to_fork.config"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c2102195-0583-4dbe-ad2f-02fac7915585",
      "metadata": {
        "id": "c2102195-0583-4dbe-ad2f-02fac7915585"
      },
      "source": [
        "Let's modify the state at this checkpoint.\n",
        "\n",
        "We can just run `update_state` with the `checkpoint_id` supplied.\n",
        "\n",
        "Remember how our reducer on `messages` works:\n",
        "\n",
        "* It will append, unless we supply a message ID.\n",
        "* We supply the message ID to overwrite the message, rather than appending to state!\n",
        "\n",
        "So, to overwrite the the message, we just supply the message ID, which we have `to_fork.values[\"messages\"].id`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "0b4a918d-858a-41ac-a5d4-e99260e2d6ec",
      "metadata": {
        "id": "0b4a918d-858a-41ac-a5d4-e99260e2d6ec"
      },
      "outputs": [],
      "source": [
        "fork_config = graph.update_state(\n",
        "    to_fork.config,\n",
        "    {\"messages\": [HumanMessage(content='Multiply 5 and 3',\n",
        "                               id=to_fork.values[\"messages\"][0].id)]},\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "8ff4e9bb-8221-42d1-b7d0-b0cbd5dc374a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ff4e9bb-8221-42d1-b7d0-b0cbd5dc374a",
        "outputId": "7fdb9143-691e-4d40-f489-6ffa03b13005"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'configurable': {'thread_id': '1',\n",
              "  'checkpoint_ns': '',\n",
              "  'checkpoint_id': '1efccde9-567d-69e9-8001-5f72b9bba393'}}"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "fork_config"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bebfe6fd-c94b-4291-a125-ec6170e35bc5",
      "metadata": {
        "id": "bebfe6fd-c94b-4291-a125-ec6170e35bc5"
      },
      "source": [
        "This creates a new, forked checkpoint.\n",
        "\n",
        "But, the metadata - e.g., where to go next - is perserved!\n",
        "\n",
        "We can see the current state of our agent has been updated with our fork."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "586ce86c-1257-45e9-ba30-6287932b9484",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "586ce86c-1257-45e9-ba30-6287932b9484",
        "outputId": "bed7c88c-c086-46ac-cb7a-aeb0461ed192"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[HumanMessage(content='Multiply 5 and 3', additional_kwargs={}, response_metadata={}, id='8736662d-f6ce-48b3-a17c-6054bd153a9f')]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "all_states = [state for state in graph.get_state_history(thread) ]\n",
        "all_states[0].values[\"messages\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "12e19798-25d8-49e8-8542-13d2b3bdf58e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12e19798-25d8-49e8-8542-13d2b3bdf58e",
        "outputId": "ab8d4da7-cfab-4245-d2d2-0dbf1d6695b9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StateSnapshot(values={'messages': [HumanMessage(content='Multiply 5 and 3', additional_kwargs={}, response_metadata={}, id='8736662d-f6ce-48b3-a17c-6054bd153a9f')]}, next=('assistant',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1efccde9-567d-69e9-8001-5f72b9bba393'}}, metadata={'source': 'update', 'writes': {'__start__': {'messages': [HumanMessage(content='Multiply 5 and 3', additional_kwargs={}, response_metadata={}, id='8736662d-f6ce-48b3-a17c-6054bd153a9f')]}}, 'thread_id': '1', 'step': 1, 'parents': {}, 'checkpoint_ns': '', 'checkpoint_id': '1efccde6-bc87-6558-8000-64aca1567884'}, created_at='2025-01-07T10:03:03.319156+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1efccde6-bc87-6558-8000-64aca1567884'}}, tasks=(PregelTask(id='279ea641-32a4-0875-64f8-04028aba1b03', name='assistant', path=('__pregel_pull', 'assistant'), error=None, interrupts=(), state=None, result=None),))"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "graph.get_state({'configurable': {'thread_id': '1'}})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "78c641e2-b8e9-4461-b854-8725006a5eb6",
      "metadata": {
        "id": "78c641e2-b8e9-4461-b854-8725006a5eb6"
      },
      "source": [
        "Now, when we stream, the graph knows this checkpoint has never been executed.\n",
        "\n",
        "So, the graph runs, rather than simply re-playing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "1c49f2a8-b325-45e4-b36c-17fab1b37cc0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1c49f2a8-b325-45e4-b36c-17fab1b37cc0",
        "outputId": "f2642f5e-0d34-4d23-bfa3-556e34d1137a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Multiply 5 and 3\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  multiply (f1b80618-45c7-41db-93ee-32de0ead20ae)\n",
            " Call ID: f1b80618-45c7-41db-93ee-32de0ead20ae\n",
            "  Args:\n",
            "    a: 5.0\n",
            "    b: 3.0\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: multiply\n",
            "\n",
            "15\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "The result is 15.\n"
          ]
        }
      ],
      "source": [
        "for event in graph.stream(None, fork_config, stream_mode=\"values\"):\n",
        "    event['messages'][-1].pretty_print()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "428d7f80-ee60-4147-b51f-ee3b0cf5cbba",
      "metadata": {
        "id": "428d7f80-ee60-4147-b51f-ee3b0cf5cbba"
      },
      "source": [
        "Now, we can see the current state is the end of our agent run."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "132ef840-64c7-479c-ad34-3f177f4b2524",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "132ef840-64c7-479c-ad34-3f177f4b2524",
        "outputId": "66e4dc6a-58bb-44ce-b294-9d760ed557fd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StateSnapshot(values={'messages': [HumanMessage(content='Multiply 5 and 3', additional_kwargs={}, response_metadata={}, id='8736662d-f6ce-48b3-a17c-6054bd153a9f'), AIMessage(content='', additional_kwargs={'function_call': {'name': 'multiply', 'arguments': '{\"a\": 5.0, \"b\": 3.0}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-0cf4aa83-44ba-4742-872a-49024321c27d-0', tool_calls=[{'name': 'multiply', 'args': {'a': 5.0, 'b': 3.0}, 'id': 'f1b80618-45c7-41db-93ee-32de0ead20ae', 'type': 'tool_call'}], usage_metadata={'input_tokens': 166, 'output_tokens': 3, 'total_tokens': 169, 'input_token_details': {'cache_read': 0}}), ToolMessage(content='15', name='multiply', id='b6d7a0fe-7247-4b6e-8c5e-39dbe66ac9c5', tool_call_id='f1b80618-45c7-41db-93ee-32de0ead20ae'), AIMessage(content='The result is 15.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-821fc3f6-23a2-44db-a69d-04c6540a22ad-0', usage_metadata={'input_tokens': 200, 'output_tokens': 7, 'total_tokens': 207, 'input_token_details': {'cache_read': 0}})]}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1efccdea-46ee-6cf0-8004-1ab3aea4c039'}}, metadata={'source': 'loop', 'writes': {'assistant': {'messages': [AIMessage(content='The result is 15.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-821fc3f6-23a2-44db-a69d-04c6540a22ad-0', usage_metadata={'input_tokens': 200, 'output_tokens': 7, 'total_tokens': 207, 'input_token_details': {'cache_read': 0}})]}}, 'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1efccde9-567d-69e9-8001-5f72b9bba393', 'step': 4, 'parents': {}}, created_at='2025-01-07T10:03:28.531350+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1efccdea-43dd-6c59-8003-bd8f5f06867b'}}, tasks=())"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "graph.get_state({'configurable': {'thread_id': '1'}})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2ceb5f31-97b0-466c-9b3b-ae4df7cd462a",
      "metadata": {
        "id": "2ceb5f31-97b0-466c-9b3b-ae4df7cd462a"
      },
      "source": [
        "### Time travel with LangGraph API\n",
        "\n",
        "--\n",
        "\n",
        "** DISCLAIMER**\n",
        "\n",
        "*Running Studio currently requires a Mac. If you are not using a Mac, then skip this step.*\n",
        "\n",
        "*Also, if you are running this notebook in CoLab, then skip this step.*\n",
        "\n",
        "--\n",
        "\n",
        "Let's load our `agent` in the Studio UI, which uses `module-3/studio/agent.py` set in `module-3/studio/langgraph.json`.\n",
        "\n",
        "![Screenshot 2024-08-26 at 9.59.19 AM.png](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66dbb038211b544898570bec_time-travel4.png)\n",
        "\n",
        "We connect to it via the SDK and show how the LangGraph API [supports time travel](https://langchain-ai.github.io/langgraph/cloud/how-tos/human_in_the_loop_time_travel/#initial-invocation)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "891defdb-746c-48e4-8efa-bb5f138dc4bd",
      "metadata": {
        "id": "891defdb-746c-48e4-8efa-bb5f138dc4bd"
      },
      "outputs": [],
      "source": [
        "import platform\n",
        "\n",
        "if 'google.colab' in str(get_ipython()) or platform.system() != 'Darwin':\n",
        "    raise Exception(\"Unfortunately LangGraph Studio is currently not supported on Google Colab or requires a Mac\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "a317925d-1788-4cfc-9c12-336b17b4d859",
      "metadata": {
        "id": "a317925d-1788-4cfc-9c12-336b17b4d859"
      },
      "outputs": [],
      "source": [
        "from langgraph_sdk import get_client\n",
        "client = get_client(url=\"https://fe5d-185-200-235-2.ngrok-free.app/\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "815d5e03-0ab8-4c7f-a1ee-f410b6aadc03",
      "metadata": {
        "id": "815d5e03-0ab8-4c7f-a1ee-f410b6aadc03"
      },
      "source": [
        "#### Re-playing\n",
        "\n",
        "Let's run our agent streaming `updates` to the state of the graph after each node is called."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "9d4d01da-7b64-4c92-96b7-29ec93332d0b",
      "metadata": {
        "id": "9d4d01da-7b64-4c92-96b7-29ec93332d0b",
        "outputId": "848fd48b-f47b-4948-e0f1-1cc5c6dfdfd5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------Assistant Node--------------------\n",
            "{'content': '', 'additional_kwargs': {'function_call': {'name': 'multiply', 'arguments': '{\"a\": 2.0, \"b\": 3.0}'}}, 'response_metadata': {'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, 'type': 'ai', 'name': None, 'id': 'run-e4b66506-3a0f-4795-9ef8-9cbd40e15a96-0', 'example': False, 'tool_calls': [{'name': 'multiply', 'args': {'a': 2.0, 'b': 3.0}, 'id': '761db7e5-36e2-41c0-a208-6de06787dec9', 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 168, 'output_tokens': 3, 'total_tokens': 171, 'input_token_details': {'cache_read': 0}}}\n",
            "--------------------Tools Node--------------------\n",
            "{'content': '6', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'tool', 'name': 'multiply', 'id': 'ed58c9e5-a0c7-4a3c-a7c9-d80c5a2e10db', 'tool_call_id': '761db7e5-36e2-41c0-a208-6de06787dec9', 'artifact': None, 'status': 'success'}\n",
            "--------------------Assistant Node--------------------\n",
            "{'content': 'The result is 6.', 'additional_kwargs': {}, 'response_metadata': {'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, 'type': 'ai', 'name': None, 'id': 'run-3e38fd1a-b877-4878-8c91-7f2fbcdcb0ac-0', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 201, 'output_tokens': 7, 'total_tokens': 208, 'input_token_details': {'cache_read': 0}}}\n"
          ]
        }
      ],
      "source": [
        "initial_input = {\"messages\": HumanMessage(content=\"Multiply 2 and 3\")}\n",
        "thread = await client.threads.create()\n",
        "async for chunk in client.runs.stream(\n",
        "    thread[\"thread_id\"],\n",
        "    assistant_id = \"agent\",\n",
        "    input=initial_input,\n",
        "    stream_mode=\"updates\",\n",
        "):\n",
        "    if chunk.data:\n",
        "        assisant_node = chunk.data.get('assistant', {}).get('messages', [])\n",
        "        tool_node = chunk.data.get('tools', {}).get('messages', [])\n",
        "        if assisant_node:\n",
        "            print(\"-\" * 20+\"Assistant Node\"+\"-\" * 20)\n",
        "            print(assisant_node[-1])\n",
        "        elif tool_node:\n",
        "            print(\"-\" * 20+\"Tools Node\"+\"-\" * 20)\n",
        "            print(tool_node[-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8cc3bab2",
      "metadata": {
        "id": "8cc3bab2"
      },
      "source": [
        "Now, let's look at **replaying** from a specified checkpoint.\n",
        "\n",
        "We simply need to pass the `checkpoint_id`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "d8ecc4fd",
      "metadata": {
        "id": "d8ecc4fd",
        "outputId": "81ac78ee-241b-4114-aef2-1a978d9ecf1b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'values': {'messages': [{'content': 'Multiply 2 and 3',\n",
              "    'additional_kwargs': {'example': False,\n",
              "     'additional_kwargs': {},\n",
              "     'response_metadata': {}},\n",
              "    'response_metadata': {},\n",
              "    'type': 'human',\n",
              "    'name': None,\n",
              "    'id': '2a6a8008-e899-46de-8c86-614154c2305f',\n",
              "    'example': False}]},\n",
              " 'next': ['assistant'],\n",
              " 'tasks': [{'id': 'caa6a6c7-09b0-937d-9327-e163b9a5c2b7',\n",
              "   'name': 'assistant',\n",
              "   'path': ['__pregel_pull', 'assistant'],\n",
              "   'error': None,\n",
              "   'interrupts': [],\n",
              "   'checkpoint': None,\n",
              "   'state': None,\n",
              "   'result': {'messages': [{'content': '',\n",
              "      'additional_kwargs': {'function_call': {'name': 'multiply',\n",
              "        'arguments': '{\"a\": 2.0, \"b\": 3.0}'}},\n",
              "      'response_metadata': {'prompt_feedback': {'block_reason': 0,\n",
              "        'safety_ratings': []},\n",
              "       'finish_reason': 'STOP',\n",
              "       'safety_ratings': []},\n",
              "      'type': 'ai',\n",
              "      'name': None,\n",
              "      'id': 'run-e4b66506-3a0f-4795-9ef8-9cbd40e15a96-0',\n",
              "      'example': False,\n",
              "      'tool_calls': [{'name': 'multiply',\n",
              "        'args': {'a': 2.0, 'b': 3.0},\n",
              "        'id': '761db7e5-36e2-41c0-a208-6de06787dec9',\n",
              "        'type': 'tool_call'}],\n",
              "      'invalid_tool_calls': [],\n",
              "      'usage_metadata': {'input_tokens': 168,\n",
              "       'output_tokens': 3,\n",
              "       'total_tokens': 171,\n",
              "       'input_token_details': {'cache_read': 0}}}]}}],\n",
              " 'metadata': {'step': 0,\n",
              "  'run_id': '1efccdec-4400-6c9b-ae3e-6cf53ea3d856',\n",
              "  'source': 'loop',\n",
              "  'writes': None,\n",
              "  'parents': {},\n",
              "  'user_id': '',\n",
              "  'graph_id': 'agent',\n",
              "  'thread_id': '5c8e78b2-906d-4613-b272-89c949be547b',\n",
              "  'created_by': 'system',\n",
              "  'run_attempt': 1,\n",
              "  'assistant_id': 'fe096781-5601-53d2-b2f6-0d3403f7e9ca',\n",
              "  'langgraph_host': 'self-hosted',\n",
              "  'langgraph_plan': 'developer',\n",
              "  'x-forwarded-for': '34.75.103.230',\n",
              "  'x-forwarded-host': 'fe5d-185-200-235-2.ngrok-free.app',\n",
              "  'langgraph_version': '0.2.61',\n",
              "  'x-forwarded-proto': 'https',\n",
              "  'langgraph_auth_user': None,\n",
              "  'langgraph_auth_user_id': ''},\n",
              " 'created_at': '2025-01-07T10:04:21.977679+00:00',\n",
              " 'checkpoint': {'checkpoint_id': '1efccdec-44a2-6f72-8000-2b639958717e',\n",
              "  'thread_id': '5c8e78b2-906d-4613-b272-89c949be547b',\n",
              "  'checkpoint_ns': ''},\n",
              " 'parent_checkpoint': {'checkpoint_id': '1efccdec-449c-6162-bfff-d4dcc39a5bf9',\n",
              "  'thread_id': '5c8e78b2-906d-4613-b272-89c949be547b',\n",
              "  'checkpoint_ns': ''},\n",
              " 'checkpoint_id': '1efccdec-44a2-6f72-8000-2b639958717e',\n",
              " 'parent_checkpoint_id': '1efccdec-449c-6162-bfff-d4dcc39a5bf9'}"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "states = await client.threads.get_history(thread['thread_id'])\n",
        "to_replay = states[-2]\n",
        "to_replay"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e33f865a",
      "metadata": {
        "id": "e33f865a"
      },
      "source": [
        "Let's stream with `stream_mode=\"values\"` to see the full state at every node as we replay."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "325e8272",
      "metadata": {
        "id": "325e8272",
        "outputId": "662549db-4770-4ad6-9804-fa69dca70390",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Receiving new event of type: metadata...\n",
            "{'run_id': '1efccdec-ffe0-68b2-b86a-0b25fda86e68', 'attempt': 1}\n",
            "\n",
            "\n",
            "\n",
            "Receiving new event of type: values...\n",
            "{'messages': [{'content': 'Multiply 2 and 3', 'additional_kwargs': {'example': False, 'additional_kwargs': {}, 'response_metadata': {}}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '2a6a8008-e899-46de-8c86-614154c2305f', 'example': False}]}\n",
            "\n",
            "\n",
            "\n",
            "Receiving new event of type: values...\n",
            "{'messages': [{'content': 'Multiply 2 and 3', 'additional_kwargs': {'example': False, 'additional_kwargs': {}, 'response_metadata': {}}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '2a6a8008-e899-46de-8c86-614154c2305f', 'example': False}, {'content': '', 'additional_kwargs': {'function_call': {'name': 'multiply', 'arguments': '{\"a\": 2.0, \"b\": 3.0}'}}, 'response_metadata': {'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, 'type': 'ai', 'name': None, 'id': 'run-43f0f131-6092-413e-8189-df8f2f61395e-0', 'example': False, 'tool_calls': [{'name': 'multiply', 'args': {'a': 2.0, 'b': 3.0}, 'id': 'f2aaaf4c-a6e8-418a-b5ef-c83843b34114', 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 168, 'output_tokens': 3, 'total_tokens': 171, 'input_token_details': {'cache_read': 0}}}]}\n",
            "\n",
            "\n",
            "\n",
            "Receiving new event of type: values...\n",
            "{'messages': [{'content': 'Multiply 2 and 3', 'additional_kwargs': {'example': False, 'additional_kwargs': {}, 'response_metadata': {}}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '2a6a8008-e899-46de-8c86-614154c2305f', 'example': False}, {'content': '', 'additional_kwargs': {'function_call': {'name': 'multiply', 'arguments': '{\"a\": 2.0, \"b\": 3.0}'}}, 'response_metadata': {'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, 'type': 'ai', 'name': None, 'id': 'run-43f0f131-6092-413e-8189-df8f2f61395e-0', 'example': False, 'tool_calls': [{'name': 'multiply', 'args': {'a': 2.0, 'b': 3.0}, 'id': 'f2aaaf4c-a6e8-418a-b5ef-c83843b34114', 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 168, 'output_tokens': 3, 'total_tokens': 171, 'input_token_details': {'cache_read': 0}}}, {'content': '6', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'tool', 'name': 'multiply', 'id': 'ce398df2-737a-46a4-bb6f-aa64dbe3f7b5', 'tool_call_id': 'f2aaaf4c-a6e8-418a-b5ef-c83843b34114', 'artifact': None, 'status': 'success'}]}\n",
            "\n",
            "\n",
            "\n",
            "Receiving new event of type: values...\n",
            "{'messages': [{'content': 'Multiply 2 and 3', 'additional_kwargs': {'example': False, 'additional_kwargs': {}, 'response_metadata': {}}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '2a6a8008-e899-46de-8c86-614154c2305f', 'example': False}, {'content': '', 'additional_kwargs': {'function_call': {'name': 'multiply', 'arguments': '{\"a\": 2.0, \"b\": 3.0}'}}, 'response_metadata': {'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, 'type': 'ai', 'name': None, 'id': 'run-43f0f131-6092-413e-8189-df8f2f61395e-0', 'example': False, 'tool_calls': [{'name': 'multiply', 'args': {'a': 2.0, 'b': 3.0}, 'id': 'f2aaaf4c-a6e8-418a-b5ef-c83843b34114', 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 168, 'output_tokens': 3, 'total_tokens': 171, 'input_token_details': {'cache_read': 0}}}, {'content': '6', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'tool', 'name': 'multiply', 'id': 'ce398df2-737a-46a4-bb6f-aa64dbe3f7b5', 'tool_call_id': 'f2aaaf4c-a6e8-418a-b5ef-c83843b34114', 'artifact': None, 'status': 'success'}, {'content': 'The result is 6.', 'additional_kwargs': {}, 'response_metadata': {'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, 'type': 'ai', 'name': None, 'id': 'run-0000e973-1abc-498d-b67c-8547ace9fa51-0', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 201, 'output_tokens': 7, 'total_tokens': 208, 'input_token_details': {'cache_read': 0}}}]}\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "async for chunk in client.runs.stream(\n",
        "    thread[\"thread_id\"],\n",
        "    assistant_id=\"agent\",\n",
        "    input=None,\n",
        "    stream_mode=\"values\",\n",
        "    checkpoint_id=to_replay['checkpoint_id']\n",
        "):\n",
        "    print(f\"Receiving new event of type: {chunk.event}...\")\n",
        "    print(chunk.data)\n",
        "    print(\"\\n\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "14c153b3",
      "metadata": {
        "id": "14c153b3"
      },
      "source": [
        "We can all view this as streaming only `updates` to state made by the nodes that we reply."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "9e608e93",
      "metadata": {
        "id": "9e608e93",
        "outputId": "733a9887-dca3-430e-9cd4-9aaa7ff30bfe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------Assistant Node--------------------\n",
            "{'content': '', 'additional_kwargs': {'function_call': {'name': 'multiply', 'arguments': '{\"a\": 2.0, \"b\": 3.0}'}}, 'response_metadata': {'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, 'type': 'ai', 'name': None, 'id': 'run-bf9964a1-db7e-481a-86aa-12d0b6d1d5c3-0', 'example': False, 'tool_calls': [{'name': 'multiply', 'args': {'a': 2.0, 'b': 3.0}, 'id': '75491169-db12-4a57-9bc9-57fcf7ca3cef', 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 168, 'output_tokens': 3, 'total_tokens': 171, 'input_token_details': {'cache_read': 0}}}\n",
            "--------------------Tools Node--------------------\n",
            "{'content': '6', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'tool', 'name': 'multiply', 'id': 'f532079b-b97e-455d-808d-6ef5d9740631', 'tool_call_id': '75491169-db12-4a57-9bc9-57fcf7ca3cef', 'artifact': None, 'status': 'success'}\n",
            "--------------------Assistant Node--------------------\n",
            "{'content': 'The result is 6.', 'additional_kwargs': {}, 'response_metadata': {'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, 'type': 'ai', 'name': None, 'id': 'run-b715e4ff-30d4-4a88-bbc0-26d5f7ba33e6-0', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 201, 'output_tokens': 6, 'total_tokens': 207, 'input_token_details': {'cache_read': 0}}}\n"
          ]
        }
      ],
      "source": [
        "async for chunk in client.runs.stream(\n",
        "    thread[\"thread_id\"],\n",
        "    assistant_id=\"agent\",\n",
        "    input=None,\n",
        "    stream_mode=\"updates\",\n",
        "    checkpoint_id=to_replay['checkpoint_id']\n",
        "):\n",
        "    if chunk.data:\n",
        "        assisant_node = chunk.data.get('assistant', {}).get('messages', [])\n",
        "        tool_node = chunk.data.get('tools', {}).get('messages', [])\n",
        "        if assisant_node:\n",
        "            print(\"-\" * 20+\"Assistant Node\"+\"-\" * 20)\n",
        "            print(assisant_node[-1])\n",
        "        elif tool_node:\n",
        "            print(\"-\" * 20+\"Tools Node\"+\"-\" * 20)\n",
        "            print(tool_node[-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8e66e0e8",
      "metadata": {
        "id": "8e66e0e8"
      },
      "source": [
        "#### Forking\n",
        "\n",
        "Now, let's look at forking.\n",
        "\n",
        "Let's get the same step as we worked with above, the human input.\n",
        "\n",
        "Let's create a new thread with out agent."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "01af5ed4",
      "metadata": {
        "id": "01af5ed4",
        "outputId": "430bf534-9bc7-4f6e-d6f0-9c2d9fcb23ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------Assistant Node--------------------\n",
            "{'content': '', 'additional_kwargs': {'function_call': {'name': 'multiply', 'arguments': '{\"a\": 2.0, \"b\": 3.0}'}}, 'response_metadata': {'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, 'type': 'ai', 'name': None, 'id': 'run-5ffabcfa-5aab-4e29-b6a0-4edd74d979e8-0', 'example': False, 'tool_calls': [{'name': 'multiply', 'args': {'a': 2.0, 'b': 3.0}, 'id': '6ce5c7af-2f90-4fb4-a9f1-db4edfe317f3', 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 168, 'output_tokens': 3, 'total_tokens': 171, 'input_token_details': {'cache_read': 0}}}\n",
            "--------------------Tools Node--------------------\n",
            "{'content': '6', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'tool', 'name': 'multiply', 'id': 'fd0dbba4-f069-4131-979b-10c1d7116e26', 'tool_call_id': '6ce5c7af-2f90-4fb4-a9f1-db4edfe317f3', 'artifact': None, 'status': 'success'}\n",
            "--------------------Assistant Node--------------------\n",
            "{'content': 'The result is 6.', 'additional_kwargs': {}, 'response_metadata': {'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, 'type': 'ai', 'name': None, 'id': 'run-1eece9ec-bc3a-4bfc-983d-ec14484369f2-0', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 201, 'output_tokens': 7, 'total_tokens': 208, 'input_token_details': {'cache_read': 0}}}\n"
          ]
        }
      ],
      "source": [
        "initial_input = {\"messages\": HumanMessage(content=\"Multiply 2 and 3\")}\n",
        "thread = await client.threads.create()\n",
        "async for chunk in client.runs.stream(\n",
        "    thread[\"thread_id\"],\n",
        "    assistant_id=\"agent\",\n",
        "    input=initial_input,\n",
        "    stream_mode=\"updates\",\n",
        "):\n",
        "    if chunk.data:\n",
        "        assisant_node = chunk.data.get('assistant', {}).get('messages', [])\n",
        "        tool_node = chunk.data.get('tools', {}).get('messages', [])\n",
        "        if assisant_node:\n",
        "            print(\"-\" * 20+\"Assistant Node\"+\"-\" * 20)\n",
        "            print(assisant_node[-1])\n",
        "        elif tool_node:\n",
        "            print(\"-\" * 20+\"Tools Node\"+\"-\" * 20)\n",
        "            print(tool_node[-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "3dbc8795-c3f5-4559-a00e-dc410c0a927f",
      "metadata": {
        "id": "3dbc8795-c3f5-4559-a00e-dc410c0a927f",
        "outputId": "66ddac31-8a1a-41d7-ed47-c5120dc167ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'messages': [{'content': 'Multiply 2 and 3',\n",
              "   'additional_kwargs': {'example': False,\n",
              "    'additional_kwargs': {},\n",
              "    'response_metadata': {}},\n",
              "   'response_metadata': {},\n",
              "   'type': 'human',\n",
              "   'name': None,\n",
              "   'id': '9ab01e02-bd8b-4683-9ca0-1356b373c363',\n",
              "   'example': False}]}"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "states = await client.threads.get_history(thread['thread_id'])\n",
        "to_fork = states[-2]\n",
        "to_fork['values']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "11e6cde1-0388-43ea-b994-1c4e9ca1199b",
      "metadata": {
        "id": "11e6cde1-0388-43ea-b994-1c4e9ca1199b",
        "outputId": "1f9eb386-9ec3-4ea5-bbfc-5d2efc6b629c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'9ab01e02-bd8b-4683-9ca0-1356b373c363'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "to_fork['values']['messages'][0]['id']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "0c1e2300-c8b2-4994-a96d-1be19c04b6a8",
      "metadata": {
        "id": "0c1e2300-c8b2-4994-a96d-1be19c04b6a8",
        "outputId": "570d82a3-f949-436d-e31a-34cd8b9cf355",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['assistant']"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "to_fork['next']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "9d31d5aa-524f-42f4-ba7e-713a029610d6",
      "metadata": {
        "id": "9d31d5aa-524f-42f4-ba7e-713a029610d6",
        "outputId": "6f1cb149-8bb0-4dc1-8334-e971263754ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1efccded-f766-6d25-8000-658271252737'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "to_fork['checkpoint_id']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8f11e1d9-9fe7-4243-a06f-9b07e38a12ad",
      "metadata": {
        "id": "8f11e1d9-9fe7-4243-a06f-9b07e38a12ad"
      },
      "source": [
        "Let's edit the state.\n",
        "\n",
        "Remember how our reducer on `messages` works:\n",
        "\n",
        "* It will append, unless we supply a message ID.\n",
        "* We supply the message ID to overwrite the message, rather than appending to state!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "0198f1b8-2f57-4c6e-ac6a-c6fb80cce0bd",
      "metadata": {
        "id": "0198f1b8-2f57-4c6e-ac6a-c6fb80cce0bd"
      },
      "outputs": [],
      "source": [
        "forked_input = {\"messages\": HumanMessage(content=\"Multiply 3 and 3\",\n",
        "                                         id=to_fork['values']['messages'][0]['id'])}\n",
        "\n",
        "forked_config = await client.threads.update_state(\n",
        "    thread[\"thread_id\"],\n",
        "    forked_input,\n",
        "    checkpoint_id=to_fork['checkpoint_id']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "1dcd5b8e-6bb1-4967-84cf-4af710b8bf46",
      "metadata": {
        "id": "1dcd5b8e-6bb1-4967-84cf-4af710b8bf46",
        "outputId": "3efa7e0f-e04e-463e-b9ac-146fef3c069c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'checkpoint': {'thread_id': 'e86ab22b-fc4f-4151-b1ee-405c45e0b167',\n",
              "  'checkpoint_ns': '',\n",
              "  'checkpoint_id': '1efccdef-38a9-6d38-8001-e30b4c81ad73'},\n",
              " 'configurable': {'thread_id': 'e86ab22b-fc4f-4151-b1ee-405c45e0b167',\n",
              "  'checkpoint_ns': '',\n",
              "  'checkpoint_id': '1efccdef-38a9-6d38-8001-e30b4c81ad73'},\n",
              " 'checkpoint_id': '1efccdef-38a9-6d38-8001-e30b4c81ad73'}"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "forked_config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "015ac68a-5cc1-4c42-90a2-5b2b4865a153",
      "metadata": {
        "id": "015ac68a-5cc1-4c42-90a2-5b2b4865a153",
        "outputId": "8eba968a-0ee9-4a56-a4b0-5b852271b070",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'values': {'messages': [{'content': 'Multiply 3 and 3',\n",
              "    'additional_kwargs': {'additional_kwargs': {},\n",
              "     'response_metadata': {},\n",
              "     'example': False},\n",
              "    'response_metadata': {},\n",
              "    'type': 'human',\n",
              "    'name': None,\n",
              "    'id': '9ab01e02-bd8b-4683-9ca0-1356b373c363',\n",
              "    'example': False}]},\n",
              " 'next': ['assistant'],\n",
              " 'tasks': [{'id': 'b5db6a68-80ad-42c1-8483-ca72d4dc361f',\n",
              "   'name': 'assistant',\n",
              "   'path': ['__pregel_pull', 'assistant'],\n",
              "   'error': None,\n",
              "   'interrupts': [],\n",
              "   'checkpoint': None,\n",
              "   'state': None,\n",
              "   'result': None}],\n",
              " 'metadata': {'step': 1,\n",
              "  'run_id': '1efccded-f6e4-64b4-bf97-38d86e11f3b1',\n",
              "  'source': 'update',\n",
              "  'writes': {'__start__': {'messages': {'id': '9ab01e02-bd8b-4683-9ca0-1356b373c363',\n",
              "     'name': None,\n",
              "     'type': 'human',\n",
              "     'content': 'Multiply 3 and 3',\n",
              "     'example': False,\n",
              "     'additional_kwargs': {},\n",
              "     'response_metadata': {}}}},\n",
              "  'parents': {},\n",
              "  'user_id': '',\n",
              "  'graph_id': 'agent',\n",
              "  'thread_id': 'e86ab22b-fc4f-4151-b1ee-405c45e0b167',\n",
              "  'created_by': 'system',\n",
              "  'run_attempt': 1,\n",
              "  'assistant_id': 'fe096781-5601-53d2-b2f6-0d3403f7e9ca',\n",
              "  'checkpoint_id': '1efccded-f766-6d25-8000-658271252737',\n",
              "  'langgraph_host': 'self-hosted',\n",
              "  'langgraph_plan': 'developer',\n",
              "  'x-forwarded-for': '34.75.103.230',\n",
              "  'x-forwarded-host': 'fe5d-185-200-235-2.ngrok-free.app',\n",
              "  'langgraph_version': '0.2.61',\n",
              "  'x-forwarded-proto': 'https',\n",
              "  'langgraph_auth_user': None,\n",
              "  'langgraph_auth_user_id': ''},\n",
              " 'created_at': '2025-01-07T10:05:41.252832+00:00',\n",
              " 'checkpoint': {'checkpoint_id': '1efccdef-38a9-6d38-8001-e30b4c81ad73',\n",
              "  'thread_id': 'e86ab22b-fc4f-4151-b1ee-405c45e0b167',\n",
              "  'checkpoint_ns': ''},\n",
              " 'parent_checkpoint': {'checkpoint_id': '1efccded-f766-6d25-8000-658271252737',\n",
              "  'thread_id': 'e86ab22b-fc4f-4151-b1ee-405c45e0b167',\n",
              "  'checkpoint_ns': ''},\n",
              " 'checkpoint_id': '1efccdef-38a9-6d38-8001-e30b4c81ad73',\n",
              " 'parent_checkpoint_id': '1efccded-f766-6d25-8000-658271252737'}"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "states = await client.threads.get_history(thread['thread_id'])\n",
        "states[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3de80029-b987-49c5-890d-6cd70cbc8de7",
      "metadata": {
        "id": "3de80029-b987-49c5-890d-6cd70cbc8de7"
      },
      "source": [
        "To rerun, we pass in the `checkpoint_id`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "da005240-d3f0-4c89-9aca-dfcb5d410ceb",
      "metadata": {
        "id": "da005240-d3f0-4c89-9aca-dfcb5d410ceb",
        "outputId": "753d5a17-8f39-42d2-d573-7cabcf32819d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------Assistant Node--------------------\n",
            "{'content': '', 'additional_kwargs': {'function_call': {'name': 'multiply', 'arguments': '{\"a\": 3.0, \"b\": 3.0}'}}, 'response_metadata': {'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, 'type': 'ai', 'name': None, 'id': 'run-47edc94c-e04b-40c0-85d0-079ad28814e0-0', 'example': False, 'tool_calls': [{'name': 'multiply', 'args': {'a': 3.0, 'b': 3.0}, 'id': '5ba3ddad-8722-4d8d-872a-66194a423093', 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 168, 'output_tokens': 3, 'total_tokens': 171, 'input_token_details': {'cache_read': 0}}}\n",
            "--------------------Tools Node--------------------\n",
            "{'content': '9', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'tool', 'name': 'multiply', 'id': '4b809aa7-e808-4845-a13e-1478fd761e22', 'tool_call_id': '5ba3ddad-8722-4d8d-872a-66194a423093', 'artifact': None, 'status': 'success'}\n",
            "--------------------Assistant Node--------------------\n",
            "{'content': 'The result is 9.', 'additional_kwargs': {}, 'response_metadata': {'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, 'type': 'ai', 'name': None, 'id': 'run-bb0de108-f420-4ddc-9ece-7ede096f5b38-0', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 201, 'output_tokens': 6, 'total_tokens': 207, 'input_token_details': {'cache_read': 0}}}\n"
          ]
        }
      ],
      "source": [
        "async for chunk in client.runs.stream(\n",
        "    thread[\"thread_id\"],\n",
        "    assistant_id=\"agent\",\n",
        "    input=None,\n",
        "    stream_mode=\"updates\",\n",
        "    checkpoint_id=forked_config['checkpoint_id']\n",
        "):\n",
        "    if chunk.data:\n",
        "        assisant_node = chunk.data.get('assistant', {}).get('messages', [])\n",
        "        tool_node = chunk.data.get('tools', {}).get('messages', [])\n",
        "        if assisant_node:\n",
        "            print(\"-\" * 20+\"Assistant Node\"+\"-\" * 20)\n",
        "            print(assisant_node[-1])\n",
        "        elif tool_node:\n",
        "            print(\"-\" * 20+\"Tools Node\"+\"-\" * 20)\n",
        "            print(tool_node[-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "36956571-a2b8-4f1b-8e30-51f02f155a6f",
      "metadata": {
        "id": "36956571-a2b8-4f1b-8e30-51f02f155a6f"
      },
      "source": [
        "### LangGraph Studio\n",
        "\n",
        "Let's look at forking in the Studio UI with our `agent`, which uses `module-1/studio/agent.py` set in `module-1/studio/langgraph.json`."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}